# Model Fit en Modellen Vergelijken {#sec-model-fit}

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

#Packages
library(rio)             #laden van data
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #samenvattingen regressiemodellen
library(parameters)      #berekenen gestandaardiseerde coëfficiënten
library(marginaleffects) #voorspelde waarden berekenen

#Import Data
demdata <- import("data/demdata.rds") |> 
  as_tibble()

#Some data cleaning
demdata <- demdata |>  
  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984), 
         Typeregime2006 = factorize(Typeregime2006))

```

Tot nu lag de focus op individuele coëfficiënten. Nu verschuiven we de focus naar model 'fit', oftewel de mate waarin het model bij de data past. We bekijken ook hoe we de fit van meerdere modellen kunnen vergelijken.

```{r}
#| eval: false

#Packages
library(rio)             #laden van data
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #samenvattingen regressiemodellen

##Importeer data en data management
demdata <- import("demdata.rds") |> 
  as_tibble()

demdata <- demdata |>  
  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984), 
         Typeregime2006 = factorize(Typeregime2006))


```

## R^2^, Adjusted R^2^ en de F-Test

Ons voorbeeld hier is een regressiemodel waarin we de electorale democratiescore van een land in 2020 (`v2x_polyarchy`) voorspellen aan de hand van gepercipieerde corruptie in dat land (`cpi)`, politiek geweld (`v2caviol`), en regimestatus in 1984 (`TYPEDEMO1984`).

```{r}
model_multiple <- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data=demdata)
```

De meeste model fit statistieken verkrijgen we simpelweg via de `summary()` functie:

```{r}
summary(model_multiple)
```

::: callout-note
#### Output uitleg

Model fit statistieken vinden we onderaan de output. "Multiple R-Squared" geeft de $R^2$ (R kwadraat) statistiek. "Adjusted R-Squared" geeft de $R^2$ gecorrigeerd voor het aantal predictoren in het model. De F-statistiek geeft informatie over de statistische significantie van het model.

-   Multiple R-squared: Dit toont de $R^2$ (R kwadraat) statistiek, die meestal geïnterpreteerd wordt in termen van % van de variatie in Y verklaard door de predictoren in het model
-   Adjusted R-squared: Dit toont de $R^2$ gecorrigeerd voor het aantal predictoren in het model.
-   F-statistic...: De F-statistiek geeft informatie over de statistische significantie van het model. Het eerste getal is de F-statistiek zelf (`r round(glance(model_multiple)$statistic, 2)`). Het cijfer achter "p-value:" is de p-waarde voor de F-statistiek. De nulhypothese die hierbij getest wordt is dat geen enkele van de onafhankelijke variabelen (hier: `cpi, v2caviol, TYPEDEMO1984`) statistisch significant is. Een statistisch signifcante F-statistiek betekent dat op z'n minst 1 predictor significant is.
:::

Deze output kunnen we ook verkrijgen via de `glance()` functie uit het `broom` package:

```{r}
glance(model_multiple)
```

De relevante statistieken vind je bij `r.squared` (R^2^), `adj.r.squared` (Adjusted R^2^), `statistic` (F-statistic), en `p.value` (p-waarde voor de F-statistiek) kolommen. `nobs` toont het aantal observaties gebruikt in het model.

## Modellen vergelijken {#sec-linear-comparing-models}

De F-statistiek gaat na of het model een significant verbeterde voorspelling geeft dan een 'nul model' zonder predictoren, oftewel het gemiddelde van de afhankelijke variabele. We kunnen ook meerdere modellen vergelijken met elkaar. Hier vergelijken we een model met enkel `cpi` als onafhankelijke, dan een model met zowel `cpi` als `v2caviol`, en ten slotte een model met alle predictoren. Deze modellen zijn 'nested', dat wil zeggen dat meer uitgebreide modellen alle variabelen bevatten van de meer simpele modellen.

Om deze vergelijking te maken moeten we er wel voor zorgen dat onze modellen met dezelfde observaties werken en dus dezelfde N hebben. Dit kunnen we bereiken door een nieuwe dataset aan te maken met complete waarden (non-missing) voor alle variabelen die gebruikt worden in het meest complete model.

```{r}
demdata_complete <- demdata |> 
  filter(complete.cases(v2x_polyarchy, cpi, v2caviol, TYPEDEMO1984))
```

Deze dataset gebruiken we om onze modellen te schatten. Om een volledige vergelijking mogelijk te maken, schatten we ook een nulmodel zonder onafhankelijke variabelen met enkel een intercept (\~ 1). Dit intercept bevat de gemiddelde waarde voor Y in de dataset (i.e. onze beste voorspelling zonder predictoren):

```{r}
#Null model
model1 <- lm(v2x_polyarchy ~ 1, data = demdata_complete)

#Model with just cpi
model2 <- lm(v2x_polyarchy ~ cpi, data = demdata_complete)

#Model with cpi & v2caviol
model3 <- lm(v2x_polyarchy ~ cpi + v2caviol, data = demdata_complete)

#Model with all predictors
model4 <- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata_complete)
```

We kunnen de R2/Adj. R-Squared van de modellen vergelijken om te bekijken welk model het beste past. Dit geeft ons echter geen significantietoets:

|  Model  |                  R2                   |                  Adj. R2                  |
|:----------------:|:------------------------:|:---------------------------:|
| Model 1 |     `r glance(model1)$r.squared`      |     `r glance(model1)$adj.r.squared`      |
| Model 2 | `r round(glance(model2)$r.squared,3)` | `r round(glance(model2)$adj.r.squared,3)` |
| Model 3 | `r round(glance(model3)$r.squared,3)` | `r round(glance(model3)$adj.r.squared,3)` |
| Model 4 | `r round(glance(model4)$r.squared,3)` | `r round(glance(model4)$adj.r.squared,3)` |

Model 4 lijkt het beste te passen, maar om de significantietoets uit te voeren moeten we de `anova()` functie gebruiken. Deze is ingebouwd in R.

```{r}
anova(model1, model2, model3, model4)
```

`anova()`

:   We voeren de functie uit op de modellen tussen haakjes.

::: callout-note
#### Output uitleg

Het eerste deel van de output toont welke modellen vergeleken worden met elkaar. De onderste helft bevat het volgende:

-   Res.Df: De residual degrees of freedom (vrijheidsgraden) van het model
-   RSS: Dit staat voor "residual sum of squares". RSS meet de variatie tussen de residuals in het model. RSS = $\sum(y_{i} - \hat{y}_{i})^2$, waarbij $\sum$ staat voor "sum up", $y_{i}$ is de geobserveerde Y voor een observatie in het model, and $\hat{y}_{i}$ is de voorspelde waarde voor diezelfde observatie.[^linear_06-1] RSS vertelt ons hoeveel van de variatie in Y het model *niet* kan verklaren of voorspellen. Een model met een lagere RSS voorspelt de Y beter, maar het verschil in RSS tussen modellen is niet altijd significant. We hebben dus nog een significantietoets nodig.
-   DF: Vrijheidsgraden. In de praktijk de hoeveelheid onafhankelijke variabelen toegevoegd in vergelijking met het voorgaande model. Dit getal is 1 als er 1 predictor werd toegevoegd in vergelijking met het vorige model in bovenstaande rij.[^linear_06-2]
-   Sum of Sq: De *model* of "regression" sum of squares is gebaseerd op de volgende formule: $\sum(\hat{y}_{i} - \bar{y})^2$, waarbij $\hat{y}_{i}$ de voorspelde waarde is voor een observatie in het model, en $\bar{y}$ de gemiddelde waarde voor Y op basis van alle observaties in het model.[^linear_06-3] De model sum of squares meet de variatie in Y die verklaart wordt door de predictoren in het model. De Sum of Sq in de `anova()` output toont de verandering in Sum of Sq ten opzichte van het voorgaande model. Hoe hoger de stijging hoe beter, maar hier moet ook een signifcantietest voor gebeuren.
-   F & Pr(\>F): De F-statistiek en bijhorende p-waarde. De nulhypothese is dat het model in de desbetreffende rij niet beter past dan het model in de voorgaande rij. In feite test dit of tenminste 1 van de variabelen toegevoegd aan het model significant is. Indien de nulhypothese verworpen wordt, dan kunnen we zeggen dat het nieuwe model beter past.
:::

[^linear_06-1]: Deze vergelijking behoort niet tot de leerstof.

[^linear_06-2]: De DF kolom geeft op zich niet weer hoeveel extra *onafhankelijke variabelen* werden toegevoegd, maar wel hoeveel nieuwe coëfficiënten (of termen) werden toegevoegd. Dit is vooral van belang bij factor variabelen (zeker als ze 3 of meer categorieën hebben). Hoewel je misschien 1 factor variabele toevoegt, kun je meer dan 1 coëfficiënt (en dus DF) krijgen als je voor meerdere categorieën dummy variabelen moet toevoegen.

[^linear_06-3]: Deze vergelijking behoort niet tot de leerstof.

We kunnen de output als volgt lezen: Model 2 past hier beter dan 1 (nulmodel), Model 3 past niet beter dan 2, en Model 4 past beter dan 3. We kunnen ook Modellen 1 en 2 direct met Model 4 vergelijken:

```{r}
#Model 4 vs. Model 2
anova(model2, model4)

#Model 4 vs. Model 1
anova(model1, model4)
```

::: callout-important
#### Waarschuwing!

`anova()` De volgorde van de modellen is van belang voor de uitkomst. Hierboven vergelijken we telkens een complexer model met een simpeler model. Indien we schrijven "(model4, model1, model2", "model3"), dan vergelijkt R model 1 tegen 4, model 2 tegen 1 enz.

```{r}
anova(model4, model1, model2, model3)
```

De tweede rij vergelijkt nu het nulmodel (`model1`) met het meest complexe model (`model4`). We krijgen een negatieve waarde voor "DF" en "Sum of Sq" omdat Model 1 minder predictoren heeft en ook minder goed past. Het verschil is statistisch significant. Dit interpreteren we nu als: model 4 is beter dan model 1.De derde rij vergelijkt `model2` (enkel `cpi` als predictor) met `model1` (het nulmodel). De resultaten zijn dezelfde als hierboven. De resultaten voor de laatste rij zijn ook dezelfde.

Let erop dat de namen die de `anova()` functie geeft aan de modellen niet noodzakelijk dezelfde zijn als de namen die je zelf geeft (model 1 voor anova is nu ons model 4).

Je kunt de fit van bepaalde modellen testen tegenover elkaar om zo stapsgewijs het beste model te vinden. Meestal zullen we meer complexe modellen vergelijken met meer simpele modellen. In de syntax gaan we dan van meest simpel naar meest complex model.
:::
