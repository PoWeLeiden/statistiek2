---
code-annotations: hover
---

# Logistische Regressie & Odds Ratios {#sec-logistic-regression-odds-ratios}

Logistische regressiemodellen worden gebruikt voor binaire afhankelijke variabelen.We maken hier gebruik van de Nederlandse survey voor ronde 9 van de [European Social Survey](https://www.europeansocialsurvey.org) (ESS). Deze dataset is op de ESS website beschikbaar in SPSS format (.sav). We kunnen de `view_df` functie in `sjplot` gebruiken om de variabelen en hun labels in de dataset te inspecteren. Zie @sec-recall-peeking-inside-data-objects

```{r}
#| eval: false

#Packages
library(rio)             #laden van data
library(sjPlot)          #overzichten van data objecten
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #resultaten van regressiemodellen

#Data
ESS9NL <- import("ESS9e03, Netherlands.sav")

#view_df example op subset van de dataset
ESS9NL |> 
  select(polintr, ppltrst) |> 
  sjPlot::view_df()
```

```{r}
#| echo: false
#| message: false
#| warning: false

#Packages
library(rio)             #laden van data
library(sjPlot)          #overzichten van data objecten
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #resultaten van regressiemodellen

#Data
ESS9NL <- import("data/ESS9e03, Netherlands.sav")

#view_df example op subset van de dataset

ESS9NL |> 
  select(polintr, ppltrst) |> 
  sjPlot::view_df()
```

De`view_df()` output toont dat er numerieke waarden zijn die geaasocieerd zijn met ontbrekende waarden (bv. respondenten die "Don't Know" antwoorden krijgen een score van 8 op `polintr`). Deze waarden werden al naar 'NA' omgezet zoals je kunt zien in onderstaande tabel en dus is er geen verdere data managament nodig. Zie [Section 4.2](https://poweleiden.github.io/statistiek1/data_04_missing_data.html#recoding-missing-data){target="_blank"} van het Statistiek 1 boek om deze leerstof op te frissen.

```{r}
table(ESS9NL$polintr)
```

::: callout-important
#### Waarschuwing!

Kijk altijd goed naar instructies van opdrachten alsook verdere informatie over de dataset (bv. het codeboek, of informatie over de dataset te verkrijgen met functies zoals `view_df()` of `attributes()`) om te weten welke data management stappen je moet zetten vooraleer je je analyse kan uitvoeren.
:::

## Logistische regressieanalyse

### Data Management

In dit voorbeeld zullen we eerst onderzoeken of gender (`gndr`) opkomst bij verkiezingen bepaalt (`vote`).

We kijken eerst of data management nodig is:

```{r}
#Variabele attributen
ESS9NL |> 
  select(gndr, vote) |> 
  view_df()

#Tabulation
table(ESS9NL$gndr)
table(ESS9NL$vote)
```

De onafhankelijke variabele heeft 2 categorieën en moet in een factor variabele worden omgezet. De afhankelijke variabele heeft 3 categorieën (Yes, No, Not Eligible). We maken hier een binaire factor variabele van door eerst de "Not Eligible" categorie op NA te zetten:

```{r}
#Factor maken
ESS9NL <- ESS9NL |>
  mutate(gndr = factorize(gndr), #<1> 
         vote = factorize(vote)) #<2>  

#not eligible op NA
ESS9NL <- ESS9NL |>
  mutate(vote = na_if(vote,"Not eligible to vote"))

```

1.  De categorie met de laagste numerieke waarde wordt hierbij de referentiecategorie. We gebruiken factorize gezien datawaarden labels hebben.
2.  We maken hier geen nieuwe variabele aan voor de gehercodeerde variabelen maar overschrijven de originele variabelen. Dit is doorgaans niet aangeraden voor studenten, gelukkig weten wij meestal wel waar we mee bezig zijn.

We checken de niveaus van de variabelen, in het bijzonder van de vote variabele:

```{r}
levels(ESS9NL$vote)
table(ESS9NL$vote)

```

De `vote` variabele is nu een factor variabele met "Yes" als de referentiecategorie. Dit is niet wat we willen gezien we stemmen willen voorspellen. Als we de variabele zo laten voorspelt het model of een persoon *niet* heeft gestemd. We veranderen dit met de relevel functie (zie @sec-relevelling).[^1]

[^1]: Met `factor()` zouden we direct in de syntax de volgorde van de niveaus aan kunnen duiden: `mutate(vote_binary = factor(vote, levels = c(2, 1), labels = c("Did not vote", "Voted"))`. Het gebruik van factor vermijdt een veelvoorkomnde fout besproken in volgend hoofdstuk.

```{r}
#Relevel de variabele
ESS9NL <- ESS9NL |> 
  mutate(vote = relevel(vote, "No"))

#en controleer het resultaat
levels(ESS9NL$vote)

```

`mutate(vote = relevel(vote, "No"))`

:   We gebruiken de relevel functie op de `vote` variabele. We creëren hier geen nieuwe variabele, maar overschrijven de oude. Je zou er ook voor kunnen kiezen een nieuwe variabele te maken. De categorie tussen dubbele aanhalingstekens zal de eerste categorie worden en dus de referentiecategorie in de regressie. We gebruiken het label "No" omdat de variabele reeds tot factor is getransformeerd (en dus niet de originele numerieke waarde '2').

Laten we nu kijken naar de `gndr` variabele:

```{r}
table(ESS9NL$gndr)
levels(ESS9NL$gndr)
```

Als we de niveaus bekijken zien we dat 'Male' als referentie zal worden genomen. Dit is prima, maar bij wijze van voorbeeld veranderen we dit hieronder naar 'Female'. We zien ook een derde categorie 'No answer'. Dit label werd gegeven aan de waarde in de variabele maar is leeg. R zal deze dus verwijderen in de analyses.

```{r}
ESS9NL <- ESS9NL |> 
  mutate(gndr = relevel(gndr, "Female"))

#controleer je codering
levels(ESS9NL$gndr)
```

::: callout-important
#### Waarschuwing!

De afhankelijke variabele voor een logistische regressie is een (factor) binaire variabele. Zorg ervoor dat de referentiecategorie de uitkomst is die je niet wil voorspellen en de hoogste categorie net die is die je wil voorspellen. Anders zal je interpretatie foutief zijn.
:::

### Logistic regressie uitvoeren

Het uitvoeren van logistische regressie in R is gelijkaardig aan lineare regressie. In plaats van de ingebouwde functie `lm()`, gebruiken we de eveneens ingebouwde `glm()` functie. De afkorting staat voor '**g**eneralized **l**inear **m**odel'.

```{r}
#Schat het model
Vote_model <- glm(vote ~ gndr, 
                data = ESS9NL, family = "binomial")

```

`Vote_model <-`

:   We slaan de resultaten op in een data object met naam naar keuze.

`glm(vote ~ gndr,`

:   We voeren de glm functie uit met vote als afhankelijke variabele, voorspeld (\~) door onze enige onafhankelijke variabele: gndr. We kunnen meerdere onafhankelijke variabelen toevoegen, gescheiden van elkaar met een '+' teken.

`data = ESS9NL,`

:   We geven aan welke dataset gebruikt wordt.

`family = "binomial")`

:   We verduidelijken de familie van modellen voor ons generalized linear model. Voor logistische regressie is dit "binomial". Dit gedeelte van de code blijft onveranderd. Zie de Veelvoorkomende Fouten appendix ( @sec-glm-factor) voor een error die je kunt tegenkomen als je dit gedeelte vergeet.

De resultaten bekijken we weer met de `summary()` functie:

```{r}
summary(Vote_model)
```

::: callout-note
#### Output uitleg

De output is gelijkaardig aan die van de lineaire regressie met `lm()`.

-   Call: Het model dat geschat werd
-   Deviance Residuals: beschrijvende statistieken over de residuals van het model.
-   Coefficients: De logistische regressiecoëfficiënten (Estimate), hun standaardfouten (Std. Error), en de teststatistiek (z-waarde; de Z-statistiek is gelijk aan $\frac{\textrm{Coefficient}}{\textrm{Std. Error}}$), en de p-waarde voor de z-statistiek (Pr(\>\|z\|). Symbolen m.b.t. statistische significantie vind je rechts van de p-waarde waar van toepassing. De interpretatie van de symbolen wordt uitgelegd in de legende onder de coëfficiënten ("Signif. Codes:").
-   (Dispersion parameter...): Te negeren.
-   Area that begins with Null deviance: Informatie over de fit van het model, besproken in een volgend hoofdstuk.
-   Number of Fisher Scoring Iterations: Aantal iteraties van het algoritme.
:::

We kunnen meerdere predictoren toevoegen aan het model op een gelijkaardige manier als bij lineaire regressie: door ze te scheiden met een `+` teken. Hier voegen we leeftijd (`agea`), vertrouwen in politici (`trstplt`), en links-rechts positie (`lrscale`) toe. data management voor deze variabelen is niet nodig: ze zijn continue en missing waarden zijn reeds als NA aangeduid.

```{r}
#Schat het model
Vote_model_mp <- glm(vote ~ gndr + agea + trstplt + lrscale, 
                data = ESS9NL, family = "binomial")

#Bekijk de output
summary(Vote_model_mp)

```

::: callout-warning
#### Interpretatie

Logistische regressiecoëfficiënten geven een schatting van de verandering in de log van de odds dat Y=1 als X met 1 eenheid stijgt. Ze zijn dus niet makkelijk direct te interpreteren. We kunnen ze wel gebruiken om iets over de richting van de relatie te zeggen. Een positive coëfficiënt toont dat de kans dat Y=1 stijgt als de onafhankelijke variabele stijgt. Een negatieve coëfficiënt toont dat de kans dat Y=1 daalt als de onafhankelijke variabele stijgt. Voor verdere interpretatie maak je best gebruik van de odds ratios (in minder mate), de gemiddelde marginale effecten (average marginal effects) (zie @sec-marginal-effects) of de voorspelde kansen (zie @sec-logit-predicted-probabilities) .

Voor dit voorbeeld:

-   Mannen hebben een grotere kans om te stemmen dan vrouwen, maar het verschil is niet statistisch signficant (p = 0.28).
-   Oudere respondenten hebben een grotere kans om te gaan stemmen en dit verband is statistisch signficant (p \< 0.001).
-   Respondenten met meer vertouwen in politici hebben een grotere kans om te gaan stemmen. deze relatie is statistisch significant (p \< 0.001).
-   Stemmen is meer waarschijnlijk naarmate respondten zich rechtser psitioneren op de ideologieschaal, maar dit effect is niet statistisch signficant (p = 0.74).
:::

## Odds Ratios

Logistische regressiecoëfficiënten kunnen omgezet worden in odds ratios die (iets) intuïtiever zijn om te interpereteren..

We kunnen de odds ratios en 95% betrouwbaarheidsintervallen verkrijgen met de `tidy` functie uit het `broom` package:

```{r}
# logistische regressiecoëfficiënten en hun betrouwbaarheidsintervallen
tidy(Vote_model_mp, conf.int = TRUE)

# odds ratios (i.e. 'exponentiële coëfficiënten') en hun betrouwbaarheidsintervallen
tidy(Vote_model_mp, conf.int = TRUE, exp = TRUE)

```

Zo lees je de syntax:

`tidy(Vote_model_mp`

:   We gebruiken de tidy functie op het model tussen haakjes.

`conf.int = TRUE`

:   We vragen R om de betrouwbaarheidsintervallen weer te geven. We kunnen 'FALSE' schrijven of deze code weglaten als we de betrouwbaarheidsintervallen niet willen.

`exp = TRUE)`

:   We vragen hier om de exponentiële (exponentiated) logistische regressiecoëfficiënten, oftewel de odds ratios. We kunnen 'FALSE' schrijven of deze code weglaten als we de logistische regressiecoëfficiënten willen.

::: callout-warning
#### Interpretatie

Voor de interpretatie van odds ratios zijn er 3 zaken waar je op moet letten.

Ten eerste, odds ratios vertellen ons iets over de relatieve *odds* dat Y = 1 (bv. iemand gaat stemmen). Dit is verschillend van de coëfficiënten. de coefficiënten zijn de *gelogde* versies van de relatieve odds..

Ten tweede, odds ratios zijn multiplicatief and worden geïnterpreteerd in termen van 1 in plaats van 0. Een odds ratio groter dan 1 betekent een hogere kans dat Y=1. Een odds ratio lager dan 1 betekent een lagere kans dat Y=1. Een odds ratio van 1 betekent dat er geen effect is. Een betrouwbaarheidsinterval voor een odds ratio waar 1 niet in voorkomt duidt een statistisch significant effect aan. Een odds ratio kan niet negatief zijn.

Ten derde interpreteren we ook de odds ratios met een multiplicatieve logica. In het voorbeeld vinden we dat de odds om te stemmen `r round(tidy(Vote_model_mp, exponentiate = T)[2,2],2)` *keer groter* zijn voor mannelijke respondeten dan vrouwelijke respondenten, ceteris paribus. het effect is wel niet significant. De odds om te stemmen vermenigvuldigen met 1.02 telkens leeftijd met 1 eenheid omhoog gaat (de andere onafhankelijke variabelen constant gehouden).
:::
