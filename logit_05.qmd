---
code-annotations: hover
---

# Assumpties van Logistische Regressie {#sec-logistic-regression-assumptions}

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

#specifieke packages voor testen assumpties
library(car)             #meerdere assumptie testen
library(ggResidpanel)    #assumpties testen met grafieken
library(expss)           #frequentietabellen maken

#algemene packages
library(rio)             #laden van data
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #data voor residuals en influential cases


#Data
ESS9NL <- import("data/ESS9e03, Netherlands.sav")
```

Ook logistische modellen rusten op assumpties. In dit hoofdstuk leren we na te gaan of aan deze assumpties voldaan is. In het bijzonder focussen we op de volgende assumpties:

-   Beperkte multicollineariteit
-   Lineariteit van de logit
-   Beperkte impact 'outliers' en 'influential cases'

We beginnen met het laden van relevante R packages en de data:

```{r}
#| eval: false

#specifieke packages voor testen assumpties
library(car)             #meerdere assumptie testen
library(ggResidpanel)    #assumpties testen met grafieken
library(expss)           #frequentietabellen maken

#algemene packages
library(rio)             #laden van data
library(tidyverse)       #data manipulatie en grafieken
library(broom)           #data voor residuals en influential cases

#Data
ESS9NL <- import("data/ESS9e03, Netherlands.sav")

```

We hebben natuurlijk een model nodig. We gebruiken `vote_model4` uit het vorige hoofdstuk waarin we de kans voorspellen dat iemand gaat stemmen op basis van informatie over gender, leeftijd, vertouwen in politici en links-rechtsideologie.

```{r}
#Data management
ESS9NL <- ESS9NL |>
  #Factor maken van categorische variabelen
  mutate(gndr = factorize(gndr), 
         vote = factorize(vote))  |> 
  #Not Eligible op missing zetten
  mutate(vote = na_if(vote,"Not eligible to vote")) |> 
  #Relevel van variabelen
  mutate(vote = relevel(vote, "No"), 
         gndr = relevel(gndr, "Female"))

#Subset van de data
ESS9NL_glm <- ESS9NL |>
  filter(complete.cases(vote,  gndr,  agea,  trstplt,  lrscale)) # <1> 

#Het model
Vote_model4 <- glm(vote ~ gndr + agea + trstplt + lrscale, 
                data = ESS9NL_glm, family = "binomial")

#Resultaten
summary(Vote_model4)
```

1.  We gebruiken een subset van de data met enkel complete observaties. Dit hebben we gedaan in het vorige hoofdstuk en is ook nuttig voor sommige asumptiechecks..

## Beperkte multicollineariteit

We kunnen nagaan of ons model onderhevig is aan te sterke multicollineariteit met de `vif()` functie uit het `car` package. Dit is gelijkaardig aan wat we deden voor lineaire regressie ( @sec-linear-no-excessive-multicollinearity). dezelfde vuistregels zijn van toepassing. Voor logistische regressiemodellen wordt een 'generalized VIF' berekend.

```{r}
vif(Vote_model4)
```

De resultaten duiden op geen problemen met multicollineariteit.

## Lineariteit van de logit

Logistische regressie verondersteld dat veranderingen in de log odds (de logit) lineair geassocieerd zijn met Y=1. Om de assumptie te checken gebruiken we de `augment()` functie uit het `broom` package. Deze functie creëert een dataframe met de variabelen gebruikt in het model, alsook belangrijke statistieken om assumpties te testen:

```{r}
augment(Vote_model4)
```

::: callout-note
#### Output uitleg

-   `vote` t.e.m. `lrscale`: Deze kolommen bevatten de geobserveerde waarden op de betreffende variabelen voor alle observaties gebruikt in het model.
-   `.fitted`: De voorspelde ('fitted') waarden op basis van de schattingen in het model in 'logit' vorm en dus niet in *probabiliteiten*.
-   `.resid`: De residuals (fouten/errors) voor elke observatie. Ook gekend als de "deviance residuals".
-   `.hat`: Diagonaal van de hat matrix (te negeren).
-   `.sigma`: Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)
-   `.cooksd`: Cook's D waarden (zie onder).
-   `.std.resid`: gestandaardiseerde residuals (zie onder).
:::

We zullen verder werken met de augment statistieken hier en voor outliers en influential cases dus maken we een nieuw dataobject met de resultaten:

```{r}
model4_augmented <- augment(Vote_model4, data = ESS9NL_glm)
```

`augment(Vote_model4, data=ESS9NL_glm)`

:   We voegen deze syntax toe aan de functie: `data = ESS9NL_glm`. De reden is dat we zo een dataobject creëren met de augment-statistieken, de variabelen gebruikt in het model, *en* alle overige variabelen in de originele ESS9 dataset. Dit kan nuttig zijn voor bepaalde handelingen. We kunnen enkel de overige variabelen toevoegen als de datasets evenveel rijen hebben. Dit is niet het geval als er missing waarden zijn en het model minder observaties heeft dan de originele dataset. Vandaar dat we eerst een `complete.cases`data subset hebben gemaakt hierboven.

Om lineariteit te checken plotten we de logit die `augment` heeft berekend telkens tegenover de onafhankelijke variabelen in het model, specifiek de continue onafhankelijke variabelen. We maken een scatterplot met een loess-lijn en `.fitted`geplot op de y-)as.

```{r}
# Leeftijd
ggplot(model4_augmented, aes(x = agea, y = .fitted)) + 
  geom_point() + 
  geom_smooth(method = 'loess')

# Vertrouwen in politici
ggplot(model4_augmented, aes(x = trstplt, y = .fitted)) + 
  geom_point() + 
  geom_smooth(method = 'loess')

# LR-ideologie
ggplot(model4_augmented, aes(x = lrscale, y = .fitted)) + 
  geom_point() + 
  geom_smooth(method = 'loess')
```

We gaan na of de loess lijn sterke afwijkingen van een lineaire relatie vertoont. Dit lijkt hier niet het geval.

## Beperkte impact outliers en influential cases

Met de `augment` functie hebben we reeds de gestandaardiseerde residuals en Cook's D waarden opgeslagen in een dataobject. We kijken eerst naar outliers, dan naar invloedrijke casussen

### Outliers

We bekijken eerst de descriptieve statistieken voor de gestandaardiseerde residuals:

```{r}
summary(model4_augmented$.std.resid)
```

De output helpt ons na te gaan of er observaties zijn die de drempelwaarden (\|1.96\|, \|2.58\|, \|3.29\|) overschrijden. We zien dat de hoogste drempelwaarden (\|2.58\|, \|3.29\|) niet overschreden worden maar de laagste van 1.96 wel (het minimum is -2.398). Nu moeten we nog weten hoeveel observaties deze waarde overschrijden.

Dit kunnen we nagaan door net zoals bij lineaire regressie een dummy variabele te maken (0 = `.std.resid` \< \|1.96\|, 1 = `.std.resid` \> \|1.96\|) en de frequentietabel te inspecteren. [^logit_05-1] (zie @sec-linear-investigating-outliers voor de syntax voor de andere drempelwaarden)

[^logit_05-1]: We zouden ook het gemiddelde van de 0/1 variabele kunnen berekenen gezien dit ons de proportie zou geven voor de '1' cases.

```{r}
#dummy variabele maken: 
model4_augmented <- model4_augmented |>
  mutate(SRE1.96 = case_when(
    .std.resid > 1.96 | .std.resid < -1.96  ~ 1,
    .std.resid > -1.96 & .std.resid < 1.96 ~ 0
  ))

#proportie opzoeken 
fre(model4_augmented$SRE1.96)


```

5.7% van de observaties liggen buiten het +/- 1.96 interval. Om te onderzoeken of deze outliers de parameters van het model beïnvloeden, kunnen we het model opnieuw schatten zonder deze observaties. We doen dit door in onze dataset enkel observaties met een waarde van '0' op SRE1.96 op te nemen. We zouden dan de resultaten van het model met en het model zonder outliers vergelijken:

```{r}
Vote_model41.96 <- glm(vote ~ gndr + agea + trstplt + lrscale, 
                data = subset(model4_augmented, SRE1.96 == 0), 
                family = "binomial")
```

### Influential cases

Om te onderzoeken of er invloedrijke casussen aanwezig zijn inspecteren we de Cook's D waarden van de observaties in het model. We kunnen de descriptieve statistieken bekijken en het Cook's D plot via de `resid_panel()` funtie uit het `ggResidpanel` package. We hanteren dezelfde vuistregels als voor lineaire regressie (zie @sec-linear-investigating-influential-cases).

```{r}
#Summary of the Cook's D values
summary(model4_augmented$.cooksd)

#Plot
resid_panel(Vote_model4, plots = c('cookd'))
```

Beide methoden wijzen op lage Cook's D waarden; de maximum waarde is slechts 0.017. Indien we hogere waarden zouden vinden, zouden we deze observaties uit de dataset kunnen filteren en het model opnieuw schatten om resultaten met en zonder invloedrijke casussen te vergelijken 
