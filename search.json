[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistische analyse en presentatie met R",
    "section": "",
    "text": "Voorwoord\nDit boek bevat het R-materiaal voor de cursus Statistiek II.\nWe hebben het boek in drie delen verdeeld:\nDe drie onderdelen presenteren de belangrijkste syntax om de aangeleerde analysemethoden uit te voeren. De syntax wordt stapsgewijs uitgelegd en de logica van de verschillende functies wordt toegelicht. We voorzien de syntax ook van bijkomende commentaar waar nodig (in tekst met grijze achtergrond of in commentaarvakjes die je ziet als je met je computermuis hierop staat). Een voorbeeld:\n# Packages\nlibrary(tidyverse)   #voor data management en grafieken\n\n# Een linear regressiemodel\n1model1 &lt;- lm(mpg ~ drat, data = mtcars)\n\n\n1\n\nSommige opmerkingen zetten we in deze tekstvakjes, vooral als ze wat langer zijn of wanneer ze zaken die al behandeld zijn herhalen.\nDit overzicht bevat ook algemene richtlijnen over hoe de resultaten van statistische analyses te presenteren en te rapporteren. Je vindt de resultaten (‘output’) van analyses en bijkomende uitleg in volgende tekstvakken:\nHet laatste deel van het boek bevat twee bijlagen met bijkomende informatie. Appendix A geeft een overzicht van veel voorkomende fouten (‘Common Errors’) bij het uitvoeren van de analyses en bij het omzetten van een R Markdown bestand naar een html bestand (nodig voor de opdrachten). Appendix B geeft een overzicht van de R ‘libraries’ of ‘packages’ (en hun functies) die we gebruiken in deze cursus en de week waarin ze worden geïntroduceerd, en bevat ook het script waarmee je alle packages in 1 keer op je computer kunt installeren."
  },
  {
    "objectID": "index.html#statistiek-i-boek",
    "href": "index.html#statistiek-i-boek",
    "title": "Statistische analyse en presentatie met R",
    "section": "Statistiek I Boek",
    "text": "Statistiek I Boek\nDe inhoud van dit boek bouwt verder op de leerstof van Statistiek 1. Data management (bv. filteren, hercoderen van variabelen, ontbrekende waarden aanduiden) blijft ook van belang voor dit vak. Deze leerstof kun je raadplegen in het Statistiek 1 boek. Soms verwijzen we in dit boek ook naar specifieke onderdelen van Statistiek 1 waar dit relevant is."
  },
  {
    "objectID": "index.html#overzicht-per-week",
    "href": "index.html#overzicht-per-week",
    "title": "Statistische analyse en presentatie met R",
    "section": "Overzicht per week",
    "text": "Overzicht per week\nVoor elke week in de cursus moet je relevante hoofdstukken lezen. In 2024-2025 is dit:\n\n\n\n\n\n\n\n\nWeek\nSectie\nHoofdstukken\n\n\n\n\n1\nLineaire Modellen\nChapter 1 ; Chapter 8 (8.1 & 8.2)\n\n\n2\nLineaire Modellen\nChapter 2 ; Chapter 3 ; Chapter 5 (5.1 & 5.2) ; Chapter 8 (8.3)\n\n\n3\nLineaire Modellen\nChapter 4 ; Chapter 5 (5.3) ; Chapter 6 ; Chapter 8 (8.3 - 8.6)\n\n\n4\nLineaire Modellen\nChapter 7\n\n\n5\nLogistische Regressie\nChapter 9 ; Chapter 10 ; Chapter 11 ; Chapter 14\n\n\n6\nLogistische Regressie\nChapter 12 ; Chapter 13\n\n\n7\nInteracties\nChapter 15 ; Chapter 16 ; Chapter 17"
  },
  {
    "objectID": "part_linear.html",
    "href": "part_linear.html",
    "title": "Lineaire Statistische Modellen",
    "section": "",
    "text": "Dit onderdeel richt zich op het uitvoeren van lineaire statistische analyses. Je leert…\n\nde correlatiecoëfficiënt tussen 2 continue variabelen te berekenen en interpreteren.\neen lineair regressiemodel uit te voeren met zowel continue als categorische onafhankelijke variabelen.\nschendingen van assumpties van lineaire modellen na te gaan."
  },
  {
    "objectID": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "href": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.1 Ter herinnering: data objecten",
    "text": "1.1 Ter herinnering: data objecten\nWe kunnen de inhoud van een data object op verschillende manieren bekijken. Vaak gaat een dataset gepaard met een codeboek dat we kunnen inkijken, maar we kunnen ook data verder inspecteren met R. We kunnen bijvoorbeeld gewoon de naam van het data object (hier: ‘demdata’) typen om vervolgens de inhoud te printen. De ‘tibble’ transformatie maakt dit overzichtelijker:\n\ndemdata\n\n# A tibble: 179 × 41\n   country_name  year v2x_polyarchy v2x_libdem v2x_egaldem v2cacamps v2caviol\n   &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Mexico        2020         0.647      0.412       0.369     1.53     0.023\n 2 Suriname      2020         0.761      0.627       0.56      0.12    -0.813\n 3 Sweden        2020         0.908      0.879       0.83     -2.08    -2.37 \n 4 Switzerland   2020         0.894      0.851       0.832    -1.70    -2.66 \n 5 Ghana         2020         0.72       0.614       0.534    -0.441   -0.008\n 6 South Africa  2020         0.703      0.578       0.477     0.092    0.395\n 7 Japan         2020         0.832      0.743       0.75     -1.54    -1.95 \n 8 Myanmar       2020         0.436      0.271       0.253     0.886    1.28 \n 9 Russia        2020         0.262      0.103       0.203     0.558    0.195\n10 Albania       2020         0.485      0.409       0.358    -0.501   -0.119\n# ℹ 169 more rows\n# ℹ 34 more variables: e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;,\n#   e_regionpol_6C &lt;dbl&gt;, v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;,\n#   bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;, dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;,\n#   TypeSoc2005 &lt;dbl&gt;, TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;,\n#   TYPEDEMO1984 &lt;dbl&gt;, TYPEDEMO2007 &lt;dbl&gt;, Fragile2006 &lt;dbl&gt;,\n#   Typeregime2006 &lt;dbl&gt;, TYPEGOV2007 &lt;dbl&gt;, CPI8085 &lt;dbl&gt;, …\n\n\nDe ‘tibble’ transformatie maakt de output duidelijker. We zien nu een overzicht van de eerste variabelen in de dataset (de kolommen) en de eerste observaties (rijen).\nWe zouden ook de voorkeur kunnen geven aan een overzicht van alle variabelen in de dataset en hun kenmerken (‘attributes’). In Statistiek 1 (zie here) werd hiervoor de str() functie gebruikt. Hier gebruiken we glimpse() als een vereenvoudigde manier om dit te doen. Het resultaat is een overzicht van alle 41 variabelen in de dataset. We doen dit hier voor een verkorte versie van de dataset om minder lange output te verkrijgen.\n\n#Een kleinere dataset door selectie van beperkt aantal variabelen\ndemdata_sub &lt;- demdata |&gt; \n  select(v2x_egaldem, TypeSoc2005, HDI2005, TYPEDEMO1984, gini_2019)\n\nglimpse(demdata_sub)\n\nRows: 179\nColumns: 5\n$ v2x_egaldem  &lt;dbl&gt; 0.369, 0.560, 0.830, 0.832, 0.534, 0.477, 0.750, 0.253, 0…\n$ TypeSoc2005  &lt;dbl&gt; 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, …\n$ HDI2005      &lt;dbl&gt; 0.829, 0.774, 0.956, 0.955, 0.553, 0.674, 0.953, 0.583, 0…\n$ TYPEDEMO1984 &lt;dbl&gt; 2, 1, 2, 2, 1, 1, 2, 1, NA, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1,…\n$ gini_2019    &lt;dbl&gt; NA, NA, 26.5, 30.1, NA, NA, NA, NA, 32.5, 37.5, NA, NA, 4…\n\n\nTen slotte kunnen we de view_df() functie gebruiken uit het sjPlot package om de namen van alle variabelen te zien, hun labels (indien van toepassing), de mogelijke waarden voor deze variabelen en de labels van deze waarden (indien van toepassing). De informatie wordt in het Viewer venster (standaard rechtsonder) weergegeven. Als je klikt op “Show in new window” krijg je een grotere weergave in een tab van je browser.\n\nview_df(demdata_sub)\n\n\nData frame: demdata_sub\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nv2x_egaldem\n\nrange: 0.0-0.9\n\n\n2\nTypeSoc2005\nType of human development, (3-cat, classified from\nHDI) (UNDP 2008)\n1\n2\n3\nLow human development\nMedium human development\nHigh human development\n\n\n3\nHDI2005\nHuman Development Index (HDI), 2005 100-pt scale\n(UNDP 2007)\nrange: 0.3-1.0\n\n\n4\nTYPEDEMO1984\nType of democracy, 1984\n1\n2\nAutocracies\nDemocracies\n\n\n5\ngini_2019\n\nrange: 22.6-48.0\n\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nview_df() creëert output met de volgende kolommen:\n\nName: Naam van de variabele\nLabel: Label van de variabele, indien aanwezig in de dataset. Doorgaans een korte inhoudelijke beschrijving van de variabele.\nValues: Indien de variabele continu is vind je hier het minimum en maximum van de variabele in de dataset “range: X-X”. Bijvoorbeeld, de v2x_egaldem variabele reikt van 0 tot 0.9. Indien de variabele slechts enkele discrete waarden bevat, worden deze getoond (zie bv. TypeSoc2005).\nValue Labels: Sommige variabelen hebben labels voor de specifieke waarden die ze aannemen. Dit label beschrijft waar de cijferwaarde voor staat. Bijvoorbeeld, observaties met een 1 voor TYPEDEMO1984 zijn autocratieën en observaties die een 2 scoren zijn democratieën.\n\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nview_df() is een handige functie om een overzicht van je dataset te hebben, maar als je dataset veel variabelen heeft wordt veel output geproduceerd. Voeg dus view_df(data) niet toe aan je R Markdown (.rmd) bestand wanneer je je taak inlevert. Gebruik de functie voor jezelf, maar verwijder dan deze syntax om je ingeleverde taak overzichtelijk te houden."
  },
  {
    "objectID": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "href": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.2 Visualisatie met een scatterplot",
    "text": "1.2 Visualisatie met een scatterplot\nIn ons voorbeeld onderzoeken we de relatie tussen economische ongelijkheid en het niveau van electorale democratie in landen.\nDe variabele gini_2019 meet het niveau van economische ongelijkheid en heeft waarden tussen 0 en 100 (hogere waarden = meer ongelijkheid).1 De variabele v2x_polyarchy meet het niveau van electorale democratie in een land. De variabele is continue met een bereik tussen 0 en 1. Hogere waarden betekenen een hoger niveau van democratie.\nWe kunnen de relatie tussen deze twee continue variabelen onderzoeken met behulp van een scatterplot. Zie Hoofdstuk 8 in het Statistiek I boek voor meer informatie over ggplot(), ook over de opties om plots mooier te maken.\n\nggplot(demdata, aes(x=gini_2019, y=v2x_polyarchy)) + \n  geom_point() + \n  labs(title = \"Economische ongelijkheid en electorale democratie\", \n       x = \"Gini Coefficient (2019)\", \n       y = \"Electorale Democratie (2020)\") + \n  scale_x_continuous(breaks=seq(from=25, to=45, by=5))\n\nWarning: Removed 109 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output bevat een waarschuwing: “Warning: Removed 109 rows containing missing values (`geom_point()`).”. Dit is geen reden tot zorg en komt voor omdat er observaties zijn die geen waarden hebben voor een van de variabelen of beide variabelen. Jammergenoeg geeft R wel meer waarschuwingen die weinig belang hebben.\n\n\nZo lees je bovenstaande syntax:\n\nggplot(\n\nHier vertellen we R dat we de data willen plotten met behulp van het ggplot2 package, onderdeel van het tidyverse package.\n\ndemdata\n\nDit is de naam van het data object waaruit we variabelen willen plotten. Deze naam verander je naar je eigen dataset.\n\naes(x=gini_2019, y=v2x_polyarchy)\n\nHier vertellen we R hoe de grafiek eruit moet zien (aes= “aesthetic mapping”). We plaatsen “gini_2019” op de x-as en “v2x_polyarchy” op de y-as. Het is gebruikelijk om de afhankelijke variabele op de y-as en de onafhankelijke variabele op de x-as te plaatsen.\n\ngeom_point()\n\nHier bepalen we welk plot we willen, namelijk een puntenwolk (‘point’). Elk punt op de grafiek geeft een observatie in de dataset weer. De positie van de observatie wordt bepaald door de waarden op onze twee variabelen.\n\nlabs(...)\n\nHier geven we titels aan de grafiek en assen.\n\nscale_x_continuous(breaks=seq(from=25, to=45, by=5))\n\nHier vragen we R om de x-as te laten lopen van 25 tot 45 (in lijn met de geobserveerde waarden voor gini_2019 in de dataset) en om de 5 waarden een aanduiding te maken op de as. Dit verduidelijkt de visualisatie.2\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nIn dit voorbeeld hebben we de schaal van de x-as aangepast om een duidelijkere weergave te bekomen. Dit is niet altijd nodig, de standaard optie waarbij deze syntax-regel wordt weggelaten produceert vaak al goede resultaten. Let er ook op dat je deze syntax niet gewoon overneemt, zeker als de variabele die je op de x-as wil plotten anders geschaald is (bv. van 0 tot 10). Dit kan anders vreemde resultaten opleveren. Denk eraan bij het overnemen van syntax uit dit boek: copy, paste, en update.\n\n\nZie Section 8.1 voor verdere instructies over het maken van duidelijke scatterplots en richtlijnen om een plot te beschrijven."
  },
  {
    "objectID": "linear_01.html#covariantie",
    "href": "linear_01.html#covariantie",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.3 Covariantie",
    "text": "1.3 Covariantie\nIn bovenstaande figuur zagen we meer landen in de linkerbovenhoek dan in de linkeronderhoek, en meer lagere waarden voor electorale democratie naarmate we hogere waarden voor gini 2019 zien. Dit lijkt te wijzen op een negatieve relatie: landen met lage ongelijkheid scoren doorgaans hoog op democratie.\nNu gebruiken we de covariantie statistiek om de relatie tussen onze twee variabelen duidelijker te vatten en onze interpretatie van bovenstaande figuur te verifiëren. We maken gebruik van de cov() functie in R. Deze functie is ingebouwd in R en kunnen we gebruiken zonder extra packages te laden.\nWe nemen “gini_2019” als x-variabele en “v2x_polyarchy” als y-variabele in lijn met ons scatterplot. De covariantiestatistiek is echter symmetrisch en we zouden dezelfde uitkomst verkrijgen als we de variabelen zouden omdraaien.\n\ncov(x = demdata$gini_2019, \n    y = demdata$v2x_polyarchy,\n    use = \"complete.obs\")   \n\n[1] -0.560385\n\n\nDe syntax betekent het volgende:\n\ncov(\n\nDe naam van de functie. Deze wordt toegepast op de variabelen gespecificeerd tussen de haakjes.\n\nx = demdata$gini_2019,\n\nVerduidelijkt dat we de “gini_2019” variabele uit het data object “demdata” als x-variabele willen we beschouwen.\n\ny = demdata$v2x_polyarchy,\n\nVerduidelijkt dat we de “v2x_polyarchy” variabele uit het data object “demdata” als y-variabele willen we beschouwen.\n\nuse= \"complete.obs\")\n\nHier verduidelijken we dat we enkel observaties met non-missing waarden in de berekening willen meenemen.\n\n\nDe covariantie is -0.56. Dit is in lijn met onze interpretatie van het scatterplot. Er is een negatieve relatie tussen onze variabelen, hogere waarden voor ongelijkheid zijn doorgaans geassocieerd met lagere waarden voor democratie."
  },
  {
    "objectID": "linear_01.html#sec-correlation-coefficients",
    "href": "linear_01.html#sec-correlation-coefficients",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.4 Correlaties",
    "text": "1.4 Correlaties\nWe kunnen ook de correlatiecoëfficiënt gebruiken om de relatie tussen onze continue variabelen te onderzoeken. De correlatie is een gestandaardiseerde maatstaf in tegenstelling tot de covariantie.\nEr bestaan meerdere correlatiecoëfficiënten. Doorgaans gebruiken we de Pearson correlatiecoëfficiënt voor continue variabelen (vaak aangeduid met een schuine letter r: \\(r\\)). We maken gebruik van de cor.test() functie, die ingebouwd is in R.3 Ook de correlatie is een symmetrische maatstaf. Je krijgt dus dezelfde uitkomst wanneer je de x en y-variabelen zou omdraaien.\n\ncor.test(x = demdata$gini_2019, \n         y = demdata$v2x_polyarchy, \n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nZo lees je de syntax:\n\ncor.test(\n\nDe naam van de functie. Deze wordt toegepast op de variabelen gespecificeerd tussen de haakjes.\n\nx = demdata$gini_2019\n\nVerduidelijkt dat we de “gini_2019” variabele uit het data object “demdata” als x-variabele willen we beschouwen.\n\ny = demdata$v2x_polyarchy\n\nVerduidelijkt dat we de “v2x_polyarchy” variabele uit het data object “demdata” als y-variabele willen we beschouwen.\n\nmethod = \"pearson\")\n\nVertelt R dat we de Pearson correlatiecoëfficiënt willen gebruiken. We kunnen een andere methode vragen door bijvoorbeeld “method = spearman” te typen.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nIn R toont de output het volgende:\n\n‘t =’: de t-waarde of t-statistiek van de correlatie\n‘df =’: de vrijheidsgraden (‘degrees of freedom’)\n‘p-value =’: de p-waarde voor de schatting (i.e., de kans dat we deze of een grotere t-waarde zouden uitkomen als de nulhypothese (correlatiecoëfficënt is in werkelijkheid gelijk aan 0) waar zou zijn en de assumpties van het model correct zijn).\n‘95 percent confidence interval:’: het 95% betrouwbaarheidsinterval voor de correlatiecoëfficiënt\n‘cor’: de correlatiecoëfficiënt\n\n\n\nDe correlatiecoëfficiënt is hier -0.35 (afgerond op 2 decimalen). Hoe interpreteren we dit cijfer?\n\n\n\n\n\n\nInterpretatie\n\n\n\nCorrelatiecoëfficiënten liggen tussen -1 en +1, waarbij:\n\n-1 = een perfect negatieve lineaire relatie. Alle observaties vallen op een neerwaarts lopende lijn in een scatterplot.\n0 = geen lineaire relatie\n+1 = een perfect positieve lineaire relatie. Alle observaties vallen op een opwaarts lopende lijn in een scatterplot.\n\nEen positieve relatie houdt in dat 1 variabele stijgt als de andere stijgt. Een negatieve relatie betekent dat 1 variabele verwacht wordt te dalen als de andere variabele stijgt.\nCorrelatiecoëfficiënten geven naast de richting ook de sterkte van een relatie aan. De volgende vuistregels, gebaseerd op Cohen (1988), worden vaak gebruikt:\n\nr \\(&lt;\\) 0.1: Heel klein\n0.1 \\(&lt;=\\) 0.3: Klein\n0.3 \\(&lt;=\\) 0.5: Gemiddeld\nr \\(&gt;=\\) 0.5: Groot\n\nIn ons voorbeeld is de correlatie gemiddeld.\nTen slotte: De bovenstaande vuistregels helpen bij het interpreteren van de correlatiecoëfficiënt (en zijn voldoende voor dit vak). Besprekingen in papers moeten doorgaans diepgaander zijn (bv. sterk in vergelijking met andere studies, andere effecten enz.).\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Erlbaum Associates."
  },
  {
    "objectID": "linear_01.html#bivariate-lineaire-regressie",
    "href": "linear_01.html#bivariate-lineaire-regressie",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.5 Bivariate lineaire regressie",
    "text": "1.5 Bivariate lineaire regressie\nDe laatste manier waarop we de bivariate relatie tussen twee continue (interval/ratio) variabelen kunnen onderzoeken is met een bivariaat regressiemodel.4.\nHier gebruiken we wederom electorale democratie als afhankelijke variabele en gini als onafhankelijke variabele. In dit geval is welke variabele we als afhankelijke en welke we als onafhankelijke beschouwen sterk bepalend voor het resultaat.\n\n1.5.1 Analyse en output\n\nm1 &lt;- lm(v2x_polyarchy ~ gini_2019, data = demdata)\n\nDe syntax lees je als volgt:\n\nm1 &lt;-\n\nWe kiezen hier de naam voor ons model: ‘m1’. Dit kun je veranderen voor eigen doeleinden. R zal de resultaten van onze regressieanalyse opslaan in een object met deze naam. In principe hoef je de resultaten niet in een data object op te slaan, maar dit is wel gebruikelijk omdat we de resultaten vaak verder gebruiken en we dan naar dit object kunnen verwijzen.\n\nlm(\n\nDit is de functie voor lineaire regressie: lm = linear (regression) model.\n\nv2x_polyarchy ~ gini_2019,\n\nDe variabele links van de tilde (“~”) is de afhankelijke variabele. Rechts vinden we de onafhankelijke variabele.\n\ndata = demdata)\n\nHier verduidelijken we welke dataset gebruikt wordt (in dit geval demdata). Dit gedeelte komt altijd aan het einde.\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nEr is een belangrijk verschil tussen cor.test()/cov() enerzijds en lm()anderzijds. Bij de ene kun je de x en y variabelen omwisselen en dezelfde uitkomst verkrijgen, bij lm kan dit niet. De beslissing over welke variabele je afhankelijke is bij lineaire regressie, is dus belangrijk.\n\n\nWe kunnen de resultaten bekijken door de naam van ons model in de console te typen en enter te drukken:\n\nm1\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nCoefficients:\n(Intercept)    gini_2019  \n    1.06031     -0.01186  \n\n\nDit geeft ons de regressiecoëfficiënten voor de constante en de onafhankelijke variabele. De informatie die we krijgen is zeer beperkt.5 Het is gebruikelijker om de output te bekijken met de summary() functie aangezien deze meer informatie geeft:\n\nsummary(m1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5389 -0.1502  0.0903  0.1668  0.3965 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.060311   0.136512   7.767  5.8e-11 ***\ngini_2019   -0.011859   0.003897  -3.043  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2225 on 68 degrees of freedom\n  (109 observations deleted due to missingness)\nMultiple R-squared:  0.1199,    Adjusted R-squared:  0.1069 \nF-statistic: 9.262 on 1 and 68 DF,  p-value: 0.003325\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nIn R toont de output het volgende:\n\n“Call”: Het regressiemodel dat geschat is.\n“Residuals”: Informatie over de residuals van het model (behandeld in verdere hoofdstukken).\n“Coefficients”: Dit zijn de regressiecoëfficiënten voor het model, waaronder…\n\nEstimate: De coëfficiënt voor elke term in het model. Bv. voor de constante (“(Intercept)” = 1.060311) en de onfahankelijke variabele (“gini_2019” = -0.0118\nStd. Error: de standaardfout van de coëfficiënt\nt value: De t-waarde of t-statistiek van de coëfficiënt\nPr(&gt;|t|): De p-waarde die bij de t-statistiek hoort. Voor meer informatie, zie Chapter 3 .\n\nHet onderste gedeelte van de output gaan over de ‘fit’ van het model, behandeld in Chapter 6 .\n\n\n\nDe coëfficiënt voor economische ongelijkheid was negatief, net zoals de covariantie en correlatie. Alle drie vatten de statistieken op hun manier de negatieve lineaire relatie tussen de variabelen.\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe Estimate kolom bevat de waarden voor de coëfficiënten van het model:\n\n(Intercept): Wat is de verwachte waarde voor de afhankelijke variabele als de onafhankelijke variabele in het model de waarde 0 aanneemt? Hier vinden we dat bij 0 ongelijkheid, de verwachte democratiescore gelijk is aan 1.06. Het intercept (of de constante) is niet altijd realistisch, bijvoorbeeld wanneer een predictor 0 niet kan aannemen in de praktijk of wanneer de schatting van de afhankelijke het werkelijke bereik ervan overschrijdt (democratiescores gemeten hier hebben een minimum van 0 en een maximum van 1)\nCoëfficientën voor continue onafhankelijke variabelen (bv. gini_2019): De coëfficiënt geeft de verwachte verandering in de afhankelijke variabele Y weer wanneer de onafhankelijke variabele X met 1 eenheid stijgt. Hier zien we dat electorale democratie verwacht wordt met-0.01 punten te dalen als ongelijkheid met 1 punt stijgt. Zie Section 8.3 voor meer informatie over rapportage in taken en papers.\n\nDe coëfficiënt voor gini_2019 is -0.01. Wat wil dit zeggen over de sterkte van het effect? Regressiecoëfficiënten zijn niet gestandaardiseerd zoals de correlatiecoëfficiënt dus zijn er geen vuistregels te hanteren. In latere hoofdstukken bespreken we gestandaardiseerde regressiecoëfficiënten Section 4.2 en voorspelde waarden Chapter 5). Deze kunnen helpen bij de interpretatie over de sterkte van het effect, maar (zoals bij de correlatie) zal een bespreking van de sterkte ook in moeten gaan op andere studies, de context etc.\n\n\n\n\n1.5.2 Regressielijn in een scatterplot\nDe regressielijn wordt vaak toegevoegd aan een scatterplot. Dit kunnen we als volgt doen:\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Economische ongelijkheid en electorale democratie\", \n       x = \"Gini Coëfficiënt (2019)\", \n       y = \"Electorale Democratie (2020)\") +  \n  scale_x_continuous(breaks = seq(from = 25, to = 45, by = 5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 109 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 109 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDe syntax is dezelfde als voor ons eerdere scatteplot met één toevoeging:\n\ngeom_smooth(method = \"lm\") +\n\nHier vragen we R om een lijn toe te voegen die de relatie tussen de twee variabelen weergeeft. We vragen hier specifiek om de lineaire regressielijn via method = \"lm\". We krijgen een lijn en ook het betrouwbaarheidsinterval voor de schatting in het grijs."
  },
  {
    "objectID": "linear_01.html#footnotes",
    "href": "linear_01.html#footnotes",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "",
    "text": "Het theoretische bereik van de variabele is van 0 tot 100, maar in de praktijk observeren we enkel waarden tussen 22.6 en 48.↩︎\nJe kunt meer leren over de seq() command als je ?seq() typt in de console en enter tikt.↩︎\nAls je meerdere correlatiecoëfficiënten tegelijkertijd wil onderzoeken zou je het correlation package kunnen gebruiken (webpage). Je hebt dit package echter niet nodig voor deze cursus.↩︎\nZoals we verder in de cursus zien kunnen we ook binaire/categorische onafhankelijke variabelen gebruiken om een continue variabele te voorspellen in een lineaire regressie.↩︎\nWe kunnen de coëfficiënten ook opvragen met de coef() functie. Bijvoorbeeld: “coef(m1)” zou ons ook gewoon de coëfficiënten geven. In verdere hoofdstukken zullen we nog een functie zien om de output te bekijken: de tidy() functie uit het broom package.↩︎"
  },
  {
    "objectID": "linear_02.html#data-management-converteren-naar-een-factor-variabele",
    "href": "linear_02.html#data-management-converteren-naar-een-factor-variabele",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "2.1 Data Management: Converteren naar een factor variabele",
    "text": "2.1 Data Management: Converteren naar een factor variabele\nVia lineaire regressieanalyse kunnen we een continue afhankelijke variable ook voorspellen aan de hand van binaire (2 waarden) en categorische (3 of meer waarden) variabelen.\nOm deze variabelen te gebruiken in een regressiemodel moeten ze toegevoegd worden als dichotome of “dummy” variabelen. Als de variabele binair is, wordt 1 dummy gebruikt, als de variabelen meer categorieën kent, worden meerdere dummies gebruikt.1 R voegt automatisch dummies toe voor factor variabelen, dus transformeren we binaire en categorische variabelen naar factor variabelen voor we ze in een regressie analyse gebruiken.2\nIn dit voorbeeld maken we gebruik van de variabele “TYPEDEMO1984”. Deze binaire variabele toont of een land een democratie of autocratie was in het jaar 1984. De variabele is numeriek opgeslaan (dit kunnen we controleren met behulp van de functie class()). De waarde 1 staat voor autocratie, de waarde 2 voor democratie.\n\n#Informatie over type variabele: \nclass(demdata$TYPEDEMO1984)\n\n[1] \"numeric\"\n\n#simpele tabel\ntable(demdata$TYPEDEMO1984)\n\n\n 1  2 \n86 57 \n\n\nAangezien de variabele numeriek is, transformeren we deze eerst naar een factor variabele. We kunnen dit doen met de ingebouwde factor() functie (zie Statistiek I, 1.6.3) of met de factorize() functie afkomstig uit het rio package. Deze laatste functie is vooral handig als de waarden labels hebben zoals hier het geval is ( 1 = “Autocratie”, 2 = “Democratie”). Als er geen labels zijn, moet je factor() gebruiken gezien factorize() in dat geval niet de juiste uitkomsten geeft. Zie Section A.2 voor meer informatie.\nDe labels kun je zien met behulp van de view_df() functie uit het sjPlot package (zie Section 1.1) of door gebruik te maken van de ingebouwde functie attributes() (vooraleer je transformeert naar factor): attributes(demdata$TYPEDEMO1984). Daarbij kijk je of er informatie is waar “$labels” staat.\n\nattributes(demdata$TYPEDEMO1984)\n\n$label\n[1] \"Type of democracy, 1984\"\n\n$format.stata\n[1] \"%10.0g\"\n\n$labels\nAutocracies Democracies \n          1           2 \n\n\nWe gebruiken factorize() gezien de waarden van onze variabelen labels hebben (1 = “Autocratie”, 2 = “Democratie”). We kijken ook na of de functie gelukt is.\n\n# transformeren naar factor\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984))\n\n#Niveaus (levels) bekijken en tabel om te checken\nlevels(demdata$TYPEDEMO1984)\n\n[1] \"Autocracies\" \"Democracies\"\n\ntable(demdata$TYPEDEMO1984)\n\n\nAutocracies Democracies \n         86          57 \n\n\nDe syntax is eenvoudig:\n\nfactorize(\n\nNaam van functie die wordt toegepast op variabele tussen haakjes.\n\nTYPEDEMO1984\n\nAangeduide variabele. Het laagste numerieke niveau van deze variabele zal als eerste niveau van de factor gebruikt worden en dus als referentiecategorie.\n\n\nDezelfde procedure wordt gehanteerd voor een categorische variabele met 3 of meer categorieën. Bijvoorbeeld, de variabele Typeregime2006 geeft weer of een land een liberale democratie was (=1), een electorale democratie (=2), of een autocratie (=3) in het jaar 2006. Deze variabele heeft ook waardenlabels dus kunnen we opnieuw factorize() gebruiken:\n\n#transformeer naar factor variabele\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006 = factorize(Typeregime2006))\n\n#Werk checken\nlevels(demdata$Typeregime2006)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\ntable(demdata$Typeregime2006)\n\n\n  Liberal democracy Electoral democracy           Autocracy \n                 71                  53                  41 \n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nWe raden aan om nieuwe variabelen aan te maken wanneer je een bestaande variabele omzet naar een factorvariabele (of wanneer je hercodeert) ook al deden we dit hierboven niet (bv., mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))). Als je een nieuwe variabele aanmaakt overschrijf je nooit de originele. Dit kan helpen om fouten makkelijker te corrigeren (zonder dat je dataset opnieuw moet inladen en eerdere syntax runnen).\n\n\n\n2.1.1 Veranderen van de referentiecategorie\nBij de transformatie naar een factor variabele wordt de categorie met laagste numerieke waarde als referentiecategorie genomen. Het kan zijn dat we dit willen veranderen. Dit kunnen we doen met behulp van de relevel() functie. Hieronder veranderen we de referentiecategorie voor “Typeregime2006” naar “Electoral Democracy”.\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_relevel = relevel(Typeregime2006, \"Electoral democracy\"))\n\n\nrelevel(\n\nNaam van de functie\n\nTyperegime2006,\n\nWe gebruiken “Typeregime2006” uit de “demdata” dataset.\n\n\"Electoral democracy\")\n\nWe geven de naam op van de categorie die we als referentiecategorie willen nemen tussen dubbele aanhalingstekens. We gebruiken de naam tussen aanhalingstekens omdat de variabele reeds hierboven naar een factor is omgezet, anders zou dit niet werken.\n\n\nWe checken altijd beter of alles goed is gegaan:\n\n#Checken:\nlevels(demdata$Typeregime2006)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\nlevels(demdata$Typeregime2006_relevel)\n\n[1] \"Electoral democracy\" \"Liberal democracy\"   \"Autocracy\""
  },
  {
    "objectID": "linear_02.html#factor-variabelen-als-predictors",
    "href": "linear_02.html#factor-variabelen-als-predictors",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "2.2 Factor variabelen als predictors",
    "text": "2.2 Factor variabelen als predictors\nWe voegen binaire en categorische onafhankelijke variabelen toe aan de regressieanalyse op dezelfde manier als bij continue variabelen:\n\n# Met binaire predictor: \nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984, data=demdata)\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984Democracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\n\n# Met categorische predictor: \nmodel_categorical &lt;- lm(v2x_polyarchy ~ Typeregime2006, data=demdata)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ Typeregime2006, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40104 -0.09898  0.00196  0.10773  0.47773 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                        0.75404    0.01734   43.48   &lt;2e-16 ***\nTyperegime2006Electoral democracy -0.32106    0.02653  -12.10   &lt;2e-16 ***\nTyperegime2006Autocracy           -0.50577    0.02866  -17.64   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1461 on 162 degrees of freedom\n  (14 observations deleted due to missingness)\nMultiple R-squared:  0.6789,    Adjusted R-squared:  0.6749 \nF-statistic: 171.2 on 2 and 162 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output van een model met binaire/categorische predictor is dezelfde als die van een model met een continue predictor met 1 verschil. R zal de variabelenaam bij de coëfficiënten anders weergeven als er een factor variabele is. Dan krijg je de naam van de variabele, onmiddellijk gevolgd door de categorie die de waarde 1 aanneemt in de dummy. Bijvoorbeeld: “TypeDemo1984Democracies” or “Typeregime2006Autocracy.”\n\n\nEr zijn subtiele verschillen in de interpretatie als een factor variabele opgenomen wordt in het model:\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe Estimate kolom toont de coëfficiënten van het regressiemodel.\nHet”(Intercept)” toont nog steeds de verwachte waarde op de afhankelijke variabele als de onafhankelijke variabele gelijk is aan 0. Als de enige onafhankelijke variabele een factor is dan toont het intercept de gemiddelde waarde op Y voor de referentiegroep (factor dummy = 0).\nHier vinden we dat de gemiddelde waarde voor v2x_polyarchy voor autocratieën (gemeten volgens de TYPEDEMO1984 variabele) gelijk is aan het Intercept dat we hierboven vonden.\n\ndemdata |&gt; \n1  filter(TYPEDEMO1984 == \"Autocracies\") |&gt;\n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n2  as.data.frame()\n\n\n1\n\nDe filter verwijdert observaties die niet de waarde “Autocracies” hebben voor TYPEDEMO1984\n\n2\n\nDeze optie dwingt R om alle decimalen weer te geven voor een betere vergelijking met het Intercept.\n\n\n\n\n  mean_democracy\n1      0.4175698\n\n\nDe coëfficiënten voor binaire en categorische variabelen worden best gezien als het verschil in de gemiddelde score voor Y tussen de referentiecategorie en andere categorieën. De coëfficiënt voor “TYPEDEMO1984Democracies” is bijvoorbeeld 0.2726758.3 Dit betekent dat de gemiddelde score op Y voor democratieën 0.2726758 schaalpunten groter is dan de gemiddelde waarde voor autocratieën (de referentiecategorie).\nWe kunnen dit wiskundig nagaan:\n\n# Gemiddelde voor democratieën\ndemdata |&gt; \n  group_by(TYPEDEMO1984) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm = T)) |&gt;\n  as.data.frame() \n\n  TYPEDEMO1984 mean_democracy\n1  Autocracies      0.4175698\n2  Democracies      0.6902456\n3         &lt;NA&gt;      0.4638056\n\n# gemiddelde democratieën - gemiddelde autocratieën\n 0.6902456 - 0.4175698\n\n[1] 0.2726758\n\n\nHetzelfde geldt voor categorische factorvariabelen. De “(Intercept)” waarde in model_categorical is de gemiddelde waarde voor de observaties in de referentiecategorie (hier: “Liberal Democracy”). De coefficiënten tonen hoe de andere groepen verschillen van dit gemiddelde. De gemiddelde 2020 democratiescore voor landen die in 2006 een “Electoral Democracy” waren is -0.32 schaalpunten lager dan de gemiddelde 2020 democratiescore voor de “Liberal Democracy” referentiegroep.\n\ndemdata |&gt; \n  group_by(Typeregime2006) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n  as.data.frame() \n\n       Typeregime2006 mean_democracy\n1   Liberal democracy      0.7540423\n2 Electoral democracy      0.4329811\n3           Autocracy      0.2482683\n4                &lt;NA&gt;      0.3777143\n\n# gemiddelde Elec Democracy - gemiddelde in Lib Democracy\n0.4329811 - 0.7540423\n\n[1] -0.3210612\n\n# gemiddelde in Autocracy - gemiddelde in Lib Democracy\n0.2482683 - 0.7540423\n\n[1] -0.505774\n\n\nZie Section 8.3 voor verdere informatie over hoe de resultaten te presenteren in taken en papers."
  },
  {
    "objectID": "linear_02.html#footnotes",
    "href": "linear_02.html#footnotes",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "",
    "text": "We gebruiken k-1 dummies, waarbij k = aantal categorieën. Als een categorische variabele 4 categorieën heeft (Bijvoorbeeld: Noorden, Westen, Zuiden en Oosten), dan gebruiken we (4-1=) 3 dummies.↩︎\nTransformatie is niet nodig als de originele variabelen reeds opgeslaan zijn als factor in de dataset, maar misschien moet de referentiecategorie wel aangepast worden (zie verder).↩︎\nNormaal ronden we af op 2 of 3 decimalen, maar hier tonen we de hele coëfficiënt zodat deze beter vergeleken kan worden met het verschil tussen de gemiddelden.↩︎"
  },
  {
    "objectID": "linear_03.html#t--en-p-waarden-via-summary",
    "href": "linear_03.html#t--en-p-waarden-via-summary",
    "title": "3  Statistische Significantie",
    "section": "3.1 t- en p-waarden via summary()",
    "text": "3.1 t- en p-waarden via summary()\nDe meeste relevant informatie over statistische significantie en onzekerheid vinden we met de summary() functie.\n\n#Schat model en sla op in object\nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984, data=demdata)\n\n#Gebruik summary om de resultaten te bekijken\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984Democracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nInformatie over onzekerheid van de schattingen en statistische significantie vinden we in het gedeelte met de coëfficiënten.\n\nStd. Error: Standaardfout van de coëfficiënt\nt value: De t-waarde of t-statistiek voor de coëfficiënt (\\(t = \\frac{\\textrm{Coefficient}}{\\textrm{Std.Error}}\\))\nPr(&gt;|t|): De p-waarde voor de t-statistiek- de probabiliteit dat we deze t-waarde of een grotere krijgen als we ervanuit gaan dat de nulhypothese van geen effect correct is en de assumpties voldaan zijn.\nAsterisken en Signif. codes: Je kunt deze symbolen zien naast de waarde onder Pr(&gt;|t|), indien van toepassing. Ze geven weer of de coëfficiënt significant is en zo ja, op welk niveau. De “Signif. codes” rij legt uit waar de codes voor staan. Een enkele asterisk (*), bijvoorbeeld, toont dat de p-waarde kleiner is dan 0.05 maar groter dan 0.01. Twee asterisks (**) vertelt dat de p-waarde kleiner is dan 0.01 maar groter dan 0.001.\n\n\n\nDoorgaans gaan we statistische significantie na door te kijken naar de symbolen naast de waarden in de Pr(&gt;|t|) kolom. Zie Section 8.3 voor verdere informatie over hoe hierover te rapporteren."
  },
  {
    "objectID": "linear_03.html#betrouwbaarheidsintervallen-via-tidy",
    "href": "linear_03.html#betrouwbaarheidsintervallen-via-tidy",
    "title": "3  Statistische Significantie",
    "section": "3.2 Betrouwbaarheidsintervallen via tidy()",
    "text": "3.2 Betrouwbaarheidsintervallen via tidy()\nDe output die we verkrijgen met summary() geeft ons niet de 95% betrouwbaarheidsintervallen voor de coëfficiënten. Deze kunnen we verkrijgen met de tidy() functie vanuit het broom package (geladen aan het begin van dit hoofdstuk).\n\ntidy(model_binary, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.371     0.464\n2 TYPEDEMO1984Democrac…    0.273    0.0369      7.38 1.25e-11    0.200     0.346\n\n\n\ntidy(\n\nNaam van de functie, toegepast op model tussen haakjes.\n\nmodel_binary,\n\nNaam van het model.\n\nconf.int=TRUE)\n\nHier vragen we om de betrouwbaarheidsintervallen op te nemen in de output. Dit wordt niet standaard gedaan. We kunnen ook “conf.int=T” schrijven (“T” = “TRUE”).\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe tidy() functie geeft ons een tabel met resultaten van het model.\n\nterm: De termen in het model (i.e., intercept en onafhankelijke variabelen).\nestimate: coëfficiënt voor elke variabele (en voor het intercept)\nstd.error: de standaardfout voor de coëfficiënten\nstatistic: de t-waarde\np.value: de p-waarde\nconf.low & conf.high: de 95% betrouwbaarheidsintervallen met onder “conf.low” de ondergrens en onder “conf.high” de bovengrens van het interval\n\n\n\nWe kunnen het betrouwbaarheidsniveau aanpassen. Als we het 99% betrouwbaarheidsniveau willen, voegen we bijvoorbeeld “conf.level = 0.99” toe:\n\ntidy(model_binary, conf.int = T, conf.level = 0.99)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.357     0.478\n2 TYPEDEMO1984Democrac…    0.273    0.0369      7.38 1.25e-11    0.176     0.369\n\n\nZowel summary() als tidy() geven ons de coëfficiënten van het model. Een voordeel van tidy() is dat de output in een tidy dataframe wordt weergegeven. Dit dataframe kunnen we manipuleren (bv. hernoemen kolommen, variabelen enz.). Hier maken we in latere lessen gebruik van."
  },
  {
    "objectID": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "href": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "4.1 Uitvoeren van de meervoudige lineaire regressie",
    "text": "4.1 Uitvoeren van de meervoudige lineaire regressie\nIn dit voorbeeld voorspellen we het niveau van electorale democratie in een land (v2x_polyarchy) aan de hand van 3 onafhankelijke variabelen (2 continue en 1 binair):\n\ncpi: CPI staat voor “corruption perception index” en meet de mate van corruptie in de publieke sector van een land. Hogere waarden staan voor minder corruptie.\nv2caviol: De variabele meet de mate van politiek geweld uitgevoerd door niet-statelijke actoren. Hogere waarden betekenen meer geweld.\nTYPEDEMO1984: Binaire variabele die meet of een land in 1984 een democratie of autocratie was.\n\nVoor we de regressie kunnen uitvoeren, moeten we eerst de binaire variabele transformeren naar een factor:\n\n#omzetten naar factor variabele\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984))\n\nVoor meervoudige regressie gebruiken we ook de lm() functie. We kunnen meerdere onafhankelijke variabelen toevoegen met een ‘+’ teken:\n\n#Model schatten en opslaan in data-object \nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, \n                     data=demdata)\n\n\nmultiple &lt;-\n\nWe slaan de resultaten op in een data object dat we ‘multiple’ noemen. Deze naam kun je zelf bepalen.\n\nlm(v2x_polyarchy ~)\n\nWe voeren een lineaire regressie uit met de afhankelijke variabele “v2x_polyarchy”. Deze plaatsen we links van de tilde (~).\n\ncpi + v2caviol + TYPEDEMO1984,\n\nDe onafhankelijke variabelen worden rechts van de tilde toegevoegd, van elkaar gescheiden door een ‘+’ teken. De volgorde maakt geen verschil voor de resultaten (wel de volgorde van de coëfficiënten in de output).\n\ndata = demdata)\n\nDe naam van de dataset komt aan het einde van de syntax.\n\n\nDe resultaten bekijken we via summary():\n\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.187394   0.042634   4.395 2.19e-05 ***\ncpi                      0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984Democracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe interpretatie van de coëfficiënten is gelijkaardig aan die van bivariate modellen, maar we moeten wel de inclusie van meerdere predictoren in rekening brengen.\nDe “(Intercept)” waarde geeft weer welke waarde we kunnen verwachten voor de afhankelijke variabele als alle onafhankelijke variabelen de waarde 0 aannemen. We verwachten op basis van het model dat een land met score 0 op zowel cpi, v2caviol, als TYPEDEMO1984 (de referentiecategorie, namelijk een autocratie in 1984) gemiddeld een score op electorale democratie in 2020 van 0.19 zal hebben.\nDe coëfficiënten van de onafhankelijke variabelen vertellen ons nog steeds welke verandering we verwachten in de afhankelijke variabele als de predictor met 1 eenheid stijgt. Nu wordt dit effect echter “gecontroleerd op” de andere predictoren in het model. Het effect geldt als de andere variabelen constant worden gehouden (‘ceteris paribus’). Bijvoorbeeld:\n\nv2caviol: Op basis van het model verwachten we dat electorale democratiescores dalen met -0.01 eenheden als politiek geweld met 1 eenheid stijgt, met de effecten van regimestatus in 1984 en corruptie constant gehouden.\nTYPEDEMO1984: Als we landen met dezelfde corruptie en politieke geweldscores vergelijken, verwachten we dat de electorale democratiescore in 2020 0.15 eenheden hoger is voor landen die in 1984 democratieën waren dan landen die autocratieën waren."
  },
  {
    "objectID": "linear_04.html#sec-standardized-coefficients",
    "href": "linear_04.html#sec-standardized-coefficients",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "4.2 Gestandaardiseerde coëfficiënten",
    "text": "4.2 Gestandaardiseerde coëfficiënten\nWe kunnen in plaats van de ongestandaardiseerde coëfficiënten ook de gestandaardiseerde coëfficiënten berekenen. We kunnen hiervoor de standardize_parameters() functie gebruiken uit het parameters package.\n\nmultiple_std &lt;- standardize_parameters(model_multiple, \n                       method = \"refit\")\n\nDe syntax lees je zo:\n\nmultiple_std &lt;-\n\nWe slaan de resultaten op in een nieuw data object “multiple_std”.\n\nstandardize_parameters(multiple,\n\nWe passen de functie toe op het model tussen haakjes\n\nmethod = 'refit')\n\nWe gebruiken de refit methode, de standaardmethode. Met deze methode worden de afhankelijke en onafhankelijke variabelen gestandaardiseerd en dan wordt het model opnieuw geschat met deze gestandaardiseerde versies.\n\n\nWe kunnen de resultaten vergelijken:\nstandardize_parameters() creëert een data frame met volgende kolommen:\n\nglimpse(multiple_std)\n\nRows: 4\nColumns: 5\n$ Parameter       &lt;chr&gt; \"(Intercept)\", \"cpi\", \"v2caviol\", \"TYPEDEMO1984Democra…\n$ Std_Coefficient &lt;dbl&gt; -0.23661987, 0.49272847, -0.05393177, 0.60000039\n$ CI              &lt;dbl&gt; 0.95, 0.95, 0.95, 0.95\n$ CI_low          &lt;dbl&gt; -0.3957424, 0.3306681, -0.2037814, 0.3287296\n$ CI_high         &lt;dbl&gt; -0.07749731, 0.65478881, 0.09591783, 0.87127121\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nParameter: Naam van de term of variabele in het model\nStd_Coefficient: De waarde van de gestandaardiseerde coëfficiënt voor elke variabele\nCI: Niveau van het betrouwbaarheidsinterval voor de gestandaardiseerde coëfficiënt.\nCI_low en CI_high: De onder -en bovengrenzen van het betrouwbaarheidsinterval. Deze waarden worden gecombineerd in 1 cel als we de waarden straks printen.\n\n\n\nWe kunnen de resultaten vergelijken met het ongestandaardiseerde model. We gebruiken tidy() hier om de output te vereenvoudigen.\n\n#Oorspronkelijk model\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                    estimate std.error statistic      p.value\n  &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)              0.187     0.0426      4.40  0.0000219   \n2 cpi                      0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984Democracies  0.153     0.0349      4.37  0.0000239   \n\n#gestandaardiseerd model\nmultiple_std\n\n# Standardization method: refit\n\nParameter               | Std. Coef. |         95% CI\n-----------------------------------------------------\n(Intercept)             |      -0.24 | [-0.40, -0.08]\ncpi                     |       0.49 | [ 0.33,  0.65]\nv2caviol                |      -0.05 | [-0.20,  0.10]\nTYPEDEMO1984Democracies |       0.60 | [ 0.33,  0.87]\n\n\nVoor de continue variabelen geven de gestandaardiseerde coëfficiënten weer hoeveel standaardafwijkingen de afhankelijke variabele gaat veranderen als de onafhankelijke variabele met 1 standaardafwijking stijgt.1\nVoor factor variabelen ligt de interpretatie anders. De gestandaardiseerde coëfficiënt die we krijgen is de ongestandaardiseerde coëfficiënt gedeeld door de standaardafwijking van de afhankelijke variabele. De gestandaardiseerde coëfficiënten van continue en factor variabelen kunnen niet direct vergeleken worden.2\n\n\n\n\n\n\nInterpretatie\n\n\n\nWe verwachten dat democratiescores met-0.05 standaardafwijkingen dalen als politiek geweld met 1 standaardafwijking stijgt (en met de effecten van corruptie en regimestatus in het verleden constant gehouden).\nAls we landen met dezelfde corruptie en politieke geweldscores vergelijken, verwachten we dat de electorale democratiescore in 2020 0.6 standaardafwijkingen hoger is voor landen die in 1984 democratieën waren dan landen die autocratieën waren.\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nJe zult opgemerkt hebben dat we noch summary() noch tidy() gebruikt hebben om de gestandaardiseerde coëfficiënten te printen in R. Deze functies zijn niet nodig omdat de output van standardize_parameters() reeds opgeslagen is in een dataframe.\nIndien je summary() zou gebruiken zou je samenvattende statistieken vinden voor elke kolom in het dataframe:\n\nsummary(multiple_std)\n\n  Parameter         Std_Coefficient         CI           CI_low        \n Length:4           Min.   :-0.2366   Min.   :0.95   Min.   :-0.39574  \n Class :character   1st Qu.:-0.0996   1st Qu.:0.95   1st Qu.:-0.25177  \n Mode  :character   Median : 0.2194   Median :0.95   Median : 0.06247  \n                    Mean   : 0.2005   Mean   :0.95   Mean   : 0.01497  \n                    3rd Qu.: 0.5195   3rd Qu.:0.95   3rd Qu.: 0.32921  \n                    Max.   : 0.6000   Max.   :0.95   Max.   : 0.33067  \n    CI_high        \n Min.   :-0.07750  \n 1st Qu.: 0.05256  \n Median : 0.37535  \n Mean   : 0.38612  \n 3rd Qu.: 0.70891  \n Max.   : 0.87127  \n\n\nMet tidy() krijg je een foutmelding gezien tidy() bedoeld is voor objecten die afkomstig zijn van statistische modellen:\n\ntidy(multiple_std)\n\nWarning: Data frame tidiers are deprecated and will be removed in an upcoming\nrelease of broom.\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in var(if (is.vector(x) || is.factor(x)) x else as.double(x), na.rm =\nna.rm): NAs introduced by coercion\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nError in x - stats::median(x, na.rm = na.rm): non-numeric argument to binary operator"
  },
  {
    "objectID": "linear_04.html#footnotes",
    "href": "linear_04.html#footnotes",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "",
    "text": "We zouden ook kunnen vragen enkel de onafhankelijke variabelen te standaardiseren en de schaal van de afhankelijke variabele te behouden met de optie “include_response = F” (F=False). Dit zou ons zeggen hoeveel Y verwacht wordt te veranderen op de originele schaal als de onafhankelijke variabele met 1 standaardafwijking stijgt. We kunnen dit doen als de schaal van de afhankelijke variabele zeer intuïtief is, bijvoorbeeld percentage stemmen voor een bepaalde partij.↩︎\nDe gestandaardiseerde coëfficiënten van continue en factor variabelen kunnen meer direct vergeleken worden als we de optie “two_sd = TRUE” toevoegen. De coëfficiënt van de continue onafhankelijke variabele geeft dan weer wat er gebeurt met Y als de onafhankelijke met 2 standaardafwijkingen stijgt, ongeveer het volledige bereik van de onafhankelijke variabele.↩︎"
  },
  {
    "objectID": "linear_05.html#voorspellingen-en-fouten-voor-de-observaties-in-het-model",
    "href": "linear_05.html#voorspellingen-en-fouten-voor-de-observaties-in-het-model",
    "title": "5  Voorspellingen en Fouten",
    "section": "5.1 Voorspellingen en fouten voor de observaties in het model",
    "text": "5.1 Voorspellingen en fouten voor de observaties in het model\nOp basis van het lineaire regressiemodel kunnen we voor elke observatie gebruikt in het model een voorspelling maken van de waarde voor de afhankelijke waarde. Het verschil tussen deze voorspelling en de echte waarde die we vinden in de dataset is de fout (‘error’) of ‘residual’.\nDe predictions() functie uit het marginaleffects package kan gebruikt worden om voorspellingen te maken voor elke observatie gebruikt in het model. 1\n\nmodel_binary_predictions &lt;- predictions(model_binary, newdata = demdata) |&gt; \n  as_tibble() #as_tibble() niet strikt nodig, zie waarschuwingsvak hieronder\n\nZo lees je de syntax:\n\nmodel_binary_predictions\n\nWe slaan de output hier op in een nieuw data object “model_binary_predictions”. Deze naam kun je zelf bepalen.\n\npredictions(model_binary,\n\nWe gebruiken de predictions functie op het model tussen haakjes.\n\nnewdata = demdata)\n\nHier verduidelijken we de originele dataset voor deze voorspellingen. Deze syntax vertelt R dat we in ons nieuwe data object de voorspellingen willen, maar ook alle variabelen uit de originele dataset, niet enkel de variabelen gebruikt in het model. Dit is nuttig als we specifieke observaties willen identificeren (bv. door te kijken naar de naam van het land). Als je dit niet specificeert krijg je een dataset zonder de overige variabelen in de originele dataset.\n\n\nDe output kunnen we printen met behulp van de volgende code:\n\nmodel_binary_predictions\n\n# A tibble: 179 × 49\n   rowid estimate std.error statistic    p.value s.value conf.low conf.high\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 2     2    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 3     3    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 4     4    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 5     5    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 6     6    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 7     7    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 8     8    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 9     9   NA       NA           NA   NA             NA    NA        NA    \n10    10    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n# ℹ 169 more rows\n# ℹ 41 more variables: country_name &lt;chr&gt;, year &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;,\n#   v2x_libdem &lt;dbl&gt;, v2x_egaldem &lt;dbl&gt;, v2cacamps &lt;dbl&gt;, v2caviol &lt;dbl&gt;,\n#   e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;, e_regionpol_6C &lt;dbl&gt;,\n#   v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;, bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;,\n#   dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;, TypeSoc2005 &lt;dbl&gt;,\n#   TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, …\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nestimate: Dit is de voorspelde waarde op de afhankelijke variabele voor elke observatie in het model. Observaties die niet in het model werden opgenomen (omwille van ontbrekende data) krijgen hier ‘NA’.\nstd.error, statistic, p.value, conf.low, en conf.high: de standaardfout van de voorspelling, t-statistiek, p-waarde en het 95% betrouwbaarheidsinterval. De s-waarde is een andere manier om onzekerheid weer te geven maar behoort niet tot de leerstof. 2\nDe overige kolommen bevatten de variabelen uit de originele dataset.\n\n\n\nWe kunnen het nieuwe dataobject gebruiken om ook de residuals te berekenen. Dit doen we door het verschil tussen echte en voorspelde waarde in een variabele op te nemen. 3\n\nmodel_binary_predictions &lt;- model_binary_predictions |&gt; \n  mutate(residual_value = v2x_polyarchy - estimate) #residual = echte waarde - voorspelde waarde\n\nDeze variabele kunnen we gebruiken om na te gaan welke observaties goed of slecht worden voorspeld. Dit kan nuttig zijn bij het nagaan of aan assumpties voldaan is, zie Chapter 7 .\n\nmodel_binary_predictions |&gt; \n  select(country_name, v2x_polyarchy, estimate, residual_value) \n\n# A tibble: 179 × 4\n   country_name v2x_polyarchy estimate residual_value\n   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Mexico               0.647    0.690        -0.0432\n 2 Suriname             0.761    0.418         0.343 \n 3 Sweden               0.908    0.690         0.218 \n 4 Switzerland          0.894    0.690         0.204 \n 5 Ghana                0.72     0.418         0.302 \n 6 South Africa         0.703    0.418         0.285 \n 7 Japan                0.832    0.690         0.142 \n 8 Myanmar              0.436    0.418         0.0184\n 9 Russia               0.262   NA            NA     \n10 Albania              0.485    0.418         0.0674\n# ℹ 169 more rows"
  },
  {
    "objectID": "linear_05.html#voorspellingen-voor-bepaalde-waarden-van-de-onafhankelijke-variabele-bivariaat",
    "href": "linear_05.html#voorspellingen-voor-bepaalde-waarden-van-de-onafhankelijke-variabele-bivariaat",
    "title": "5  Voorspellingen en Fouten",
    "section": "5.2 Voorspellingen voor bepaalde waarden van de onafhankelijke variabele (Bivariaat)",
    "text": "5.2 Voorspellingen voor bepaalde waarden van de onafhankelijke variabele (Bivariaat)\nWe kunnen ook nagaan welke waarde op de afhankelijke we kunnen verwachten volgens het model als de onafhankelijke variabele bepaalde waarden aanneemt. Bijvoorbeeld: welke democratiescore kunnen we gemiddeld verwachten voor landen die in 1984 een autocratie waren? Of voor landen die een lage of hoge economische ongelijkheid kennen? We kunnen hier ook de predictions() functie voor gebruiken.\nEerst voorspellen we de verwachte democratiescore in 2020 voor landen die in 1984 een autocratie versus democratie waren op basis van ons bivariaat model (model_binary).\n\npredictions(model_binary, \n            by = 'TYPEDEMO1984') |&gt; \n  as_tibble()  \n\n# A tibble: 2 × 10\n  rowid TYPEDEMO1984 estimate std.error statistic   p.value s.value conf.low\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Democracies     0.690    0.0287      24.1 3.16e-128    424.    0.634\n2     2 Autocracies     0.418    0.0233      17.9 1.16e- 71    236.    0.372\n# ℹ 2 more variables: conf.high &lt;dbl&gt;, rowid_dedup &lt;int&gt;\n\n\n\npredictions(model_binary,\n\nWe passen de functie toe op het model tussen haakjes.\n\nby = \"TYPEDEMO1984\")\n\nHier vragen we de voorspelling voor elk niveau (level) van de factor “TYPEDEMO1984”. De “by=” syntax wordt enkel gebruikt met factor variabelen. We maken geen gebruik van “newdata=” omdat we hier geen voorspellingen vragen voor alle observaties.\n\n\nWe kunnen ook voorspellingen maken op basis van een continue onafhankelijke variabele. We kunnen bijvoorbeeld de score voor electorale democratie voorspellen aan de hand van economische ongelijkheid (gini_2019). Hier gaan we na welke democratiescore we kunnen verwachten als ongelijkheid laag (25) versus hoog is (45).\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,45))) |&gt; \n  as_tibble()\n\n# A tibble: 2 × 10\n  rowid estimate std.error statistic  p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e-64   211.     0.675     0.852\n2     2    0.527    0.0493      10.7 1.10e-26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\nnewdata = datagrid(gini_2019 = c(25,45))\n\nHier bepalen we de waarden van de continue onafhankelijke variabele waar we voorspellingen voor willen maken. Je kunt de naam van de variabele veranderen, alsook de waarden waarvoor je voorspellingen maakt. De rest van de syntax blijft gelijk.\n\n\nWe kunnen eventueel meerdere waarden toevoegen om voorspellingen voor te maken door de code op de volgende manier uit te breiden in het c() gedeelte van de syntax:\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,30,35,40,45))) |&gt; \n  as_tibble()\n\n# A tibble: 5 × 10\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e- 64   211.     0.675     0.852\n2     2    0.705    0.0316      22.3 2.20e-110   364.     0.643     0.766\n3     3    0.645    0.0267      24.2 6.30e-129   426.     0.593     0.698\n4     4    0.586    0.0345      17.0 1.04e- 64   213.     0.518     0.654\n5     5    0.527    0.0493      10.7 1.10e- 26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nWe eindigden de predictions() functie met as_tibble(). Deze stap is niet strikt noodzakelijk. Dit is het resultaat zonder de toevoeging:\n\npredictions(model_binary, by = 'TYPEDEMO1984')\n\n\n TYPEDEMO1984 Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  Democracies    0.690     0.0287 24.1   &lt;0.001 423.5 0.634  0.746\n  Autocracies    0.418     0.0233 17.9   &lt;0.001 235.6 0.372  0.463\n\nColumns: rowid, TYPEDEMO1984, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rowid_dedup \nType:  response \n\n\nHet verschil zit hem in de weergave van de output in R: standaard geeft predictions() andere namen aan de kolommen (bv., Estimate i.p.v. estimate, 2.5% i.p.v. conf.low) om de zaken netter te maken, maar dit bemoeilijkt de zaken eigenlijk vaak voor ons omdat dit niet de echte variabelenamen zijn zoals ze ogeslagen worden in het object. Later in het vak gebruiken we deze variabelen om verdere bewerkingen te doen. Daarvoor moeten we de juiste variabelenamen opgeven: estimate dus en niet Estimate."
  },
  {
    "objectID": "linear_05.html#voorspelde-waarden-meervoudige-lineaire-regressie",
    "href": "linear_05.html#voorspelde-waarden-meervoudige-lineaire-regressie",
    "title": "5  Voorspellingen en Fouten",
    "section": "5.3 Voorspelde waarden (Meervoudige Lineaire Regressie)",
    "text": "5.3 Voorspelde waarden (Meervoudige Lineaire Regressie)\nVoorspelde waarden en fouten kunnen we ook voor meervoudige regressie bekijken via de predictions() functie. De procedure om voorspelde waarden te vinden voor alle observaties in het model is dezelfde als hierboven dus herhalen we deze niet. De procedure voor voorspellingen op basis van waarden van een onafhankelijke variabele is gelijkaardig, met 1 belangrijk verschil voor factor variabelen.\n\n5.3.1 Voorspellingen voor een continue predictor\nDit waren de resultaten van ons meervoudig lineair regressiemodel:\n\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                    estimate std.error statistic      p.value\n  &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)              0.187     0.0426      4.40  0.0000219   \n2 cpi                      0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984Democracies  0.153     0.0349      4.37  0.0000239   \n\n\ncpi meet gepercipieerde corruptie in een land op een schaal van 0 tot 100 (hogere waarden staan voor minder corruptie). In de praktijk is het bereik van de variabele in ons model 12 tot 88. Voor we voorspellingen doen gaan we het werkelijke bereik eerst na:\n\n1predictions(model_multiple) |&gt;\n2  select(cpi) |&gt;\n3  summary()\n\n\n1\n\nWe gebruiken de predictions() functie hier om enkel observaties te selecteren die gebruikt werden in het model (observaties met ontbrekende waarden op ‘NA’ worden weggefilterd).\n\n2\n\nWe selecteren de cpi variabele\n\n3\n\nEn vragen de beschrijvende statistieken voor de variabele.\n\n\n\n\n      cpi       \n Min.   :12.00  \n 1st Qu.:28.00  \n Median :39.50  \n Mean   :43.37  \n 3rd Qu.:56.75  \n Max.   :88.00  \n\n\nWe kunnen voorspelde waarden gebruiken om een inschatting te maken over het verwachte niveau van democratie bij lage en hoge corruptie. Een regressiecoëfficiënt zegt ons wat er gebeurt als corruptie met 1 eenheid stijgt, maar voorspelde waarden kunnen vaak een intuïtiever beeld geven over de sterkte van een effect. Hier gebruiken we predictions() om verwachte democratiescores te berekenen voor corruptiescores (cpi) van 20 tot 80 met verhogingen van telkens 10 eenheden.\n\npreds1 &lt;- predictions(model_multiple, \n            newdata = datagrid(cpi = c(20,30,40,50,60,70,80))) |&gt; \n  as_tibble()\n\n\npreds1 &lt;-\n\nWe slaan de resultaten op in een data object omdat we ze ook voor andere doeleinden zullen gebruiken. De naam bepaal je zelf.\n\npredictions(multiple,\n\nWe passen de functie toe op het model tussen haakjes.\n\nnewdata = datagrid(cpi = c(20,30,40,50,60,70,80))\n\nHier bepalen we voor welke onafhankelijke variabele we voorspellingen willen (cpi) en voor welke waarden (20…80). De waarden zijn numeriek en gaan niet tussen aanhalingstekens.\n\n\nWe printen de voorspellingen:\n\npreds1\n\n# A tibble: 7 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.318    0.0278      11.4 2.41e- 30    98.4    0.264     0.373\n2     2    0.382    0.0217      17.6 3.30e- 69   227.     0.339     0.424\n3     3    0.445    0.0199      22.4 2.59e-111   367.     0.406     0.484\n4     4    0.509    0.0233      21.9 6.10e-106   350.     0.463     0.555\n5     5    0.573    0.0302      18.9 4.92e- 80   263.     0.513     0.632\n6     6    0.636    0.0389      16.4 2.78e- 60   198.     0.560     0.713\n7     7    0.700    0.0483      14.5 1.17e- 47   156.     0.605     0.795\n# ℹ 4 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, cpi &lt;dbl&gt;,\n#   v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nestimate: De voorspelde waarde\nkolommen “std.error” tot “conf.high”: informatie met betrekking tot onzekerheid van de schatting\n“4 more variables”: Dit zegt dat ons tidied dataframe nog 4 variabelen heeft (dit verschilt naargelang het model dat je gebruikt). De kolommen zijn genoemd naar de variabelen gebruikt in het model. Voor de onafhankelijke variabelen (hier: v2caviol, TYPEDEMO1984, en cpi) tonen ze de waarden die gebruikt worden voor deze variabelen om de voorspellingen te maken.\n\n\n\nIn bovenstaand voorbeeld houdt predictions() automatisch de 2 overige onafhankelijke variabelen (v2caviol en TYPEDEMO1984) constant op dezelfde waarde bij de berekening van elke voorspelde waarde. Continue predictoren worden constant gehouden op hun gemiddelde, voor factor variabelen wordt de modus (de meest voorkomende categorie) gebruikt. Dit kunnen we nagaan:\n\npreds1 |&gt; \n  select(estimate, cpi, v2caviol, TYPEDEMO1984)\n\n# A tibble: 7 × 4\n  estimate   cpi v2caviol TYPEDEMO1984\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;       \n1    0.318    20   -0.394 Autocracies \n2    0.382    30   -0.394 Autocracies \n3    0.445    40   -0.394 Autocracies \n4    0.509    50   -0.394 Autocracies \n5    0.573    60   -0.394 Autocracies \n6    0.636    70   -0.394 Autocracies \n7    0.700    80   -0.394 Autocracies \n\n\n\n\n5.3.2 Voorspellingen voor een factor predictor\nWe kunnen een gelijkaardige procedure gebruiken om voorspellingen te maken voor de verschillende niveaus van factor variabelen. Dit kunnen we doen met behulp van de by= optie i.p.v newdata = datagrid().4 Om ervoor te zorgen dat we voor de overige onafhankelijke variabelen het gemiddelde of de modus nemen, moeten we hier wel nog syntax toevoegen via newdata:\n\npreds2 &lt;- predictions(model_multiple, by= \"TYPEDEMO1984\", \n                      newdata = \"mean\") |&gt; \n  as_tibble()\n\n\nby=\"TYPEDEMO1984\"\n\nHier verduidelijken we dat we voorspellingen willen voor elk niveau van de factor variabele.\n\nnewdata = \"mean\")\n\nHier zeggen we dat voor de overige onafhankelijke variabelen het gemiddelde of de modus aangehouden moet worden. Dit gebeurde automatisch in vorig voorbeeld, maar moet toegevoegd worden als we “by=” gebruiken.\n\n\nDe resultaten zijn als volgt:\n\npreds2\n\n# A tibble: 2 × 12\n  rowid TYPEDEMO1984 estimate std.error statistic   p.value s.value conf.low\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Democracies     0.620    0.0260      23.8 2.47e-125    414.    0.569\n2     2 Autocracies     0.467    0.0205      22.8 4.94e-115    380.    0.427\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, cpi &lt;dbl&gt;, v2caviol &lt;dbl&gt;,\n#   v2x_polyarchy &lt;dbl&gt;\n\n\nOpnieuw kunnen we zien dat predictions() de andere onafhankelijke variabelen constant houdt:\n\npreds2 |&gt; \n  select(estimate, TYPEDEMO1984, cpi, v2caviol)\n\n# A tibble: 2 × 4\n  estimate TYPEDEMO1984   cpi v2caviol\n     &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1    0.620 Democracies   43.4   -0.394\n2    0.467 Autocracies   43.4   -0.394\n\n\n\n\n5.3.3 Voorspellingen voor specifieke waarden van de onafhankelijke variabelen\nWe kunnen predictions() ook gebruiken om voorspellingen te maken voor specifieke, hypothetische casussen. Bijvoorbeeld, hier vragen we de voorspelde waarde voor de afhankelijke variabele electorale democratie voor een land dat: een democratie was in 1984, 88 scoort op de corruptieperceptie-index (de maximum waarde in de dataset) en -3.429 voor politiek geweld (de minimum waarde in de dataset).\nWe bepalen deze waarden in het newdata = datagrid() gedeelte van de syntax. Indien we een variabele niet zouden specificeren zou deze constant gehouden worden op het gemiddelde of de modus.\n\npredictions(model_multiple, \n            newdata = datagrid(cpi=c(88), \n                               v2caviol=c(-3.429), \n                               TYPEDEMO1984=c(\"Democracies\"))) |&gt; \n  as_tibble()\n\n# A tibble: 1 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high   cpi\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1    0.930    0.0392      23.7 1.89e-124    411.    0.853      1.01    88\n# ℹ 3 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, v2x_polyarchy &lt;dbl&gt;"
  },
  {
    "objectID": "linear_05.html#footnotes",
    "href": "linear_05.html#footnotes",
    "title": "5  Voorspellingen en Fouten",
    "section": "",
    "text": "De augment() functie uit het broom package kunnen we ook gebruiken om de residuals te bestuderen. Dit gebruiken we in een ander hoofdstuk. Hier richten we ons op predictions() omdat deze functie gemakkelijker een dataframe produceert met de voorspellingen, fouten en de overige data in de originele dataset.↩︎\nDe s-waarde is een poging om de p-waarde te vertalen naar een maat die volgens sommigen gemakkelijker te interpreteren is. In het bijzonder vertelt het ons: “Hoeveel opeenvolgende”kop”-worpen zouden dezelfde hoeveelheid bewijs (of “verrassingen”) leveren tegen de nulhypothese dat de munt eerlijk is?” Een p-waarde van 0,05 zou bijvoorbeeld een overeenkomstige s-waarde van 4,3 of zo hebben. We zouden dan kunnen zeggen dat een p-waarde van 0,05 ongeveer net zo verrassend is als vier keer een eerlijke munt opgooien en de munt alle vier de keren op kop zien landen. Zou je je gerust voelen om een verklaring af te leggen dat de munt vals is in plaats van eerlijk op basis van die reeks muntworpen? In de context van de output van predictions() (en van de slopes()-functie die we in latere hoofdstukken zien), zouden hogere s-waarden aangeven dat we steeds verraster zouden moeten zijn om onze resultaten te zien als de waarde van het ding dat we schatten eigenlijk 0 is. Deze statistiek is niet zo nuttig voor onze voorspelde waarden, maar zou nuttiger kunnen zijn om te begrijpen hoe verrassend een schatting van een coëfficiënt of “marginaal effect” is. Als je wilt, kun meer lezen over wat p-waarden zijn, enkele van de complicaties die onderzoekers tegenkomen bij het interpreteren ervan, en een discussie over wat s-waarden zijn en hoe ze kunnen helpen in deze blogpost. De s-waarde is geen onderdeel van de leerstof.↩︎\nRusland heeft hier een ‘NA’ waarde voor estimate en residual_value omdat het omwille van ontbrekende waarden niet is opgenomen in het regressiemodel.↩︎\nWe zouden technisch gezien wel newdata = datagrid() kunnen gebruiken maar dan moeten we de niveaus van de factor variabele manueel typen (bv. newdata = datagrid(TYPEDEMO1984 = c(\"Autocracies', \"Democracies\")). De by = functie is dus gemakkelijker.↩︎"
  },
  {
    "objectID": "linear_06.html#r2-adjusted-r2-en-de-f-test",
    "href": "linear_06.html#r2-adjusted-r2-en-de-f-test",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "6.1 R2, Adjusted R2 en de F-Test",
    "text": "6.1 R2, Adjusted R2 en de F-Test\nOns voorbeeld hier is een regressiemodel waarin we de electorale democratiescore van een land in 2020 (v2x_polyarchy) voorspellen aan de hand van gepercipieerde corruptie in dat land (cpi), politiek geweld (v2caviol), en regimestatus in 1984 (TYPEDEMO1984).\n\nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data=demdata)\n\nDe meeste model fit statistieken verkrijgen we simpelweg via de summary() functie:\n\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.187394   0.042634   4.395 2.19e-05 ***\ncpi                      0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984Democracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nModel fit statistieken vinden we onderaan de output. “Multiple R-Squared” geeft de \\(R^2\\) (R kwadraat) statistiek. “Adjusted R-Squared” geeft de \\(R^2\\) gecorrigeerd voor het aantal predictoren in het model. De F-statistiek geeft informatie over de statistische significantie van het model.\n\nMultiple R-squared: Dit toont de \\(R^2\\) (R kwadraat) statistiek, die meestal geïnterpreteerd wordt in termen van % van de variatie in Y verklaard door de predictoren in het model\nAdjusted R-squared: Dit toont de \\(R^2\\) gecorrigeerd voor het aantal predictoren in het model.\nF-statistic…: De F-statistiek geeft informatie over de statistische significantie van het model. Het eerste getal is de F-statistiek zelf (47.26). Het cijfer achter “p-value:” is de p-waarde voor de F-statistiek. De nulhypothese die hierbij getest wordt is dat geen enkele van de onafhankelijke variabelen (hier: cpi, v2caviol, TYPEDEMO1984) statistisch significant is. Een statistisch signifcante F-statistiek betekent dat op z’n minst 1 predictor significant is.\n\n\n\nDeze output kunnen we ook verkrijgen via de glance() functie uit het broom package:\n\nglance(model_multiple)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.507         0.496 0.181      47.3 4.46e-21     3   43.5 -77.0 -62.3\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nDe relevante statistieken vind je bij r.squared (R2), adj.r.squared (Adjusted R2), statistic (F-statistic), en p.value (p-waarde voor de F-statistiek) kolommen. nobs toont het aantal observaties gebruikt in het model."
  },
  {
    "objectID": "linear_06.html#sec-linear-comparing-models",
    "href": "linear_06.html#sec-linear-comparing-models",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "6.2 Modellen vergelijken",
    "text": "6.2 Modellen vergelijken\nDe F-statistiek gaat na of het model een significant verbeterde voorspelling geeft dan een ‘nul model’ zonder predictoren, oftewel het gemiddelde van de afhankelijke variabele. We kunnen ook meerdere modellen vergelijken met elkaar. Hier vergelijken we een model met enkel cpi als onafhankelijke, dan een model met zowel cpi als v2caviol, en ten slotte een model met alle predictoren. Deze modellen zijn ‘nested’, dat wil zeggen dat meer uitgebreide modellen alle variabelen bevatten van de meer simpele modellen.\nOm deze vergelijking te maken moeten we er wel voor zorgen dat onze modellen met dezelfde observaties werken en dus dezelfde N hebben. Dit kunnen we bereiken door een nieuwe dataset aan te maken met complete waarden (non-missing) voor alle variabelen die gebruikt worden in het meest complete model.\n\ndemdata_complete &lt;- demdata |&gt; \n  filter(complete.cases(v2x_polyarchy, cpi, v2caviol, TYPEDEMO1984))\n\nDeze dataset gebruiken we om onze modellen te schatten. Om een volledige vergelijking mogelijk te maken, schatten we ook een nulmodel zonder onafhankelijke variabelen met enkel een intercept (~ 1). Dit intercept bevat de gemiddelde waarde voor Y in de dataset (i.e. onze beste voorspelling zonder predictoren):\n\n#Null model\nmodel1 &lt;- lm(v2x_polyarchy ~ 1, data = demdata_complete)\n\n#Model with just cpi\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata_complete)\n\n#Model with cpi & v2caviol\nmodel3 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol, data = demdata_complete)\n\n#Model with all predictors\nmodel4 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata_complete)\n\nWe kunnen de R2/Adj. R-Squared van de modellen vergelijken om te bekijken welk model het beste past. Dit geeft ons echter geen significantietoets:\n\n\n\n\n\n\n\n\nModel\nR2\nAdj. R2\n\n\n\n\nModel 1\n0\n0\n\n\nModel 2\n0.437\n0.433\n\n\nModel 3\n0.438\n0.43\n\n\nModel 4\n0.507\n0.496\n\n\n\nModel 4 lijkt het beste te passen, maar om de significantietoets uit te voeren moeten we de anova() functie gebruiken. Deze is ingebouwd in R.\n\nanova(model1, model2, model3, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi\nModel 3: v2x_polyarchy ~ cpi + v2caviol\nModel 4: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq        F    Pr(&gt;F)    \n1    141 9.1323                                    \n2    140 5.1436  1    3.9887 122.2045 &lt; 2.2e-16 ***\n3    139 5.1285  1    0.0151   0.4614    0.4981    \n4    138 4.5043  1    0.6243  19.1269 2.392e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nanova()\n\nWe voeren de functie uit op de modellen tussen haakjes.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nHet eerste deel van de output toont welke modellen vergeleken worden met elkaar. De onderste helft bevat het volgende:\n\nRes.Df: De residual degrees of freedom (vrijheidsgraden) van het model\nRSS: Dit staat voor “residual sum of squares”. RSS meet de variatie tussen de residuals in het model. RSS = \\(\\sum(y_{i} - \\hat{y}_{i})^2\\), waarbij \\(\\sum\\) staat voor “sum up”, \\(y_{i}\\) is de geobserveerde Y voor een observatie in het model, and \\(\\hat{y}_{i}\\) is de voorspelde waarde voor diezelfde observatie.1 RSS vertelt ons hoeveel van de variatie in Y het model niet kan verklaren of voorspellen. Een model met een lagere RSS voorspelt de Y beter, maar het verschil in RSS tussen modellen is niet altijd significant. We hebben dus nog een significantietoets nodig.\nDF: Vrijheidsgraden. In de praktijk de hoeveelheid onafhankelijke variabelen toegevoegd in vergelijking met het voorgaande model. Dit getal is 1 als er 1 predictor werd toegevoegd in vergelijking met het vorige model in bovenstaande rij.2\nSum of Sq: De model of “regression” sum of squares is gebaseerd op de volgende formule: \\(\\sum(\\hat{y}_{i} - \\bar{y})^2\\), waarbij \\(\\hat{y}_{i}\\) de voorspelde waarde is voor een observatie in het model, en \\(\\bar{y}\\) de gemiddelde waarde voor Y op basis van alle observaties in het model.3 De model sum of squares meet de variatie in Y die verklaart wordt door de predictoren in het model. De Sum of Sq in de anova() output toont de verandering in Sum of Sq ten opzichte van het voorgaande model. Hoe hoger de stijging hoe beter, maar hier moet ook een signifcantietest voor gebeuren.\nF & Pr(&gt;F): De F-statistiek en bijhorende p-waarde. De nulhypothese is dat het model in de desbetreffende rij niet beter past dan het model in de voorgaande rij. In feite test dit of tenminste 1 van de variabelen toegevoegd aan het model significant is. Indien de nulhypothese verworpen wordt, dan kunnen we zeggen dat het nieuwe model beter past.\n\n\n\nWe kunnen de output als volgt lezen: Model 2 past hier beter dan 1 (nulmodel), Model 3 past niet beter dan 2, en Model 4 past beter dan 3. We kunnen ook Modellen 1 en 2 direct met Model 4 vergelijken:\n\n#Model 4 vs. Model 2\nanova(model2, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    140 5.1436                                  \n2    138 4.5043  2   0.63935 9.7941 0.0001053 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Model 4 vs. Model 1\nanova(model1, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    141 9.1323                                  \n2    138 4.5043  3     4.628 47.264 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nanova() De volgorde van de modellen is van belang voor de uitkomst. Hierboven vergelijken we telkens een complexer model met een simpeler model. Indien we schrijven “(model4, model1, model2”, “model3”), dan vergelijkt R model 1 tegen 4, model 2 tegen 1 enz.\n\nanova(model4, model1, model2, model3)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\nModel 2: v2x_polyarchy ~ 1\nModel 3: v2x_polyarchy ~ cpi\nModel 4: v2x_polyarchy ~ cpi + v2caviol\n  Res.Df    RSS Df Sum of Sq        F Pr(&gt;F)    \n1    138 4.5043                                 \n2    141 9.1323 -3   -4.6280  47.2642 &lt;2e-16 ***\n3    140 5.1436  1    3.9887 122.2045 &lt;2e-16 ***\n4    139 5.1285  1    0.0151   0.4614 0.4981    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe tweede rij vergelijkt nu het nulmodel (model1) met het meest complexe model (model4). We krijgen een negatieve waarde voor “DF” en “Sum of Sq” omdat Model 1 minder predictoren heeft en ook minder goed past. Het verschil is statistisch significant. Dit interpreteren we nu als: model 4 is beter dan model 1.De derde rij vergelijkt model2 (enkel cpi als predictor) met model1 (het nulmodel). De resultaten zijn dezelfde als hierboven. De resultaten voor de laatste rij zijn ook dezelfde.\nLet erop dat de namen die de anova() functie geeft aan de modellen niet noodzakelijk dezelfde zijn als de namen die je zelf geeft (model 1 voor anova is nu ons model 4).\nJe kunt de fit van bepaalde modellen testen tegenover elkaar om zo stapsgewijs het beste model te vinden. Meestal zullen we meer complexe modellen vergelijken met meer simpele modellen. In de syntax gaan we dan van meest simpel naar meest complex model."
  },
  {
    "objectID": "linear_06.html#footnotes",
    "href": "linear_06.html#footnotes",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "Deze vergelijking behoort niet tot de leerstof.↩︎\nDe DF kolom geeft op zich niet weer hoeveel extra onafhankelijke variabelen werden toegevoegd, maar wel hoeveel nieuwe coëfficiënten (of termen) werden toegevoegd. Dit is vooral van belang bij factor variabelen (zeker als ze 3 of meer categorieën hebben). Hoewel je misschien 1 factor variabele toevoegt, kun je meer dan 1 coëfficiënt (en dus DF) krijgen als je voor meerdere categorieën dummy variabelen moet toevoegen.↩︎\nDeze vergelijking behoort niet tot de leerstof.↩︎"
  },
  {
    "objectID": "linear_07.html#sec-linear-autocorr-DW",
    "href": "linear_07.html#sec-linear-autocorr-DW",
    "title": "7  OLS Assumpties",
    "section": "7.1 Onafhankelijke fouten en de Durbin-Watson test",
    "text": "7.1 Onafhankelijke fouten en de Durbin-Watson test\nDe assumptie van onafhankelijke fouten is gerelateerd aan de voorwaarde dat observaties onafhankelijk van elkaar geselecteerd moeten zijn. Aan deze voorwaarde is niet voldaan als er een tijdsrelatie is tussen de observaties of als er sprake is van geografische clustering (bv. gebruik van multistage sampling voor een survey).\nDe Durbin-Watson test kan gebruikt worden om na te gaan of een tijdsrelatie leidt tot een te sterke correlatie tussen de fouten (errors/residuals). De test kan niet gebruikt worden als er geen tijdsrelatie is (bv. een cross-sectionele survey). Bovendien moet de dataset geordend zijn volgens tijd: van oud naar nieuw of van nieuw naar oud.\nDe voorbeelddataset “gdp-dem, time order.csv” voldoet aan deze voorwaarden. Het bevat het BBP (“gdp”) en de democratiescore (“democracy”) voor een enkel land over de jaren heen. De dataset is fictief. Er is geen missing data, maar de syntax kan ook gebruikt worden indien er ontbrekende waarden zijn (‘NA’).\n\ndta &lt;- import(\"gdp-dem, time order.csv\")\nhead(dta, n = 10L) #Zodat we enkel 10 eerste rijen zien\n\n\n\n   year  gdp democracy\n1  1990 8400        50\n2  1991 8500        55\n3  1992 8800        60\n4  1993 8700        60\n5  1994 8600        60\n6  1995 8800        65\n7  1996 9200        65\n8  1997 9300        65\n9  1998 9500        70\n10 1999 9700        70\n\n\nIndien de dataset niet gesorteerd is, kun je dit zelf doen met behulp van de arrange functie uit het dplyr package (onderdeel van tidyverse).\n\n#sorteer oud-nieuw\ndta &lt;- dta |&gt;\n  arrange(year)\n\n#sort nieuw-oud\ndta &lt;- dta |&gt;\n  arrange(desc(year))\n\n\ndta &lt;- dta\n\nMet deze code verduidelijken we dat we willen dat de nieuwe, gesorteerde dataset, de oude overschrijft. We zouden ook een nieuwe dataset kunnen creëren zonder de oude te vervangen, maar dat is meestal niet nodig.\n\narrange(year)\n\nMet deze functie sorteren (‘arrange’) we de dataset volgens de waarden van de variabele tussen haakjes. Op deze manier wordt gesorteerd van lage (oud) naar hogere waarden (nieuw). We kunnen op meerdere variabelen sorteren door deze tussen haakjes toe te voegen, gescheiden van elkaar door een komma.\n\narrange(desc(year))\n\nMet deze syntax laten we de dataset sorteren van hoge (nieuw) naar lage (oud) waarden (“descending”).\n\n\nWe voeren een bivariate regressieanalyse uit met gdp als onafhankelijke variabele en democratie als afhankelijke variabele:\n\ntime_model &lt;- lm(democracy ~ gdp, data = dta)\ntidy(time_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept) -36.2     13.9         -2.61 0.0143      \n2 gdp           0.0111   0.00148      7.50 0.0000000291\n\n\nDan gebruiken we de Durbin-Watson uit het car package.\n\ndurbinWatsonTest(time_model) \n\n lag Autocorrelation D-W Statistic p-value\n   1       0.5124721     0.8369625       0\n Alternative hypothesis: rho != 0\n\n\n\ndurbinWatsonTest(modelname)\n\nWe voeren de Durbin-Watson test uit op het model tussen haakjes.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nAutocorrelation: Mate van correlatie tussen de fouten (errors of residuals)\nD-W Statistic: De Durbin-Watson statistiek. Waarden lager dan 1 en hoger dan 3 wijzen op te hoge autocorrelatie\np-waarde: p-waarde voor de nulhypothese dat de autocorrelatie niet significant van 0 verschilt, de alternatieve hypothese is dat die wel verschilt.\n\n\n\nDe D-W statistiek voor dit model is 0.84. Dit wijst op een probleem met autocorrelatie."
  },
  {
    "objectID": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "href": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "title": "7  OLS Assumpties",
    "section": "7.2 Beperkte multicollineariteit",
    "text": "7.2 Beperkte multicollineariteit\nVoor de andere assumptietests maken we gebruik van data zonder autocorrelatie. We gebruiken onze landendataset (demadata.rds) en schatten een meervoudig regressiemodel waarbij V-Dem polyarchy scores (v2x_polyarchy) voorspeld worden op basis van economische ongelijkheid (gini_2019), regime in het verleden (TYPEDEMO1984: democratie of autocratie in 1984, naar een factor variabele getransformeerd) en BBP in 2006 (GDP2006).\n\n#data laden\ndemdata &lt;- import(\"demdata.rds\") |&gt; \n  as_tibble()\n\n#Factor maken van binaire variabele\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984))\n\n#Meervoudig model schatten en resultaten bekijken\nmodel_multiple &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + GDP2006, data = demdata)\n\nsummary(model_multiple)\n\n\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             6.78e-1   2.02e-1      3.36 0.00153  2.72e-1 1.08     \n2 gini_2019              -4.99e-3   4.98e-3     -1.00 0.322   -1.50e-2 0.00502  \n3 TYPEDEMO1984Democraci…  7.00e-2   5.95e-2      1.18 0.246   -4.97e-2 0.190    \n4 GDP2006                 8.58e-6   2.70e-6      3.17 0.00261  3.14e-6 0.0000140\n\n\nDe coëfficienten voor gini_2019 (p = 0.322) en TYPEDEMO1984 (p = 0.246) zijn niet significant. Om te kijken of er sprake is van te hoge multicollineariteit gebruiken we opnieuw het car package, nu voor de vif() functie.\n\nvif(model_multiple)\n\n   gini_2019 TYPEDEMO1984      GDP2006 \n    1.811074     1.171946     2.039059 \n\n\n\nvif(multiple)\n\nWe gebruiken de vif functie op het model tussen haakjes\n\n\nDe output geeft de VIF statistieken voor elke onafhankelijke variabele. Geen van de waarden is hoger dan 5 dus is er geen sprake van te hoge multicollineariteit.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nIndien je een factor variabele opneemt met 3 of meer oorspronkelijke categorieën (bv. meerdere regio’s, onderwijsniveaus) dan krijg je licht andere output:\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006 = factorize(Typeregime2006))\n\nvif_example &lt;- lm(v2x_polyarchy ~ gini_2019 + GDP2006 + Typeregime2006, data = demdata) \n\nvif(vif_example)\n\n                   GVIF Df GVIF^(1/(2*Df))\ngini_2019      1.385354  1        1.177011\nGDP2006        1.448928  1        1.203714\nTyperegime2006 1.346530  2        1.077219\n\n\nvif() geeft nu een GVIF en GVIF^(1/(2*DF)). Dit zijn aanpassingen gezien categorische variabelen meerdere coëfficiënten hebben en dus vrijheidsgraden. We evalueren multicollineariteit door GVIF^(1/(2*DF)) te kwadrateren en we gebruiken dezelfde vuistregels als bij de gewone VIF. In principe kunnen we ook kijken of GVIF^(1/(2*DF)) op zich hoger is dan 2.23 (gezien 2.23²= 5)."
  },
  {
    "objectID": "linear_07.html#lineariteit-en-additiviteit",
    "href": "linear_07.html#lineariteit-en-additiviteit",
    "title": "7  OLS Assumpties",
    "section": "7.3 Lineariteit en additiviteit",
    "text": "7.3 Lineariteit en additiviteit\nEen lineair regressiemodel berust op de assumptie dat er een lineaire relatie is tussen de predictoren en de afhankelijke variabele. Om te onderzoeken of de assumptie niet geschonden is maken we gebruik van plots, aangemaakt via het ggResidpanel package.\nWe gaan hier eerst de assumptie na voor een simpel model waarbij electorale democratie (v2x_polyarchy) voorspeld wordt door ongelijkheid (gini_2019).\n\nbivar_model &lt;- lm(v2x_polyarchy ~ gini_2019, data=demdata)\n\nresid_panel(bivar_model, plots = c(\"resid\"))\n\n\n\n\n\nresid_panel(bivar_model,\n\nWe voeren de functie resid_panel uit op het model tussen haakjes.\n\nplots = c(\"resid\"))\n\nDe functie kan gebruikt worden voor meerdere soorten plots. Hier verduidelijken we dat we het plot van residuals tegen voorspelde waarden willen (“resid”).\n\n\nOp het plot zien we geen duidelijk patroon in de data, over het algemeen gewoon een puntenwolk. Het ontbreken van een patroon duidt erop dat de relatie tussen ongelijkheid en democratiescores als lineair kan beschouwd worden.\nWanneer je een ordinale variabele gebruikt als predictor in plaats van een echt continue variabele, dan ziet het plot er anders uit (i.e. neerwaarts gaande lijnen van residuals).\n\n7.3.1 Logaritmische functies\nWe krijgen niet altijd gewoon een puntenwolk zonder patroon te zien. Laten we het plot bekijken voor ons complexer model voor democratiescores (model_multiple).\n\nresid_panel(model_multiple, plots = c(\"resid\"))\n\n\n\n\nIn het plot zien we een lijnpatroon bij hogere waarden op de x-as. We kunnen onderzoeken welke onafhankelijke variabele dit patroon veroorzaakt door te kijken naar de partiële regressieplots via de avPlots() functie uit het car package.\n\navPlots(model_multiple)\n\n\n\n\n\navPlots(model_multiple)\n\nWe vragen R om de partiële regressieplots voor het model tussen haakjes.\n\n\nDeze partiële regressieplots (“added-variable plot”) tonen de relatie tussen de predictor en de afhankelijke variabele gecontroleerd voor de andere predictoren in het model.\nVoor de onafhankelijke variabele gini_2019, vinden we een relatief vlakke lijn (de coëfficiënt was ook niet significant). De residuals zijn vrij gelijk verspreid onder en boven de lijn dus er lijkt geen afwijking van lineariteit te zijn.\nVoor de TYPEDEMO1984 factor bekijken we het plot niet gezien we slechts twee waarden voor deze variabele hebben.\nAls we de onafhankelijke variabele GDP2006 bekijken vinden we een positief hellende regressielijn (de coëfficiënt was ook significant), maar de punten zijn niet gelijk verspreid rond de lijn. Het lijkt hier eerder dat de relatie een degressieve curve volgt dan een rechte lijn.\nOm hiervoor te compenseren voeren we een logaritmische transformatie uit op GDP2006.\n\ndemdata &lt;- demdata |&gt;\n  mutate(LNGDP2006 = log(GDP2006))\n\nDeze nieuwe gelogde versie van de variabele wordt vervolgens gebruikt in de regressie in de plaats van de originele variabele. We zouden dan het residual plot en de partiële regressieplots opnieuw kunnen inspecteren.\n\n#Opnieuw schatten model \nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006, \n               data=demdata)\n\n#Residual Plot\nresid_panel(multiple_ln, plots = c(\"resid\"))\n\n\n\n#Partiële regressieplots\navPlots(multiple_ln)\n\n\n\n\n\n\n7.3.2 Kwadratische functies\nEen andere niet-lineaire relatie die we kunnen tegenkomen is de kwadratische of curvilineaire relatie. Bij wijze van voorbeeld hier inspireren we ons op de ‘meer geweld in het midden’-these, namelijk het idee dat landen met hybride regimes (gemiddelde democratiescores) meer geweld en instabiliteit ervaren dan zowel autoritaire systemen (lage democratiescores) als democratische systemen (hoge democratiescores).\nDe variabele voor politiek geweld en instabiliteit is hier pve en is gebaseerd of de 2021 World Governance Indicators. Hogere waarden staan voor minder geweld en instabiliteit. Hier gebruiken we electorale democratie (v2x_polyarchy) als onafhankelijke variabele.\nWe inspecteren hier eerst de empirische, bivariate relatie met behulp van een scatterplot.\n\nggplot(demdata, aes(x = v2x_polyarchy, y = pve)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(title = \"Politiek geweld en democratie\", \n       x = \"Electorale democratie (2020)\", \n       y = \"Afwezigheid van politiek geweld en instabiliteit (2021)\")\n\n\n\n\nDe syntax lijkt sterk op wat we eerder gezien hebben (Section 1.2), met 1 belangrijk verschil:\n\ngeom_smooth(method = \"loess\")\n\nHier vragen we R om een lijn te tekenen om de relatie tussen de 2 variabelen te vatten. We vragen hier niet om een rechte lijn (method=“lm”), maar een ‘locally estimated scatterplot smoothing’ (loess) lijn (method = “loess”). Deze lijn volgt de data zo nauwgezet mogelijk om de relatie tussen de variabelen weer te geven. De loess methode is de standaard (default) methode om de lijn te tekenen. We zouden dus ook gewoon geom_smooth() kunnen schrijven om dezelfde uitkomst te verkrijgen.\n\n\nZoals we kunnen zien als we naar het scatterplot kijken is er enige steun voor een curvilineaire relatie. We schatten nu eerst een lineair regressiemodel:\n\n#schat het model\nViolence_linmodel &lt;- lm(pve ~ v2x_polyarchy, data = demdata)\n\n#bekijk resultaten\ntidy(Violence_linmodel, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term          estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      -1.34     0.135     -9.90 2.36e-18    -1.60     -1.07\n2 v2x_polyarchy     2.19     0.233      9.38 5.75e-17     1.73      2.65\n\n\nDe niet-lineaire relatie kun je soms zien uit het residuals plot, in de vorm van een gebogen patroon, maar dit is visueel minder zichtbaar hier:\n\nresid_panel(Violence_linmodel, plots = c(\"resid\"))\n\n\n\n\nOm te onderzoeken of de relatie beter als kwadratisch wordt gevat voegen we een kwadratische term toe aan het model. We maken deze variabele eerst aan en voegen die dan toe aan het model, samen met de originele variabele.\n\n#gewadrateerde variabele maken\ndemdata &lt;- demdata |&gt; \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n#nieuw model schatten\nViolence_sqmodel &lt;- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n               data=demdata)\n\ntidy(Violence_sqmodel, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -0.589     0.243     -2.42 0.0165      -1.07    -0.109\n2 v2x_polyarchy      -1.73      1.10      -1.58 0.117       -3.90     0.438\n3 v2x_polyarchy_sq    3.83      1.05       3.64 0.000361     1.75     5.90 \n\n\nWe vinden hier dat de kwadratische variabele significant is (p &lt; 0.001) en dus dat de relatie tussen v2x_polyarchy en pve beter als curvilineair dan lineair te beschrijven is.\nWe kunnen dan het residuals plot opnieuw inspecteren (zie onder)."
  },
  {
    "objectID": "linear_07.html#homoskedasticiteit",
    "href": "linear_07.html#homoskedasticiteit",
    "title": "7  OLS Assumpties",
    "section": "7.4 Homoskedasticiteit",
    "text": "7.4 Homoskedasticiteit\nOm te onderzoeken of de assumptie van homoskedasticiteit geschonden is maken we opnieuw gebruik van het residuals plot (scatterplot van voorspelde waarden en residuals). Hier vinden we bijvoorbeeld heteroskedasticiteit voor het kwadratische model (Violence_sqmodel):\n\nresid_panel(Violence_sqmodel, plots = c(\"resid\"))\n\n\n\n\nOpnieuw zien we liever een wolk van toevallig verspreide punten (homoskedasticiteit) eerder daan een trechter-vorm (heteroskedasticiteit). De trechter-vorm in het plot wijst erop dat de assumptie geschonden is."
  },
  {
    "objectID": "linear_07.html#normaal-verdeelde-errors",
    "href": "linear_07.html#normaal-verdeelde-errors",
    "title": "7  OLS Assumpties",
    "section": "7.5 Normaal verdeelde errors",
    "text": "7.5 Normaal verdeelde errors\nWe onderzoeken of de assumptie van normaal verdeelde errors is geschonden met behulp van 2 mogelijke plots uit het ggResidpanel package: een histogram van de fouten en een kwartielplot (qq-plot) van de fouten.\nHier gaan we na of de assumptie geschonden is voor ons meervoudig regressiemodel met gelogde GDP predictor (multiple_ln):\n\nresid_panel(multiple_ln, plots = c(\"hist\", \"qq\"))\n\n\n\n\n\nplots = c(\"hist\", \"qq\"))\n\nHier vragen we om het histogram (“hist”) samen met het qq-plot (“qq”).\n\n\nWe zouden ook het residuals plot (“resid”) kunnen toevoegen indien we meerdere assumpties vlug samen willen testen:\n\nresid_panel(multiple_ln, plots = c(\"resid\", \"hist\", \"qq\"))"
  },
  {
    "objectID": "linear_07.html#beperkte-impact-outliers-en-influential-cases",
    "href": "linear_07.html#beperkte-impact-outliers-en-influential-cases",
    "title": "7  OLS Assumpties",
    "section": "7.6 Beperkte impact outliers en influential cases",
    "text": "7.6 Beperkte impact outliers en influential cases\nWe gebruiken de augment() functie uit het broom package op de meervoudig regressie met gelogde GDP predictor (multiple_ln). De statistieken worden in een nieuwe dataset opgeslagen in onderstaande code.\n\n#augment gebruiken en resultaten opslaan in nieuw object\ndemdata_multln &lt;- augment(multiple_ln)\n\n\ndemdata_multln &lt;-augment(multiple_ln)\n\nWe gebruiken de augment functie op het model tussen haakjes en slaan de resultaten op in een nieuw data object (demdata_multln).\n\n\nDe gegevens in het dataobject zien er als volgt uit:\n\ndemdata_multln\n\n# A tibble: 53 × 11\n   .rownames v2x_polyarchy gini_2019 TYPEDEMO1984 LNGDP2006 .fitted   .resid\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;            &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 3                 0.908      26.5 Democracies      10.3    0.857  0.0514 \n 2 4                 0.894      30.1 Democracies      10.5    0.881  0.0129 \n 3 10                0.485      37.5 Autocracies       7.38   0.480  0.00510\n 4 13                0.652      48   Democracies       7.75   0.559  0.0925 \n 5 14                0.632      29.3 Autocracies       8.62   0.625  0.00694\n 6 15                0.678      47.6 Democracies       8.31   0.632  0.0464 \n 7 16                0.807      38.7 Democracies      10.5    0.906 -0.0995 \n 8 17                0.882      32.1 Democracies       9.32   0.733  0.149  \n 9 18                0.577      37.3 Democracies       7.68   0.530  0.0466 \n10 20                0.327      40.7 Democracies       6.99   0.447 -0.120  \n# ℹ 43 more rows\n# ℹ 4 more variables: .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\naugment() creëert een dataframe met alle observaties die gebruikt zijn om het model te schatten. Je vindt de volgende kolommen terug:\n\n.rownames: Di is het rijnummer van de observatie zoals je die vindt in de originele dataset (zonder eventuele missing waarden)\nv2x_polyarchy tot en met LNGDP2006: Dit zijn de variabelen gebruikt in het model met de waarden die elke observatie ervoor heeft.\n.fitted: De voorspelde (‘fitted’) waarden op basis van de schattingen in het model.\nresid: De residuals (fouten/errors) voor elke observatie, waarbij Residual = Observed - Fitted/Predicted. Hier: Residual = v2x_polyarchy - .fitted\n.hat: Diagonaal van de hat matrix (te negeren).\n.sigma: Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n.cooksd: De Cook’s D waarde voor de observatie. Zie onder.\n.std.resid: Niet getoond in de output hierboven maar aanwezig in de dataset. Deze kolom bevat de gestandaardiseerde residuals van het model. Zie onder.\n\n\n\nWe gebruiken de gestandaardiseerde residuals (.std.resid) om eerst outliers te onderzoeken. Vervolgens gebruiken we de Cook’s D waarden (.cooksd) om influential cases te onderzoeken.\n\n7.6.1 Outliers analyseren\nOm te beginnen bekijken we de descriptieve statistieken voor de gestandaardiseerde residuals (opgeslagen in het data object demdata_multln) . We kijken specifiek naar de minimum en maximum waarden als eerste check voor outliers. We bekijken in het bijzonder of gestandaardiseerde residuals hoger zijn dan de drempelwaarden van (|1.96|, |2.54|, en zeker |3.29|).\n\nsummary(demdata_multln$.std.resid)\n\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-3.1281471 -0.2252984  0.2109869 -0.0007828  0.5831831  1.7394397 \n\n\nWe vinden waarden die zorgwekkend kunnen zijn. Zo is er al zeker 1 observatie waarvan de gestandaardiseerde residual een absolute waarde hoger dan 2.58 heeft (aangezien het minimum -3.128 is). Maar we moeten nog nagaan hoeveel observaties precies de drempelwaarden overschrijden.\nWe doen dit door 3 dummy variabelen aan te maken in onze dataset: SRE1.96, SRE2.58, SRE3.29. Deze dummy variabelen nemen de waarde ‘1’ aan als de gestandaardiseerde residual van een observatie hoger is dan de drempelwaarde in de naam van de variabele. Als de waarde van de gestandaardiseerde residual lager is, neemt de dummy de waarde ‘0’ aan. We gebruiken hier de case when functie (uit dplyr) voor de hercodering. Zie Statistiek I, 5.1\nOnderstaande code kun je grotendeels onaangepast laten in je eigen voorbeelden, enkel de naam van de dataset (hier: demdata_multln) moet aangepast worden voor eigen toepassingen.\n\ndemdata_multln &lt;- demdata_multln |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n         SRE2.58 = case_when(\n    .std.resid &gt; 2.58 | .std.resid &lt; -2.58  ~ 1,\n    .std.resid &gt; -2.58 & .std.resid &lt; 2.58 ~ 0),\n        SRE3.29 = case_when(\n    .std.resid &gt; 3.29 | .std.resid &lt; -3.29  ~ 1,\n    .std.resid &gt; -3.29 & .std.resid &lt; 3.29 ~ 0\n  ))\n\n\ndemdata_multln &lt;- demdata_multln |&gt;\n\nDe nieuwe variabelen maken gebruik van de demdata_multln dataset (voor de .std.resid variabele), en worden ook zelf opgeslagen in deze dataset.\n\nmutate(SRE1.96 = case_when(\n\nWe creëren hier de nieuwe variabele SRE1.96. De waarden worden bepaald door de case_when functie.\n\n.std.resid &gt; 1.96 | .std.resid &lt; -1.96 ~ 1,\n\nHier duiden we aan dat wanneer gestandaardiseerde residuals groter dan 1.96 of (de streep ‘|’ staat symbool voor ‘of’ ) lager dan -1.96 zijn, de SRE1.96 variabele de waarde 1 aanneemt (~). Let erop dat de variabele .std.resid twee keer geschreven moet worden.\n\n.std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n\nHier duiden we aan dat wanneer gestandaardiseerde residuals groter dan -1.96 en (de ‘&’ staat hier voor ‘en’) lager dan 1.96 zijn, de SRE1.96 variabele de waarde 0 aanneemt (~).\n\n\nNu we de dummies aangemaakt hebben kunnen we frequentietabellen voor elk van hen bekijken. We maken gebruik van de fre() functie uit het expss package.\nDe code hieronder kun je wederom grotendeels gebruiken voor eigen voorbeelden; enkel de naam van de dataset (hier: demdata_multln) dient veranderd te worden voor eigen toepassingen.\n\nfre(demdata_multln$SRE1.96)\n\n\n\n\ndemdata_multln$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n49\n92.5\n92.5\n92.5\n92.5\n\n\n 1 \n4\n7.5\n7.5\n7.5\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\nfre(demdata_multln$SRE2.58)\n\n\n\n\ndemdata_multln$SRE2.58\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n51\n96.2\n96.2\n96.2\n96.2\n\n\n 1 \n2\n3.8\n3.8\n3.8\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\nfre(demdata_multln$SRE3.29)\n\n\n\n\ndemdata_multln$SRE3.29\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n53\n100\n100\n100\n100\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0\n\n\n\n\n\n\n\nWe vinden hier dat meer dan 5% van de observaties een gestandaardiseerde residual heeft met een absolute waarde hoger dan 1.96, meer dan 1% heeft een gestandaardiseerde residual met een absolute waarde hoger dan 2.58. Er is geen enkele observatie met een absolute waarde hoger dan 3.29 (dit konden we reeds aflezen uit de descriptieve statistieken).\nOm te onderzoeken of de outliers ook een invloed hebben op de resultaten van het model vergelijken we de resultaten van ons model met die van een nieuw model zonder outliers. Hier doen we dit voor outliers met gestandaardiseerde residuals met absolute waarde hoger dan 1.96. De SRE1.96 variabele kan vervangen worden met de SRE2.58 en SRE3.29 variabelen om alternatieve manieren om outliers uit te sluiten te onderzoeken.\n\nmultiple_ln1.96 &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n               data = subset(demdata_multln, SRE1.96 == 0))\n\n\ndata = subset(demdata_multln, SRE1.96 == 0))\n\nMet deze code gebruiken we de demdata_multln dataset gecreëerd met augment, maar we behouden enkel observaties die voor de variabele SRE1.96 de waarde 0 hebben.\n\n\nAls we de modellen met en zonder outliers vergelijken gaan we na of de coëfficiënten en hun significantie substantieel veranderd zijn. Let wel, outliers kunnen niet zomaar verwijderd worden om om de model fit te verbeteren. Er moet een gemotiveerde, theoretische reden zijn voor uitsluiting van observaties.\n\n\n7.6.2 Influential cases analyseren\nOm influential cases te onderzoeken gaan we na of er observaties zijn in de dataset met hoge Cook’s D waarden:\n\nwaarden hoger dan 1 zijn over het algemeen zorgwekkend;\nwaarden hoger dan 0.5 moeten nader bestudeerd worden en kunnen een risico vormen;\nwaarden die veel hoger zijn dan de andere Cook’s D waarden behoeven ook verdere aandacht.\n\nWe bekijken eerst de overzichtsstatistieken voor de Cook’s D waarden.\n\nsummary(demdata_multln$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000036 0.0007700 0.0035030 0.0292621 0.0162039 0.6608136 \n\n\nHet overzicht toont dat er minstens 1 observatie is met een hoge Cook’s D waarde. De maximum waarde is 0.66 en deze waarde is substantieel hoger dan de andere waarden. De waarde voor het 3de kwartiel is slechts 0.016, wat betekent dat 75% van de observaties een waarde lager hebben dan 0.016.\nWe kunnen ook een visualisatie maken van de Cook’s D waarden met het ggResidpanel package:\n\nresid_panel(multiple_ln, plots = c(\"cookd\"))\n\n\n\n\n\nplots = c(\"cookd\"))\n\nWe vragen hier om een plot met Cook’s D waarden op de y-as. Het rijnummer van de observatie in de dataset komt op de x-as.\n\n\nDe grafiek toont dat er slechts 1 case is om ons zorgen over te maken. Dit is de case met de maximum waarde van 0.66.\nWe kunnen deze case verwijderen uit het model om na te gaan of de resultaten beïnvloed worden:\n\nmultiple_lncook &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n               data = subset(demdata_multln, .cooksd &lt; 0.65))\n\n\ndata = subset(demdata_multln, .cooksd &lt; 0.65))\n\nWe gebruiken de demdata_multln dataset maar vragen om een subset van de data met enkel die observaties met een waarde lager dan 0.65 voor .cooksd. We kiezen deze waarde hier omdat de case die we willen uitsluiten een waarde van 0.66 heeft. In principe hadden we ook 0.66 zelf, 0.64 enz. kunnen kiezen, zolang het een grenswaarde is die de mogelijk invloedrijke casus uitsluit.\n\n\nWe kunnen ook outliers en influential cases tegelijk uitsluiten als we in de syntax gebruik maken van het ‘&’ teken:\n\nmultiple_ln_excl &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n               data = subset(demdata_multln,\n                             SRE1.96==0 & .cooksd &lt; 0.65))\n\n\n\n7.6.3 Specifieke probleemgevallen analyseren\nWat we in vorige analyses niet bekeken hebben is welke specifieke observaties outliers of influential cases waren. Om dit te kunnen doen moeten we de gestandaardiseerde residuals en Cook’s D waarden toevoegen aan onze originele dataset, waar we de country name variabele hebben.\nIndien er missende waarden zijn, zoals hier het geval is, kunnen we deze statistieken niet zomaar met augment toevoegen aan de originele dataset. Een oplossing is om eerst een dataset te creëren met niet-missende waarden voor de variabelen gebruikt in het model en dan met augment de statistieken aan deze ‘complete cases’ dataset toe te voegen:\n\n# subset van de dataset zonder 'NA' waarden\ndemdata_complete &lt;- demdata |&gt;\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984, LNGDP2006))\n\n# model opnieuw geschat met nieuwe dataset\nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006, \n               data=demdata_complete)\n\n# augment gebruiken om statistieken toe te voegen\ndemdata_complete &lt;-augment(multiple_ln, data=demdata_complete)\n\nNu kunnen we specifieke outliers onderzoeken met de volgende code:\n\ndemdata_complete |&gt; \n  filter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96) |&gt;\n  select(country_name, .std.resid)\n\n# A tibble: 4 × 2\n  country_name .std.resid\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Thailand          -2.17\n2 Venezuela         -2.68\n3 China             -2.53\n4 Singapore         -3.13\n\n\n\nfilter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96)\n\nHier willen we outliers vinden, dus we filteren voor observaties met gestandaardiseerde residual hoger dan 1.96 of lager dan -1.96.\n\nselect(country_name.std.resid)\n\nHier vragen we R om de namen van de landen en hun specifieke gestandaardiseerde residual.\n\n\nDe influential case vinden we op een gelijkaardige manier:\n\ndemdata_complete |&gt; \n  filter(.cooksd &gt; 0.65) |&gt;\n  select(country_name, .cooksd)\n\n# A tibble: 1 × 2\n  country_name .cooksd\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Singapore      0.661"
  },
  {
    "objectID": "linear_08.html#sec-report-scatterplots",
    "href": "linear_08.html#sec-report-scatterplots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.1 Puntenwolken of Scatterplots",
    "text": "8.1 Puntenwolken of Scatterplots\nWe kunnen een visuele weergave tonen van de bivariate relatie tussen twee continue variabelen in een puntenwolk of scatterplot. Hieronder is een voorbeeld voor de variabelen gini_2019 en v2x_polyarchy:\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(x = \"Economische Ongelijkheid\", \n       y = \"Electorale Democratie\", \n       title = \"Economische Ongelijkheid en Electorale Democratie\")\n\n\n\n\n\n8.1.1 Rapportage\nDe volgende zaken kun je best benoemen wanneer je een scatterplot bespreekt:\n\nDe richting van de relatie, alsook de sterkte (maar let op dat je best ook de correlatiecoëfficiënt bekijkt gezien visuele weergaven ook misleidend kunnen zijn).\nPatronen of trends in het plot.\nCases die extreme waarden hebben of cases die als outliers kunnen beschreven worden.\n\n\n\n8.1.2 Instructies\n\nZorg ervoor de je informatieve labels hebt voor de x -en y-as en een duidelijke titel.\nJe kan de regressielijn toevoegen aan het plot om de interpretatie te verduidelijken. Dit kan je doen met de syntax method = \"lm\". Je kunt de syntax veranderen naar method = \"loess\" om een ‘locally estimated scatterplot smoothing’ line te plotten. Dit is handig voor het spotten van niet-lineaire patronen in de data. Zie Section 7.3.2\nLet op de tekstgrootte op de assen en zorg dat de tekst goed leesbaar is. De grootte van het lettertype kun je aanpassen met de syntax om het visuele thema van de figuur te veranderen, bv. door het volgende toe te voegen: + theme_grey(14) of + theme_bw(18). Het nummer tussen haakjes bepaalt de grootte van het lettertype.Je kunt een lijst met de ingebouwde visuele ggplot schema’s hier vinden. Bijkomende opties zijn beschikbaar in het ggthemes package. Meer complexe veranderingen, zoals verschillende tekstgroottes voor titel en astitels, kun je uitvoeren via theme(), maar dit behandelen we niet in dit document.\nBovenstaand plot toont de bivariate relatie tussen twee continue variabelen met toevoeging van de regressielijn. We kunnen ook de formule van de lijn toevoegen met geom_text(). Dit doen we door een + toe te voegen na labs() en de volgende regel toe te voegen: geom_text(x = 40, y=0.1, label=\"Dem Score = 1.06 + (-0.012 * Inequality)\") . De formule vind je met lm(zie onder). De x= en y=gedeelten geven de waarden (coördinaten) weer waar het label in het plot moet komen. Het kan nodig zijn de waarden stelselmatig aan te passen om een mooie weergave te bereiken. Bepaalde packages in R kunnen dit proces vergemakkelijken, zoals deze functie uit het ggpubr package. Dit package behoort niet tot de leerstof."
  },
  {
    "objectID": "linear_08.html#correlaties",
    "href": "linear_08.html#correlaties",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.2 Correlaties",
    "text": "8.2 Correlaties\nVoor dit voorbeeld berekenen we de Pearson correlatie tussen economische ongelijkheid (hogere waarden = meer ongelijk; gini_2019) en electorale democratie (hogere waarden = meer democratie; v2x_polyarchy).\n\ncor1 &lt;- cor.test(x = demdata$gini_2019, \n                 y = demdata$v2x_polyarchy, \n                 method = 'pearson')\n\ncor1\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nZie Section 1.4 voor richtlijnen over de interpretatie van correlatiecoëfficiënten.\n\n8.2.1 Rapportage\nDe volgende zaken neem je best op in je rapportage:\n\nDe specifieke correlatie je gebruikt hebt (bv. Pearson).\nEen bespreking van de richting van de relatie (positief, negatief, geen relatie), waarbij ook aandacht is voor de codering van gebruikte variabelen.\nEen bespreking van de statistische significantie:\n\nSignificantie hebben we meestal op de niveaus van 95% (p &lt; 0.05), 99% (p &lt; 0.01), en 99.9% (p &lt; 0.001) 1\nRaporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\n\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nEen bespreking van de sterkte van de relatie. (zie Section 1.4)\n\n\n\n\n\n\n\nVoorbeeld rapportage\n\n\n\nHogere waarden voor economische ongelijkheid hangen samen met lagere waarden voor electorale democratie (\\(r\\) = -0.35). De associatie heeft een gemiddelde sterkte en is statistisch significant (p \\(&lt;\\) 0.01).\n\n\n\n\n8.2.2 Presentatie: Correlatietabellen\nWanneer we slechts de correlatie tussen twee variabelen beschrijven, kunnen we deze discussie gewoon in onze tekst opnemen zoals hierboven. Wanneer we echter analyses doen met meerdere continue variabelen is het een goede praktijk om een correlatietabel op te stellen die de correlatie tussen deze variabelen weergeeft. Deze tabel kan in de hoofdtekst van een paper of in een appendix worden opgenomen. De tabel kan aangemaakt worden met de datasummary_correlation() functie uit het modelsummary package. Hier is een voorbeeld met 4 variabelen:\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Elec. Democracy\" = v2x_polyarchy, \n         \"Econ Inequality\" = gini_2019, \n         \"Corruption\" = cpi, \n         \"GDP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relationship between Main Continuous Variables\")\n\n\nRelationship between Main Continuous Variables\n\n\n\nElec. Democracy\n Econ Inequality\nCorruption\nGDP\n\n\n\n\nElec. Democracy\n1\n.\n.\n.\n\n\nEcon Inequality\n-.35\n1\n.\n.\n\n\nCorruption\n.66\n-.53\n1\n.\n\n\nGDP\n.40\n-.52\n.79\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nElke cel bevate een correlatiecoëfficiënt voor 2 gepaarde variabelen. De correlatie tussen corruptie en economische ongelijkheid is bijvoorbeeld -0,53, terwijl de correlatie tussen GDP en corruptie 0,79 is.\nOpmerking: De titel wordt in dit document onderaan de tabel weergegeven, maar wordt bovenaan afgedrukt bij het opslaan in een Word-document (zie hieronder), wat de meer conventionele plaatsing is.\n\n\nZo lees je de syntax:\n\ndemdata |&gt; select(…)\n\nHier selected we de dataset (demdata) en de variabelen waartussen we de correlaties willen berekenen. Zonder select(…) berekent R de correlaties tussen alle variabelen in de dataset!\n\nrename(…)\n\nWe geven de variabelen een andere naam zodat presentatie van de variabelen in de tabel duidelijker is voor lezers.\n\ndatasummary_correlation(method = \"pearson\", title = \"...\")\n\nHier duiden we aan welke correlatie we precies willen en geven we een duidelijke titel (Pearson correlation: method = “pearson”; Spearman: method = “spearman”).\n\n\nWe kunnen deze tabel naar een Microsoft Word bestand exporteren zodat we de tabel kunnen gebruiken in eigen papers met volgende syntax toevoeging (Je ziet de tabel nu wel niet langer in R verschijnen):\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Elec. Democracy\" = v2x_polyarchy, \n         \"Econ Inequality\" = gini_2019, \n         \"Corruption\" = cpi, \n         \"GDP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relationship between Main Continuous Variables\", \n                          output = \"correlation table example.docx\")\n\n\noutput = \"correlation table example.docx\"\n\nHier vragen we de output te exporteren naar een Word (.docx) bestand. De naam van het bestand bepaal je zelf. Het bestand is terug te vinden in je projectfolder of de folder waar je syntax bestand (script of Markdown) zich in bevindt. In Word kunnnen nog verdere aanpassingen worden gedaan. 2\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nJe kunt problemen tegenkomen met deze syntax indien je je Word-bestand met tabel open hebt in Word en de syntax nogmaals runt, bijvoorbeeld om een foutje te corrigeren. We raden aan het Word bestand altijd te sluiten voor je de syntax opnieuw runt.\n\n\n\n8.2.2.1 Instructies\n\nDoorgaans plaatsen we de afhankelijke variabele op de eerste rij in een correlatietabel. Dit doe je door de variabele als eerste te noemen in de select() regel van de syntax hierboven.\nDe variabelen hernoem je zodat het duidelijk is voor de lezer wat ze inhouden. Gebruik dus niet gewoon de naam van de variabelen zoals ze opgeslagen zijn in de dataset.\nGeef de tabel een informatieve titel.\nHet is gebruikelijk om asterisks te plaatsen in de tabel om statistische significantie weer te geven (*** = p &lt; 0.01, ** = p &lt; 0.01, * = p &lt; 0.05). Jammergenoeg kan datasummary_correlation() dit niet automatisch toevoegen. Wel kun je deze symbolen manueel (op basis van cor.test) toevoegen aan een tabel in een .docx (Word) bestand.\nCorrelatie (en regressie) tabellen gemaakt met modelsummary kun je verder aanpassen met instructies op deze webpagina. Dit is echter niet nodig voor dit vak."
  },
  {
    "objectID": "linear_08.html#sec-reporting-linear-regression",
    "href": "linear_08.html#sec-reporting-linear-regression",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.3 OLS Regressiemodellen",
    "text": "8.3 OLS Regressiemodellen\nLineaire regressie, oftewel OLS (Ordinary Least Squares) regressie modelleert veranderingen in het gemiddelde van een afhankelijke variabele als lineaire functie van een of meerdere onafhankelijke variabelen. We gebruiken hier de demdata dataset en voorspellen electorale democratiescores in het jaar 2020 als functie van economische ongelijkheid (gini_2019), de status van het regime van een land in 1984 (TYPEDEMO1984) en regio van de wereld waarin een land is gesitueerd (1 = Europa, 2 = Afrika, 3 = Azië, 4 = Amerikas).\nHieronder vind je de syntax en output in R. Deze output neem je niet rechtstreeks op in een paper. In de plaats daarvan maak je een formele tabel of een coëfficiëntenplot (zie onder).\n\n#Factorize categorical variables\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984), \n         region = factor(region, \n                    levels=c(2,3,1,4), #Ref group is listed first\n                    labels=c(\"Africa\", \"Asia\", \"Europe\", \"Americas\")))\n\n#model schatten en opslaan\nexample_model &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n                    data=demdata)\n\n#Resultaten\nsummary(example_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n    data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52522 -0.06736  0.03585  0.09521  0.37555 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)              0.899777   0.271068   3.319  0.00175 **\ngini_2019               -0.013400   0.005693  -2.354  0.02282 * \nTYPEDEMO1984Democracies  0.067402   0.061709   1.092  0.28028   \nregionAsia               0.040365   0.149003   0.271  0.78765   \nregionEurope             0.244037   0.157307   1.551  0.12753   \nregionAmericas           0.253473   0.150635   1.683  0.09907 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1893 on 47 degrees of freedom\n  (126 observations deleted due to missingness)\nMultiple R-squared:  0.4378,    Adjusted R-squared:  0.378 \nF-statistic:  7.32 on 5 and 47 DF,  p-value: 3.842e-05\n\n\nVoor interpretatierichtlijnen, zie Section 4.1.\n\n8.3.1 Rapportage\nJe rapport bevat best de volgende zaken:\n\nEen bespreking van de richting van de relatie (positief/negatief) en een inhoudelijke interpretatie van wat dit concreet betekent op basis van hoe de variabelen gemeten zijn en welke schaal zij hebben.\n\nBij een multiple regressie is het belangrijk te verduidelijken dat het effect dat je vindt voor een onafhankelijke variabele gecontroleerd is op de andere onafhankelijke variabelen in het model. Deze worden ‘constant gehouden’ (oftewel ‘ceteris paribus’).\n\nEen bespreking van de statistische significantie (verwerpen of niet nulhypothese?) met vermelding van p-waarde en/of het betrouwbaarheidsinterval.\n\nCoëfficiënten met p-waarden groter dan 0.05 worden meestal niet als statistisch significant of als statistisch significant bij conventionele niveaus beschouwd.3 Rapporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nHet betrouwbaarheidsinterval kan ook gebruikt worden om statistische significantie te bespreken en de onzekerheid rond de geschatte coëfficiënten aan te duiden. Als je het betrouwbaarheidsinterval bespreekt, kun je dit tussen haakjes toevoegen na de coëfficiënt, bv. “De coëfficiënt voor economische ongelijkheid is 0.8 (95% CI: 0.5, 1.1)”.\nHet is minder gebruikelijk de t-statistiek concreet te benoemen, maar het is ook geen probleem als je dit doet. Indien de t-waarde wordt opgenomen, zet je deze bij de p-waarde: “(t = 1.98, p &lt; 0.05)”.\n\n\nHier vind je uitgewerkte voorbeelden voor gini_2019 (een continue variabele) en TYPEDEMO1984 (een binaire variabele).\n\n\n\n\n\n\nReport\n\n\n\ngini_2019: We verwachten dat het niveau van electorale democratie lager is als economische ongelijkheid stijgt, gecontroleerd op de effecten van regimestatus in het verleden en regio in de wereld. Gebaseerd op het model verwachten we dat electoral democratie met -0.01 eenheden daalt als economische ongelijkheid met 1 eenheid stijgt. Dit effect is statistisch signifcant (p &lt; 0.05).\nTYPEDEMO1984: Het regressiemodel toont dat landen die als democratie werden beschouwd in 1984 ook vandaag democratischer zijn. Gemiddeld genomen scoren deze landen 0.07 eenheden hoger op electorale democratie in 2020 dan landen die in 1984 geen democratie waren, gecontroleerd op ongelijkheid en regio in de wereld. Het verschil is echter niet statistisch significant (p &gt; 0.05).\n\n\nBijkomende tips:\n\nIn een bespreking van een onderzoek kun je behalve een discussie van de coëfficiënten ook een bespreking van voorspelde waarden opnemen (bv. welk niveau van democratie verwacht je bij hoge en lage ongelijkheid volgens je model). Een plot van voorspelde waarden kan de bespreking verder verduidelijken. Zie Section 8.6 voor meer informatie.\nAls je onderzoek vooral gericht is op de relatie tussen een specifieke onafhankelijke variabele en de afhankelijke variabele dan is een discussie van de coëfficiënten van de controlevariabelen doorgaans niet nodig.\nHet intercept wordt zelden vermeld in onderzoekspapers. In een bivariaat model waarbij de predictor binair is, is het intercept wel inhoudelijk interessant, want dan staat de 0 voor de gemiddelde score op de afhankelijke variabele voor de referentiecategorie. In een experiment zou je bijvoorbeeld scores vergelijken van de controlegroep (X=0) en de experimentele groep (x=1).\nWees voorzichting in je bespreking van de relatie tussen de variabelen. Causaliteit is moeilijk te bepalen en is onderhevig aan sterke voorwaarden. Je schrijft bijgevolg dus meestal niet het “effect van X op Y” , maar “deze verandering in X is geassocieerd met deze verandering in Y”."
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "href": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.4 Lineaire Regressietabellen",
    "text": "8.4 Lineaire Regressietabellen\nEen gebruikelijke methode om de resultaten van regressiemodellen te presenteren is met behulp van een tabel. Via het modelsummarypackage (en functie met dezelfde naam) kunnen we R gebruiken om zo’n tabel aan te maken.\n\n8.4.1 Regressietabel voor 1 model\nAls voorbeeld maken we hier een regressietabel voor een model waarin de score voor electorale democratie voorspeld wordt aan de hand van 1 onafhankelijke variabele: de corruptieperceptie-index (cpi). Hieronder vinden we de standaard output zonder toevoegingen:\n\n#Schatten en opslaan van het model\nmodel1 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata)\n\n#basisfunctie voor regressietabel\nmodelsummary(model1)\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n0.140\n\n\n\n(0.036)\n\n\ncpi\n0.009\n\n\n\n(0.001)\n\n\nNum.Obs.\n174\n\n\nR2\n0.438\n\n\nR2 Adj.\n0.435\n\n\nAIC\n-78.1\n\n\nBIC\n-68.6\n\n\nLog.Lik.\n42.061\n\n\nF\n134.123\n\n\nRMSE\n0.19\n\n\n\n\n\n\n\n\nmodelsummary(\n\nNaamn van de functie\n\nmodel1,\n\nnaam van het model waarvan we de resultaten in een tabel willen presenteren.\n\n\nDeze tabel kan verbeterd worden. Ten eerste kunnen we de statistische significantie van de coëfficiënten aanduiden met een asterisk (*) of andere symbolen. Ten tweede kunnen we onze variabelen duidelijkere labels geven. Ten derde kunnen we model fit statistieken die minder interessant zijn weglaten uit de tabel. Ten slotte kunnen we een titel en onderschrift toevoegen.\nDit doen we met volgende syntax:\n\nmodelsummary(model1, \n1             stars = TRUE,\n2             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\"), \n3             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n4             title = \"Electorale Democratie voorspeld door corruptie\",\n5             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes\")\n\n\n1\n\nVoegt “stars” of asterisks toe voor statistische significantie.\n\n2\n\nWe hernoemen de variabeln voor de duidelijkheid coef_rename()\n\n3\n\nWe selecteren de fit statistieken die we willen rapporteren gof_map()\n\n4\n\nWe geven een titel aan de table title =\n\n5\n\nEn ten slotte geven we informatie aan de lezer over wat we precies weergeven notes =\n\n\n\n\n\nElectorale Democratie voorspeld door corruptie\n\n\n\n (1)\n\n\n\n\nConstante\n0.140***\n\n\n\n(0.036)\n\n\nCorruptieperceptie-index\n0.009***\n\n\n\n(0.001)\n\n\nNum.Obs.\n174\n\n\nR2\n0.438\n\n\nR2 Adj.\n0.435\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes\n\n\n\n\n\n\n\n\n\n\nstars = TRUE,\n\nMet deze optie voegen we symbolen voor statistische significantie toe. De legende voor de symbolen wordt automatisch toegevoegd aan de tabel.\n\ncoef_rename = c(...)\n\nMet deze functie kunnen we de namen van de onafhankelijke variabelen hernoemen. We doen dit voor het intercept en voor cpi. Voor zowel de originele naam als de nieuwe naam gebruik je dubbele (of enkele) aanhalingstekens.\n\ngof_map = c(...)\n\nHier geven we aan welke “goodness of fit” (gof) statistieken we willen. We voegen hier de statistieken die we willen toe: het aantal observaties (“nobs”), de R² (“r.squared”), en de adjusted R² (“adj.r.squared”). De andere statistieken worden dan weggelaten.4\n\ntitle = ...\n\nTitel voor de tabel.\n\nnotes = (...)\n\nOnderschrift voor de tabel. Hier verduidelijk je aan de lezer wat er precies af te lezen valt: de lineaire regressiecoëfficiënten met standaardfouten tussen haakjes.\n\n\n\n\n8.4.2 Regressietabel met meerdere modellen\nWe kunnen modelsummary() ook gebruiken om een regressietabel met meerdere modellen te maken. Bijvoorbeeld, een model met enkel cpi en een model met alle predictors. We kunnen de modellen eerst in een lijst (‘list’) opslaan en dan modelsummary() op de lijst gebruiken. De rest van de syntax blijft grotendeels hetzelfde behalve de toevoeging van de andere onafhankelijke variabelen in het coef_rename() gedeelte.\n\n#model met 3 predictors\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#lijst maken\nmodel_list &lt;- list(model1, model2)\n\n#lijst gebruiken in modelsummary()\nmodelsummary(model_list, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerikas\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\")\n\n\nElectorale democratie voorspeld door corruptie, politiek geweld en regio\n\n\n\n (1)\n  (2)\n\n\n\n\nConstante\n0.140***\n0.178***\n\n\n\n(0.036)\n(0.038)\n\n\nCorruptieperceptie-index\n0.009***\n0.007***\n\n\n\n(0.001)\n(0.001)\n\n\nPolitiek geweld\n\n-0.009\n\n\n\n\n(0.010)\n\n\nAzië\n\n-0.090**\n\n\n\n\n(0.034)\n\n\nEuropa\n\n0.108*\n\n\n\n\n(0.042)\n\n\nAmerikas\n\n0.145***\n\n\n\n\n(0.041)\n\n\nNum.Obs.\n174\n174\n\n\nR2\n0.438\n0.559\n\n\nR2 Adj.\n0.435\n0.546\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\n\n\n\n\n\n\n\n\n\n\nDe functie zal standaard het eerste model ‘Model 1’ noemen en het tweede ‘Model 2’. We kunnen dit desgewenst veranderen met behulp van onze lijst, waarin we dan niet alleen de namen van de objecten aangegeven maar ook de naam die we aan het model willen geven (door middel van: ‘naam model in tabel’ = object):\n\n#lijst met namen\nmodel_list_named &lt;- list(\n  'Enkel Corruptie' = model1, \n  'Alle predictoren' = model2)\n\n#tabel maken\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerikas\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\")\n\n\nElectorale democratie voorspeld door corruptie, politiek geweld en regio\n\n\n\nEnkel Corruptie\nAlle predictoren\n\n\n\n\nConstante\n0.140***\n0.178***\n\n\n\n(0.036)\n(0.038)\n\n\nCorruptieperceptie-index\n0.009***\n0.007***\n\n\n\n(0.001)\n(0.001)\n\n\nPolitiek geweld\n\n-0.009\n\n\n\n\n(0.010)\n\n\nAzië\n\n-0.090**\n\n\n\n\n(0.034)\n\n\nEuropa\n\n0.108*\n\n\n\n\n(0.042)\n\n\nAmerikas\n\n0.145***\n\n\n\n\n(0.041)\n\n\nNum.Obs.\n174\n174\n\n\nR2\n0.438\n0.559\n\n\nR2 Adj.\n0.435\n0.546\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.3 Opslaan als Word document\nWe kunnen de regressietabellen gemaakt met modelsummary() ook opslaan in een Word document door de optie ‘output’ te gebruiken:\n\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerikas\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\", \n             output = 'regressie_tabel.docx') \n\n\noutput = 'regressie_tabel.docx'\n\nHier vragen we om een Word document (.docx) genaamd “regressie_tabel” op te slaan. Dit bestand vind je terug in je R project folder. Je kan ook een subfolder aanduiden, bv. “Output folder/regressie_tabel.docx”. Let erop dat je het Word document niet geopend hebt als je de syntax opnieuw wil gebruiken met aanpassingen, anders kun je een foutmelding krijgen.\n\n\n\n\n8.4.4 Instructies\n\nHet is gebruikelijk de ongestandaardiseerde coëfficiënt weer te geven met standaardfouten tussen haakjes onder de coëfficiënt. Dit is de standaardoutput voor de modelsummary functie. Standaard worden drie decimalen gebruikt. Dit is ook de conventie in de literatuur, maar het aantal decimalen kan aangepast worden met syntax. Standaardfouten kunnen echter ook tussen haakjes naast de coëfficiënt gezet worden.\nVoorzie de tabel van een informatieve titel, duidelijke namen voor de variabelen en een notitie onderaan die verduidelijkt welke informatie precies wordt weergegeven.\nVoor categorische variabelen kun je de referentiegroep op verschillende manieren verduidelijken: 1) je kunt deze informatie opnemen in de notitie zoals in het voorbeeld; 2) je kunt de referentiegroep aanduiden in de benaming van de variabele bv. “Azië (ref.: Afrika”; 3) je kunt de referentiegroep ook opnemen in een aparte rij in de tabel. Deze optie wordt beschreven op de modelsummary webpagina. De webpagina bevat ook verdere informatie om je tabel aan te passen naar voorkeur.\nStandaard nummert modelsummary de modellen in de tabel (bv. (1), (2), etc.). Je kan echter ook een specifieke kolomnaam geven. Dit is bijvoorbeeld handig als modellen een andere afhankelijke variabele hebben."
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.5 Plotten van coëfficiënten",
    "text": "8.5 Plotten van coëfficiënten\nDe resultaten van regressiemodellen kunnen ook in de vorm van een “coefficient plot” (plot van coëfficiënten) weergegeven worden. Deze plot bevat de coëfficiënten en hun betrouwbaarheidsintervallen (doorgaans op het 95% niveau). De constante wordt doorgaans niet opgenomen in de figuur.\nBij wijze van voorbeeld plotten we hier de resultaten van een model dat electorale democratie voorspelt op basis van corruptie, politiek geweld en regimestatus in 1984. We maken gebruik van de tidy() functie uit het broom package en de ggplot() functie uit het tidyverse package.\n\n\n#Model\nplot_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\n#Oslaan van resultaten in tidy dataframe\n#MOET betrouwbaarheidsintervallen bevatten\nplot_model_tidied &lt;- tidy(plot_model, conf.int = TRUE)\n\n#resultaat bekijken\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 cpi                     0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 v2caviol               -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 TYPEDEMO1984Democraci…  0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nWe kunnen met deze data een figuur maken met ggplot() maar eerst doen we nog wat data management. We geven bijvoorbeeld andere namen aan de variabelen (opgeslaan in term) om duidelijker de resultaten te presenteren. 5\n\n#duidelijkere namen:\nplot_model_tidied &lt;- plot_model_tidied |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruptieperceptie-Index\", \n                       \"v2caviol\" = \"Politiek geweld\",  \n                       \"TYPEDEMO1984Democracies\" = \"Democratie in 1984?\"))\n\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 Corruptieperceptie-In…  0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 Politiek geweld        -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 Democratie in 1984?     0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nDan maken we het plot:\n\nplot_model_tidied |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  ggplot(aes(x = estimate, y = term)) +  \n  geom_pointrange(aes(xmin = conf.low, \n                      xmax = conf.high)) + \n  labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\") + \n2  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n3  geom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.5)\n\n\n1\n\nfilter intercept weg uit dataframe\n\n2\n\nVoeg lijn toe bij x = 0\n\n3\n\nVoeg de coëfficiënten toe aan het plot, afgerond op 2 decimalen\n\n\n\n\n\n\n\n\nplot_model_tidied |&gt; filter(term != \"(Intercept)\") |&gt;\n\nWe gebruiken het data object dat we eerder aangemaakt hebben (plot_model_tidied) en filteren het intercept uit de data gezien die doorgaans niet geplot wordt.\n\nggplot(aes(x=estimate, y=term)) +\n\nWe gebruiken ggplot() en bepalen welke variabelen op de x–as (hier: ‘estimate’, de waarde voor de coëfficiënten) en de y-as (hier: de variabele term met de naam van onze variabelen) komen. De variabelen kunnen gewisseld worden van as, maar de getoonde manier levert meestal een betere visualisatie (anders zouden de namen van de variabelen kunnen overlappen).\n\ngeom_pointrange(aes(xmin=conf.low, xmax=conf.high))\n\nHier vragen we om de coefficiënten aan te duiden met een punt (“point”). Vervolgens vragen we om een lijn door het punt te tekenen om de reikwijdte (“range”) van de betrouwbaarheidsintervallen voor te stellen. De xmin and xmax delen van de syntax bepalen de reikwijdte.6 Hier gebruiken we conf.low and conf.high, de variabelen waarin de ondergrens en bovengrens van de intervallen is opgeslaan.\n\nlabs(...)\n\nWe geven hier namen aan de assen en geven ook een titel.\n\ngeom_vline(xintercept=0, linetype=\"dashed\", color=\"red\")\n\nHier vragen we R om een verticale referentielijn te tekenen (“geom_vline”) waar x = 0. Deze lijn helpt met het bepalen van de significantie, aangezien overlap van het betrouwbaarheidsinterval met de lijn wijst op een niet-significante coëfficiënt.\n\ngeom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.5)\n\nHier vragen we om ook de waarde van de coëfficiënt weer te geven op de plot met geom_text(). De tekst die op het plot komt wordt bepaald met “label =”. Hier vragen we om de ‘estimate’ (de coëfficiënt), maar afgerond (“round”) tot 2 decimalen voor de duidelijkheid.\n\n\nMet vjust = -0.5 bepalen we waar de tekst komt (“vertical justification”). Dit kunnen we gebruiken om overlap tussen tekst en geplotte waarden te voorkomen. Negatieve waarden plaatsen de tekst hoger, positieve waarden plaatsen de tekst lager.\nMet hjust = -0.5 (“horizontal justification”) kunnen we de tekst naar links (positieve waarden) of rechts (negatieve waarden) bewegen. In de praktijk kan het zijn dat je hier wat moet spelen met de waarden voor vjust en hjust om je plot goed te presenteren.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nStandaard plot ggplot coëfficiënten van variabelen in alfabetische volgorde (is to order the coefficients by the alphabetical order of the variable that contains the variable names (named)zoals opgeslaan in de term variabele in het dataframe geproduceerd door tidy()). Dit is niet altijd ideaal, bijvoorbeeld wanneer categorieën van een factor variabele niet bij elkaar komen te staan of wanneer we vooral geïnteresseerd zijn in 1 bepaalde predictor en niet willen dat die in het midden komt te staan in plaats van prominent bovenaan.\nEen voorbeeld:\n\n#Model met categorische variabele\ncat_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#Tidy met simpel plot\ntidy(cat_model, conf.int = TRUE) |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruptieperceptie\", \n                       \"v2caviol\" = \"Politiek geweld\",\n                       \"regionAsia\" = \"Azië\",\n                       \"regionEurope\" = \"Europa\", \n                       \"regionAmericas\" = \"Amerikas\")) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) +\n    labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\")\n\n\n\n\nDe coëfficiënten van de categorische regio variable staan niet bij elkaar. We kunnen dit aanpassen door van termeen factor te maken en dan de volgorde van de niveaus aan te passen met relevel.\n\ntidy(cat_model, conf.int = TRUE) |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  mutate(term = factor(term,\n                       levels = c(\"regionEurope\", \"regionAsia\", \n                                  \"regionAmericas\", \"v2caviol\",\n2                                  \"cpi\"),\n                       labels = c(\"Europa\", \"Azië\", \n                                  \"Amerikas\", \"Pol. geweld\",\n                                  \"Corruptieperceptie\"))) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high))+\n    labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\")\n\n\n1\n\nOmzetten naar een factor doe je nadat het intercept is weggefilterd. Dat kan in 1 stap zoals in het voorbeeld of in 2 aparte syntax-stappen.\n\n2\n\nggplot() zal het eerste niveau als onderste variabele plotten, het laatste niveau wordt de bovenste enzovoort.\n\n\n\n\n\n\n\n\n\n\n8.5.1 Instructies\n\nMeestal plaats je de coëfficiënt op de x-as en de naam van de variabele op de y-as. Het is mogelijk dit te veranderen met de ggplot syntax, maar dan kunnen de variabelenamen makkelijker overlappen. Lange variabelennamen leiden wel vaker tot problemen met de visualisatie (in deze blog vind je enkele tips).\nHet toevoegen van de (afgeronde) coëfficiënt-waarde kan lezers helpen de resultaten beter te vatten.\nMeestal plotten we de 95% betrouwbaarheidsintervallen, maar dit kan aangepast worden (we kunnen tidy om andere niveaus vragen).\nIn een rapport voeg je best een notitie onderaan de figuur toe, bv. “Notitie: OLS coëfficiënten met 95% betrouwbaarheidsinterval”.\nHet is handig en gebruikelijk een referentielijn toe te voegen die nul aanduidt want dan kan statistische significantie (hier: bij p &lt; 0.05) onmiddellijk afgelezen worden\nStandaard plot ggplot de coëfficiënten in alfabetische volgorde. Dit kan ervoor zorgen dat variabelen die bij elkaar horen (bv. meerdere dummies van 1 onderliggende categorische variabele) niet bij elkaar staan in het plot. We kunnen de volgorde aanpassen als we de term variabele omzetten in een factor variabele en de volgorde van de levels zelf bepalen. Zie het ‘waarschuwing’-vak hiervoven.\nGelman and Stern (2006) maakte de welbekende uitspraak (althans onder statistici) dat “het verschil tussen ‘significant’ en ‘niet significant’ op zichzelf ‘niet significant’ is”. Dit betekent dat je op basis van de betrouwbaarheidsintervallen van coëfficiënten en hun overlap niet kunt bepalen of coefficiënten significant van elkaar verschillen, je kan enkel bepalen of een coëfficiënt verschillend is van 0 (de nulhypothese).\n\n\nGelman, Andrew, and Hal Stern. 2006. “The Difference Between “Significant” and “Not Significant” Is Not Itself Statistically Significant.” The American Statistician 60 (4): 328331."
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.6 Voorspelde waarden plotten",
    "text": "8.6 Voorspelde waarden plotten\nRegressietabellen en coëfficiëntenplots presenteren de coëfficiënten voor de onafhankelijke variabelen in een model: wat is de verwachte gemiddelde waarde van de DV wanneer alle predictors = 0 (entercept of constante) en wat is de verwachte verandering in Y gegeven als X met één eenheid stijgt (coëfficiënten van onafhankelijke variabelen). We kunnen ook voorspelde waarden en grafieken van die voorspelde waarden gebruiken om discussies over coëfficiënten aan te vullen en meer te kunnen zeggen over het substantiële belang van de geschatte relatie.\nHet proces is gelijkaardig dan dat van coëfficiëntenplots, maar nu maken we gebruik van de predictions() functie in plaats van tidy(). We werken immers met voorspellingen nu en niet de coëfficiënten. Zie Chapter 5 voor meer informatie over de predictions() functie.\nHieronder geven we voorbeelden voor plots van voorspelde waarden op basis van continue en binaire/categorische onafhankelijke variabelen.\n\n8.6.1 Continue onafhankelijke variabele\nVoor dit voorbeeld gebruiken we heet eerder geschatte plot_model, waarbij electorale democratiescores voorspeld worden aan de hand van de corruptieperceptie-index, politiek geweld, en regimestatus in het verleden. Stel nu dat corruptie (cpi) als continue predictor ons specifiek interesseert. We willen weten hoe demoratieniveau verandert op verschillende niveaus van corruptie. we gebruiken predictions() om de verwachte waarde voor v2x_polyarchy te berekenen wanneer corruptie waarden tussen 20 en 80 aanneemt (de andere onafhankelijke variabelen worden constant gehouden op hun gemiddelde of modus).\n\n#Voorspellingen berekenen\ncpi_preds &lt;- predictions(plot_model, \n                         newdata = datagrid(cpi = c(20, 30, 40, 50, 60, 70, 80)))\n\n#en bekijken\ncpi_preds\n\n\n cpi Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % v2caviol TYPEDEMO1984\n  20    0.318     0.0278 11.4   &lt;0.001  98.4 0.264  0.373   -0.394  Autocracies\n  30    0.382     0.0217 17.6   &lt;0.001 227.5 0.339  0.424   -0.394  Autocracies\n  40    0.445     0.0199 22.4   &lt;0.001 367.4 0.406  0.484   -0.394  Autocracies\n  50    0.509     0.0233 21.9   &lt;0.001 349.5 0.463  0.555   -0.394  Autocracies\n  60    0.573     0.0302 18.9   &lt;0.001 263.5 0.513  0.632   -0.394  Autocracies\n  70    0.636     0.0389 16.4   &lt;0.001 197.8 0.560  0.713   -0.394  Autocracies\n  80    0.700     0.0483 14.5   &lt;0.001 155.9 0.605  0.795   -0.394  Autocracies\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, v2caviol, TYPEDEMO1984, cpi, v2x_polyarchy \nType:  response \n\n\nDeze data kunnen we invoeren in ggplot() om een plot te maken.\n\n1ggplot(cpi_preds, aes(x = cpi, y = estimate)) +\n2       geom_line () +\n3       geom_ribbon(aes(ymin = conf.low, ymax = conf.high),\n                   alpha = 0.2) +  \n4       labs(title = \"Voorspelde electorale democratiescore op basis van corruptieperceptie\",\n            x = \"Corruptieperceptie-index (Hoger = Minder corrupt)\",   \n            y = \"Voorspelde waarde\") +  \n5       scale_y_continuous(limits=c(0,1))\n\n\n1\n\nDuidt aan welke data en welk plot we willen gebruiken\n\n2\n\nDuidt aan dat we een lijn willen die voorspelde waarden verbindt\n\n3\n\nDuidt aan dat we een betrouwbaarheidsinterval willen en hoe donker dit interval geplot wordt\n\n4\n\nInformatieve titel en labels\n\n5\n\nDe y-as zetten we van 0 tot 1 gezien dit het theoretisch bereik is van de afhankelijke variabele. Niet altijd nodig dit te doen.\n\n\n\n\n\n\n\n\nggplot(\n\n: We gebruiken ggplot op het data object tussen haakjes.\n\ncpi_preds, aes(x = cpi, y = estimate)) +\n\ndataobject (cpi_preds) en de variabelen die we willen plotten op elke as.\n\ngeom_line() +\n\nWe vragen ggplot hier een lijn te trekken tussen de voorspelde waarden. Dit is gebruikelijk voor een continue onafhankelijke variabele.\n\ngeom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n\nHier vragen we om een band (‘ribbon’) rond de lijn te tekenen om de betrouwbaarheidsintervallen voor de voorspelde waarden weer te geven. Via aes() bepalen we welke variabelen de ligging van de band bepalen: de ondergrens (ymin) en bovengrens (ymax) van de betrouwbaarheidsintervallen. Met alpha=0.2 bepalen we hoe donker de band is. Hogere waarden zijn donkerder en kunnen de zichtbaarheid van de lijn zelf hinderen.\n\nlabs(...)\n\nWe voegen titel en astitels toe.\n\nscale_y_continuous(limits = c(0,1))\n\nWe bepalen met deze syntax de limieten van de y-as, hier tussen 0 en 1.\n\n\nDe limieten van de as zelf bepalen kan handig zijn om data duidelijker te visualiseren. We kunnen ervoor kiezen om de as het volledige theoretische bereik van de afhankelijke variabele te laten aannemen, zoals we hier doen met een y-as van 0 tot 1. Door het volledige bereik van de afhankelijke variabele te gebruiken lijken de effecten ook niet groter dan ze zijn. Echter kan deze benadering er soms wel voor zorgen dat een grafiek veel wit bevat en minder visueel aantrekkelijk is. Zie this webpage voor voorbeelden van wat er mis kan gaan. In de praktijk maken we een afweging. Wat we wel willen vermijden is dat de schaal groter is dan het theoretische bereik van de afhankelijke variabele.7\n\n\n8.6.2 Binaire/categorische onafhankelijke variabele\nOm voorspelde waarden voor een factor variabele te plotten is de procedure gelijkaardig. Hier plotten we de voorspelde waarden voor electoral democratie voor de verschillende niveaus van TYPEDEMO1984.\n\n#Voorspelde waarden berekenen\ndemo_preds &lt;- predictions(plot_model, \n                          by = 'TYPEDEMO1984', \n1                          newdata = 'mean')\n\n#en bekijken: \ndemo_preds\n\n\n1\n\nHoudt de andere onafhankelijke variabelen op hun gemiddelde of modus\n\n\n\n\n\n TYPEDEMO1984 Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  cpi\n  Democracies    0.620     0.0260 23.8   &lt;0.001 413.9 0.569  0.671 43.4\n  Autocracies    0.467     0.0205 22.8   &lt;0.001 379.7 0.427  0.507 43.4\n v2caviol\n   -0.394\n   -0.394\n\nColumns: rowid, TYPEDEMO1984, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cpi, v2caviol, v2x_polyarchy \nType:  response \n\n\nDit data object voeren we door naar de ggplot() functie. We maken gebruik van geom_pointrange() zoals eerder voor het coëfficiëntenplot.\n\nggplot(demo_preds, aes(x = TYPEDEMO1984, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Voorspelde democratiescore aan de hand van regime in het verleden\", \n       y = \"Voorspelde waarde\", \n       x = \"Regime in 1984\") + \n  scale_y_continuous(limits = c(0,1)) +\n  scale_x_discrete(labels = c(\"Autocracies\" = \"Autocratie\", \"Democracies\" = \"Democratie\"))\n\n\n\n\n\nscale_x_discrete(labels = c(...)\n\nWe veranderen de labels voor de categorische variabele naar het Nederlands.\n\n\nWe kunnen hier ook de effectieve voorspelde waarden toevoegen aan het plot met geom_text. We kunnen de positie van de tekst weer bepalen met vjust en/of hjust. Dit doen we vooral met categorische variabelen en niet met continue predictors.\n\nggplot(demo_preds, aes(x=TYPEDEMO1984, y=estimate)) + \n  geom_pointrange(aes(ymin=conf.low, ymax=conf.high)) + \n  labs(title = \"Voorspelde democratiescore aan de hand van regime in het verleden\", \n       y = \"Voorspelde waarde\", \n       x = \"Regime in 1984\") + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25)+\n  scale_x_discrete(labels = c(\"Autocracies\" = \"Autocratie\", \"Democracies\" = \"Democratie\"))\n\n\n\n\n\n\n8.6.3 Instructies\n\nWelke variabelen en waarden plot je?\n\nAls de variabele binair/categorisch is, gebruik je alle categorieën die relevant zijn voor de discussie. (zie Week 3 R materialen voor een plot met categorieën).\nAls de variabele continue is gebruik je het minimum en maximum met redelijke tussenintervallen. Om het minimum en maximum te bepalen kijk je naar de data voor de observaties gebruikt in het model (dit is niet noodzakelijk de volledige dataset gezien observaties kunnen wegvallen door missing waarden). Met de predictions() kun je gemakkelijk een dataset aanmaken met alle observaties gebruikt in het model en vervolgens gebruik je summary om minimum en maximum te bepalen (zie Section 5.3.1).\n\nEen lijn met 95% betrouwbaarheidsintervallen past bij een continue predictor, geom_pointrange() (of geom_errorbar()) bij een binaire/categorische variabele.\nDe y-schaal verdient bijzonder aandacht bij dit soort plots. In het voorbeeld wordt scale_y_continuous() gebruikt om ervoor te zorgen dat het plot het volledige bereik van de afhankelijke variabele (democratiescore) omvat. Soms maakt ggplot() zelf de schaal kleiner (om ongebruikte ruimte weg te laten), maar dan kan een effect groter lijken dan het is. Deze aanpak heeft ook wel nadelen, bijvoorbeeld juist veel ongebruikte ruimte in een plot en minder duidelijke visualisatie. Socioloog Kieran Healy geeft een verdere bespreking over deze verschillende manieren om de schaal vorm te geven in zijn boek over datavisualisatie."
  },
  {
    "objectID": "linear_08.html#footnotes",
    "href": "linear_08.html#footnotes",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "Een 90% betrouwbaarheidsniveau kan passend zijn indien het model een lage N heeft.↩︎\nWe willen bijvoorbeeld misschien asteriks toevoegen voor statistische significantie. Dit lukt niet gemakkelijk vanzelf met datasummary_correlation (De website van het package beschrijft wel deze methode).Je kunt ook altijd cor.testgebruiken om significantie na te gaan.↩︎\nEen 90% betrouwbaarheidsniveau kan passend zijn indien het model een lage N heeft.↩︎\nHet alternatief is om gof_omit() te gebruiken en die statistieken die we niet willen te specificeren.↩︎\nWe kunnen ook de volgorde waarin de variabelen verschijnen in het plot aanpassen. We doen dit door van termeen factor te maken en dan de volgorde van de niveaus aan te passen met relevel.↩︎\nAls we de coëfficiënten op de y-as plaatsen moeten we hier ymin en ymax aanduiden.↩︎\nSocioloog Kieran Healy bespreekt meer in de diepte hoe data te inspecteren in zijn boek “Data Visualization”, gratis beschikbaar hier. Zie in het bijzonder sectie 6 in Hoofdstuk 1, “Problems of honesty and good judgment”.↩︎"
  },
  {
    "objectID": "part_logistic.html",
    "href": "part_logistic.html",
    "title": "Logistische Regressiemodellen",
    "section": "",
    "text": "In dit onderdeel richten we ons op logistische regressies voor binaire afhankelijke variabelen. We leren hoe…\n\nEen logistisch model te schatten\nHoe het model te interpreteren op basis van de coëfficiënten, de odds ratios, marginale effecten en voorspelde waarden.\nDe assumpties van deze modellen te testen"
  },
  {
    "objectID": "logit_01.html#logistische-regressieanalyse",
    "href": "logit_01.html#logistische-regressieanalyse",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "9.1 Logistische regressieanalyse",
    "text": "9.1 Logistische regressieanalyse\n\n9.1.1 Data Management\nIn dit voorbeeld zullen we eerst onderzoeken of gender (gndr) opkomst bij verkiezingen bepaalt (vote).\nWe kijken eerst of data management nodig is:\n\n#Variabele attributen\nESS9NL |&gt; \n  select(gndr, vote) |&gt; \n  view_df()\n\n\nData frame: select(ESS9NL, gndr, vote)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ngndr\nGender\n1\n2\n9\nMale\nFemale\nNo answer\n\n\n2\nvote\nVoted last national election\n1\n2\n3\n7\n8\n9\nYes\nNo\nNot eligible to vote\nRefusal\nDon't know\nNo answer\n\n\n\n\n#Tabulation\ntable(ESS9NL$gndr)\n\n\n  1   2 \n833 840 \n\ntable(ESS9NL$vote)\n\n\n   1    2    3 \n1291  247  130 \n\n\nDe onafhankelijke variabele heeft 2 categorieën en moet in een factor variabele worden omgezet. De afhankelijke variabele heeft 3 categorieën (Yes, No, Not Eligible). We maken hier een binaire factor variabele van door eerst de “Not Eligible” categorie op NA te zetten:\n\n#Factor maken\nESS9NL &lt;- ESS9NL |&gt;\n1  mutate(gndr = factorize(gndr),\n2         vote = factorize(vote))\n\n#not eligible op NA\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(vote = na_if(vote,\"Not eligible to vote\"))\n\n\n1\n\nDe categorie met de laagste numerieke waarde wordt hierbij de referentiecategorie. We gebruiken factorize gezien datawaarden labels hebben.\n\n2\n\nWe maken hier geen nieuwe variabele aan voor de gehercodeerde variabelen maar overschrijven de originele variabelen. Dit is doorgaans niet aangeraden voor studenten, gelukkig weten wij meestal wel waar we mee bezig zijn.\n\n\n\n\nWe checken de niveaus van de variabelen, in het bijzonder van de vote variabele:\n\nlevels(ESS9NL$vote)\n\n[1] \"Yes\"                  \"No\"                   \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\ntable(ESS9NL$vote)\n\n\n                 Yes                   No Not eligible to vote \n                1291                  247                    0 \n             Refusal           Don't know            No answer \n                   0                    0                    0 \n\n\nDe vote variabele is nu een factor variabele met “Yes” als de referentiecategorie. Dit is niet wat we willen gezien we stemmen willen voorspellen. Als we de variabele zo laten voorspelt het model of een persoon niet heeft gestemd. We veranderen dit met de relevel functie (zie Section 2.1.1).1\n\n#Relevel de variabele\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(vote = relevel(vote, \"No\"))\n\n#en controleer het resultaat\nlevels(ESS9NL$vote)\n\n[1] \"No\"                   \"Yes\"                  \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\n\n\nmutate(vote = relevel(vote, \"No\"))\n\nWe gebruiken de relevel functie op de vote variabele. We creëren hier geen nieuwe variabele, maar overschrijven de oude. Je zou er ook voor kunnen kiezen een nieuwe variabele te maken. De categorie tussen dubbele aanhalingstekens zal de eerste categorie worden en dus de referentiecategorie in de regressie. We gebruiken het label “No” omdat de variabele reeds tot factor is getransformeerd (en dus niet de originele numerieke waarde ‘2’).\n\n\nLaten we nu kijken naar de gndr variabele:\n\ntable(ESS9NL$gndr)\n\n\n     Male    Female No answer \n      833       840         0 \n\nlevels(ESS9NL$gndr)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\n\nAls we de niveaus bekijken zien we dat ‘Male’ als referentie zal worden genomen. Dit is prima, maar bij wijze van voorbeeld veranderen we dit hieronder naar ‘Female’. We zien ook een derde categorie ‘No answer’. Dit label werd gegeven aan de waarde in de variabele maar is leeg. R zal deze dus verwijderen in de analyses.\n\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(gndr = relevel(gndr, \"Female\"))\n\n#controleer je codering\nlevels(ESS9NL$gndr)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nDe afhankelijke variabele voor een logistische regressie is een (factor) binaire variabele. Zorg ervoor dat de referentiecategorie de uitkomst is die je niet wil voorspellen en de hoogste categorie net die is die je wil voorspellen. Anders zal je interpretatie foutief zijn.\n\n\n\n\n9.1.2 Logistic regressie uitvoeren\nHet uitvoeren van logistische regressie in R is gelijkaardig aan lineare regressie. In plaats van de ingebouwde functie lm(), gebruiken we de eveneens ingebouwde glm() functie. De afkorting staat voor ‘generalized linear model’.\n\n#Schat het model\nVote_model &lt;- glm(vote ~ gndr, \n                data = ESS9NL, family = \"binomial\")\n\n\nVote_model &lt;-\n\nWe slaan de resultaten op in een data object met naam naar keuze.\n\nglm(vote ~ gndr,\n\nWe voeren de glm functie uit met vote als afhankelijke variabele, voorspeld (~) door onze enige onafhankelijke variabele: gndr. We kunnen meerdere onafhankelijke variabelen toevoegen, gescheiden van elkaar met een ‘+’ teken.\n\ndata = ESS9NL,\n\nWe geven aan welke dataset gebruikt wordt.\n\nfamily = \"binomial\")\n\nWe verduidelijken de familie van modellen voor ons generalized linear model. Voor logistische regressie is dit “binomial”. Dit gedeelte van de code blijft onveranderd. Zie de Veelvoorkomende Fouten appendix ( Section A.3) voor een error die je kunt tegenkomen als je dit gedeelte vergeet.\n\n\nDe resultaten bekijken we weer met de summary() functie:\n\nsummary(Vote_model)\n\n\nCall:\nglm(formula = vote ~ gndr, family = \"binomial\", data = ESS9NL)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.56485    0.09535  16.412   &lt;2e-16 ***\ngndrMale     0.18359    0.13925   1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output is gelijkaardig aan die van de lineaire regressie met lm().\n\nCall: Het model dat geschat werd\nDeviance Residuals: beschrijvende statistieken over de residuals van het model.\nCoefficients: De logistische regressiecoëfficiënten (Estimate), hun standaardfouten (Std. Error), en de teststatistiek (z-waarde; de Z-statistiek is gelijk aan \\(\\frac{\\textrm{Coefficient}}{\\textrm{Std. Error}}\\)), en de p-waarde voor de z-statistiek (Pr(&gt;|z|). Symbolen m.b.t. statistische significantie vind je rechts van de p-waarde waar van toepassing. De interpretatie van de symbolen wordt uitgelegd in de legende onder de coëfficiënten (“Signif. Codes:”).\n(Dispersion parameter…): Te negeren.\nArea that begins with Null deviance: Informatie over de fit van het model, besproken in een volgend hoofdstuk.\nNumber of Fisher Scoring Iterations: Aantal iteraties van het algoritme.\n\n\n\nWe kunnen meerdere predictoren toevoegen aan het model op een gelijkaardige manier als bij lineaire regressie: door ze te scheiden met een + teken. Hier voegen we leeftijd (agea), vertrouwen in politici (trstplt), en links-rechts positie (lrscale) toe. data management voor deze variabelen is niet nodig: ze zijn continue en missing waarden zijn reeds als NA aangeduid.\n\n#Schat het model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Bekijk de output\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nLogistische regressiecoëfficiënten geven een schatting van de verandering in de log van de odds dat Y=1 als X met 1 eenheid stijgt. Ze zijn dus niet makkelijk direct te interpreteren. We kunnen ze wel gebruiken om iets over de richting van de relatie te zeggen. Een positive coëfficiënt toont dat de kans dat Y=1 stijgt als de onafhankelijke variabele stijgt. Een negatieve coëfficiënt toont dat de kans dat Y=1 daalt als de onafhankelijke variabele stijgt. Voor verdere interpretatie maak je best gebruik van de odds ratios (in minder mate), de gemiddelde marginale effecten (average marginal effects) (zie Chapter 10) of de voorspelde kansen (zie Chapter 11) .\nVoor dit voorbeeld:\n\nMannen hebben een grotere kans om te stemmen dan vrouwen, maar het verschil is niet statistisch signficant (p = 0.28).\nOudere respondenten hebben een grotere kans om te gaan stemmen en dit verband is statistisch signficant (p &lt; 0.001).\nRespondenten met meer vertouwen in politici hebben een grotere kans om te gaan stemmen. deze relatie is statistisch significant (p &lt; 0.001).\nStemmen is meer waarschijnlijk naarmate respondten zich rechtser psitioneren op de ideologieschaal, maar dit effect is niet statistisch signficant (p = 0.74)."
  },
  {
    "objectID": "logit_01.html#odds-ratios",
    "href": "logit_01.html#odds-ratios",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "9.2 Odds Ratios",
    "text": "9.2 Odds Ratios\nLogistische regressiecoëfficiënten kunnen omgezet worden in odds ratios die (iets) intuïtiever zijn om te interpereteren..\nWe kunnen de odds ratios en 95% betrouwbaarheidsintervallen verkrijgen met de tidy functie uit het broom package:\n\n# logistische regressiecoëfficiënten en hun betrouwbaarheidsintervallen\ntidy(Vote_model_mp, conf.int = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -0.284    0.380      -0.747 0.455       -1.03       0.463 \n2 gndrMale      0.0433   0.154       0.281 0.779       -0.259      0.346 \n3 agea          0.0183   0.00450     4.07  0.0000461    0.00958    0.0272\n4 trstplt       0.195    0.0387      5.04  0.000000469  0.119      0.271 \n5 lrscale       0.0293   0.0393      0.744 0.457       -0.0480     0.106 \n\n# odds ratios (i.e. 'exponentiële coëfficiënten') en hun betrouwbaarheidsintervallen\ntidy(Vote_model_mp, conf.int = TRUE, exp = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    0.753   0.380      -0.747 0.455          0.357      1.59\n2 gndrMale       1.04    0.154       0.281 0.779          0.772      1.41\n3 agea           1.02    0.00450     4.07  0.0000461      1.01       1.03\n4 trstplt        1.22    0.0387      5.04  0.000000469    1.13       1.31\n5 lrscale        1.03    0.0393      0.744 0.457          0.953      1.11\n\n\nZo lees je de syntax:\n\ntidy(Vote_model_mp\n\nWe gebruiken de tidy functie op het model tussen haakjes.\n\nconf.int = TRUE\n\nWe vragen R om de betrouwbaarheidsintervallen weer te geven. We kunnen ‘FALSE’ schrijven of deze code weglaten als we de betrouwbaarheidsintervallen niet willen.\n\nexp = TRUE)\n\nWe vragen hier om de exponentiële (exponentiated) logistische regressiecoëfficiënten, oftewel de odds ratios. We kunnen ‘FALSE’ schrijven of deze code weglaten als we de logistische regressiecoëfficiënten willen.\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nVoor de interpretatie van odds ratios zijn er 3 zaken waar je op moet letten.\nTen eerste, odds ratios vertellen ons iets over de relatieve odds dat Y = 1 (bv. iemand gaat stemmen). Dit is verschillend van de coëfficiënten. de coefficiënten zijn de gelogde versies van de relatieve odds..\nTen tweede, odds ratios zijn multiplicatief and worden geïnterpreteerd in termen van 1 in plaats van 0. Een odds ratio groter dan 1 betekent een hogere kans dat Y=1. Een odds ratio lager dan 1 betekent een lagere kans dat Y=1. Een odds ratio van 1 betekent dat er geen effect is. Een betrouwbaarheidsinterval voor een odds ratio waar 1 niet in voorkomt duidt een statistisch significant effect aan. Een odds ratio kan niet negatief zijn.\nTen derde interpreteren we ook de odds ratios met een multiplicatieve logica. In het voorbeeld vinden we dat de odds om te stemmen 1.04 keer groter zijn voor mannelijke respondeten dan vrouwelijke respondenten, ceteris paribus. het effect is wel niet significant. De odds om te stemmen vermenigvuldigen met 1.02 telkens leeftijd met 1 eenheid omhoog gaat (de andere onafhankelijke variabelen constant gehouden)."
  },
  {
    "objectID": "logit_01.html#footnotes",
    "href": "logit_01.html#footnotes",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "",
    "text": "Met factor() zouden we direct in de syntax de volgorde van de niveaus aan kunnen duiden: mutate(vote_binary = factor(vote, levels = c(2, 1), labels = c(\"Did not vote\", \"Voted\")). Het gebruik van factor vermijdt een veelvoorkomnde fout besproken in volgend hoofdstuk.↩︎"
  },
  {
    "objectID": "logit_02.html#data-management-voorbeeldmodel-en-problemen-met-factorize",
    "href": "logit_02.html#data-management-voorbeeldmodel-en-problemen-met-factorize",
    "title": "10  Marginale Effecten",
    "section": "10.1 Data Management, voorbeeldmodel, en problemen met factorize()",
    "text": "10.1 Data Management, voorbeeldmodel, en problemen met factorize()\nWe maken gebruiken van eenzelfde model dat we gebruikt hebben in vorig hoofdstuk. Daarin voorspelden we stemmen op basis van gender, leeftijd, vertouwen in politici en linsk-rechtsideologie. We herhalen eerst een paar data management stappen:\n\n#Data Preparation\nESS9NL &lt;- ESS9NL |&gt;\n  #Factor maken van categorische variabelen\n1  mutate(gndr = factorize(gndr),\n         vote = factorize(vote))  |&gt; \n  #Not Eligible op missing zetten\n  mutate(vote = na_if(vote,\"Not eligible to vote\")) |&gt;\n  #Relevel van variabelen\n  mutate(vote = relevel(vote, \"No\"), \n         gndr = relevel(gndr, \"Female\"))\n\n#Het model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Resultaten printen\nsummary(Vote_model_mp)\n\n\n1\n\nWe zouden ook deze 3 mutate() stappen in 1 stap kunnen combineren.\n\n\n\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n\n\nHet marginaleffectspackage is niet volledig compatibel met de factorize functie die we hierboven hebben gebruikt voor gender. Laten we even kijken naar de gndrvariabele:\n\nlevels(ESS9NL$gndr)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\ntable(ESS9NL$gndr)\n\n\n   Female      Male No answer \n      840       833         0 \n\n\nEr zijn 3 niveaus of levels voor gndr: “Female”, “Male”, en “No Answer”. Er vallen echter 0 respondente onder “No Answer”. In dergelijke situaties zal onderstaande functie een error geven omdat de functie zoekt naar een derde niveau dat er niet is.\nOm dit te voorkomen kunnen we gebruik maken va de droplevels() functie om lege niveaus te verwijderen. Of we gebruiken factor() om gndr een factor variabele te maken. Zie. Section A.4 in de Veelvoorkomende Fouten Appendix voor meer informatie.\n\n#Drop levels: verwijderen van categorieën zonder observaties\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(gndr = droplevels(gndr))\n\n#Checken van syntax\nlevels(ESS9NL$gndr)\n\n[1] \"Female\" \"Male\"  \n\ntable(ESS9NL$gndr)\n\n\nFemale   Male \n   840    833"
  },
  {
    "objectID": "logit_02.html#gemiddelde-marginale-effecten-ame",
    "href": "logit_02.html#gemiddelde-marginale-effecten-ame",
    "title": "10  Marginale Effecten",
    "section": "10.2 Gemiddelde Marginale Effecten (AME)",
    "text": "10.2 Gemiddelde Marginale Effecten (AME)\nDe eerste soort marginale effecten die we bekijken zijn de gemiddelde marginale effecten: de Average Marginal Effect (AME). We gebruiken hiervoor de avg_slopes() functie uit marginaleffects. De AME geeft de gemiddelde verandering in probabiliteit dat Y=1 weer (in termen van percentpunten) als de onafhankelijke met 1 eenheid omhoog gaat (dy/dx). We bereken het marginale effect voor elke observatie en elke variabele in het model en nemen dan het gemiddelde per variabele. Deze figuur beschrijft het proces (uit Heiss (2022)):\n\n\n\nAME berekening door avg_slopes\n\n\nLaten we kijken naar de AMEs van ons model:\n\n#Schatten van AMEs obv model\nAME &lt;- avg_slopes(Vote_model_mp,\n                  conf_level = 0.95)\n\nDe syntax lees je zo\n\nAME &lt;- avg_slopes(Vote_model_mp,\n\nWe gebruiken de functie avg_slopes op het model tussen haakjes. De resultaten slaan we op in een nieuw data object (AME).\n\nconf_level = 0.95)\n\nStandaard wordt een betrouwbaarheidsniveau van 95% gebruikt, dus deze code kan weggelaten worden als dit het gewenste niveau is. Met de code kun je het niveau ook veranderen (bv. 0.99).\n\n\nDit is de output:\n\n1tibble(AME)\n\n\n1\n\nWe zouden AME kunne typen eerder dan tibble(AME) maar dit geeft andere kolomnamen. We gebruiken tibble() om de kolomnamen te zien zoals ze ook in de dataset zijn opgeslagen. Zie de waarschuwing hiervover in Hoofdstuk 5 Chapter 5.\n\n\n\n\n# A tibble: 4 × 12\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 agea  mean(dY…  0.00220  0.000538     4.08  4.47e-5  14.4    0.00114   0.00325\n2 gndr  mean(Ma…  0.00518  0.0185       0.281 7.79e-1   0.360 -0.0310    0.0414 \n3 lrsc… mean(dY…  0.00350  0.00470      0.744 4.57e-1   1.13  -0.00571   0.0127 \n4 trst… mean(dY…  0.0233   0.00460      5.07  3.92e-7  21.3    0.0143    0.0323 \n# ℹ 3 more variables: predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nterm: bevat de namen van de variabelen (bv., agea, gndr, etc.).\ncontrast: Het ‘contrast’ duidt aan welke vergelijking gemaakt wordt: 1 eenheid toename voor continue variabelen, een verandering van categorie voor factor variabelen.\nestimate: De AME\nstd.error t.e.m. conf.high: Informatie over de onzekerheid van de schatting.\n\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe gemiddelde marginale effecten (AMEs) geven weer wat de gemiddelde verandering is in de probabiliteit dat Y=1 (in percentpunten) als X met 1 eenheid stijgt. De percentpunten verkrijg je door de AME schatting te vermenigvuldigen met 100. Bijvoorbeeld:\n\nDe kans om te stemmen is gemiddeld 0.5 percentpunten hoger voor een mannelijke respondent dan voor een vrouwelijke respondent.\nDe kans om te stemmen stijgt gemiddeld met 2.3 percentpunten met elke eenheid dat respondenten meer vertrouwen hebben in politici."
  },
  {
    "objectID": "logit_02.html#effecten-op-gemiddelde-waarden-van-de-predictors-mem",
    "href": "logit_02.html#effecten-op-gemiddelde-waarden-van-de-predictors-mem",
    "title": "10  Marginale Effecten",
    "section": "10.3 Effecten op gemiddelde waarden van de predictors (MEM)",
    "text": "10.3 Effecten op gemiddelde waarden van de predictors (MEM)\nWe raden aan om AME te gebruiken als je marginale effecten op basis van een logistische regressie interpreteert. Echter zie je ook soms onderzoek waarin men gebruik maakt van “effecten op gemiddelde waarden”: “marginal effect at the mean” of MEM. Daarmee berekenen we het effect op de probabiliteit dat Y=1 wanneer predictors hun gemiddelde waarden aannemen, of de modus bij categorische variabelen. Deze figuur beschrijft de berekening (uit Heiss (2022)):\n\nHeiss, Andrew. 2022. “Marginalia: A Guide to Figuring Out What the Heck Marginal Effects, Marginal Slopes, Average Marginal Effects, Marginal Effects at the Mean, and All These Other Marginal Things Are.” May 20, 2022. https://doi.org/10.59350/40xaj-4e562.\n\n\n\nHe avg_slopes de MEM berekent\n\n\nDe syntax wordt licht aangepast voor de MEM;\n\nMEM &lt;- slopes(Vote_model_mp, \n              conf_level = 0.95,\n              newdata = datagrid()\n              )\n\n\nnewdata = datagrid()\n\nWe maken een nieuwe dataset voor de berekening waarin alle onafhankelijke variabelen op hun gemiddelde of modus worden gehouden.\n\n\nLaten we kijken naar de resultaten:\n\ntibble(MEM)\n\n# A tibble: 4 × 18\n  rowid term    contrast   estimate std.error statistic p.value s.value conf.low\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 agea    dY/dX       0.00210  0.000519     4.05  5.07e-5  14.3    0.00109\n2     1 gndr    Male - Fe…  0.00504  0.0180       0.281 7.79e-1   0.360 -0.0302 \n3     1 lrscale dY/dX       0.00336  0.00453      0.742 4.58e-1   1.13  -0.00551\n4     1 trstplt dY/dX       0.0224   0.00447      5.00  5.67e-7  20.8    0.0136 \n# ℹ 9 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;, gndr &lt;fct&gt;, agea &lt;dbl&gt;, trstplt &lt;dbl&gt;, lrscale &lt;dbl&gt;,\n#   vote &lt;fct&gt;\n\n\nBehalve estimate, standaardfout, test statistiek, p-waarde, en onder- en bovengrens van de betrouwbaarheidsintervallen, bevat de MEM dataset ook de gemiddelden en/of modus waarden voor de predictoren.\n\nMEM |&gt; \n  select(gndr, agea, trstplt, lrscale) |&gt; \n  as_tibble()\n\n# A tibble: 4 × 4\n  gndr   agea trstplt lrscale\n  &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Male   50.7    5.34    5.15\n2 Male   50.7    5.34    5.15\n3 Male   50.7    5.34    5.15\n4 Male   50.7    5.34    5.15\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe interpretatie van MEMs is gelijkaardig aan die van AME: Welke gemiddelde verandering in de kans dat Y=1 verwachten we als X 1 eenheid stijgt? Vermenigvuldigen met 100 leidt tot een interpretatie in termen van percentpunten. De gemiddelde verandering is nu wel berekend wanneer onafhankelijke variabelen hun gemiddelde waarden aannemen. Dit moet gerapporteerd worden. Bijvoorbeeld: mannelijke respondenten hebben een 0.5 percentpunten hogere kans om te stemmen dan vrouwelijke respondenten, als leeftijd, ideologie, en vertrouwen in politici constant worden gehouden op hun gemiddelde waarde."
  },
  {
    "objectID": "logit_03.html#voorspelde-kans-voor-individuele-observaties",
    "href": "logit_03.html#voorspelde-kans-voor-individuele-observaties",
    "title": "11  Voorspelde kansen",
    "section": "11.1 Voorspelde kans voor individuele observaties",
    "text": "11.1 Voorspelde kans voor individuele observaties\nOm op basis van het logistische regressiemodel de kans dat de afhankelijke variabele Y gelijk is aan 1 (hier: dat een respondent heeft gestemd) te voorspellen voor elke observatie in het model maken we gebruik van de predictions functie. De resultaten worden altijd opgeslaan in een nieuwe dataset, die je een naam geeft naar keuze (hier: Vote_pred).\n\n#Resultaten opslaan in nieuw object\nVote_pred &lt;- predictions(Vote_model_mp,\n                         conf_level = 0.95, \n                         newdata = ESS9NL)\n\n#tibble() gebruiken voor overzicht\ntibble(Vote_pred)\n\n# A tibble: 1,673 × 578\n   rowid estimate   p.value s.value conf.low conf.high name    essround edition\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  \n 1     1    0.835  6.13e-35   114.     0.796     0.867 ESS9e03        9 3      \n 2     2    0.910  1.71e-56   185.     0.884     0.931 ESS9e03        9 3      \n 3     3    0.904  4.26e-45   147.     0.874     0.928 ESS9e03        9 3      \n 4     4   NA     NA           NA     NA        NA     ESS9e03        9 3      \n 5     5    0.864  9.71e-39   126.     0.828     0.894 ESS9e03        9 3      \n 6     6    0.912  7.81e-53   173.     0.884     0.933 ESS9e03        9 3      \n 7     7    0.800  1.32e-12    39.5    0.731     0.854 ESS9e03        9 3      \n 8     8    0.914  9.43e-31    99.7    0.877     0.941 ESS9e03        9 3      \n 9     9    0.877  1.88e-47   155.     0.845     0.903 ESS9e03        9 3      \n10    10    0.944  2.64e-39   128.     0.917     0.963 ESS9e03        9 3      \n# ℹ 1,663 more rows\n# ℹ 569 more variables: proddate &lt;chr&gt;, idno &lt;dbl&gt;, cntry &lt;chr&gt;, nwspol &lt;dbl&gt;,\n#   netusoft &lt;dbl&gt;, netustm &lt;dbl&gt;, ppltrst &lt;dbl&gt;, pplfair &lt;dbl&gt;, pplhlp &lt;dbl&gt;,\n#   polintr &lt;dbl&gt;, psppsgva &lt;dbl&gt;, actrolga &lt;dbl&gt;, psppipla &lt;dbl&gt;,\n#   cptppola &lt;dbl&gt;, trstprl &lt;dbl&gt;, trstlgl &lt;dbl&gt;, trstplc &lt;dbl&gt;, trstplt &lt;dbl&gt;,\n#   trstprt &lt;dbl&gt;, trstep &lt;dbl&gt;, trstun &lt;dbl&gt;, vote &lt;fct&gt;, prtvtcat &lt;dbl&gt;,\n#   prtvtdbe &lt;dbl&gt;, prtvtdbg &lt;dbl&gt;, prtvtgch &lt;dbl&gt;, prtvtbcy &lt;dbl&gt;, …\n\n\nDit is de syntax-uitleg:\n\nVote_pred &lt;-\n\nNieuw data object met voorspelde kansen.\n\npredictions(Vote_model_mp,\n\nWe voeren de predictions functie uit op het model tussen haakjes.\n\nconf_level = 0.95,\n\nStandaard betrouwbaarheidsniveau. De waarde kan veranderd worden (bv. conf_level = 0.99).\n\nnewdata = ESS9NL)\n\nWe kopiëren de variabelen uit de originele dataset. Dit gedeelte kan weggelaten worden als je dit niet nodig acht."
  },
  {
    "objectID": "logit_03.html#gemiddelde-voorspelde-kansen",
    "href": "logit_03.html#gemiddelde-voorspelde-kansen",
    "title": "11  Voorspelde kansen",
    "section": "11.2 Gemiddelde voorspelde kansen",
    "text": "11.2 Gemiddelde voorspelde kansen\nWe kunnen de predictions() functie ook gebruiken om de gemiddelde voorspelde kans dat Y=1 te berekenen voor specifieke waarden van een onafhankelijke variabele. De andere onafhankelijke variabelen worden constant gehouden op hun gemiddelde (continue variabelen) of modus (factor variabelen). Deze voorspellingen kunnen we ook weergeven in een figuur zoals besproken in Section 14.5 .\n\n11.2.1 Continue onafhankelijke variabele\nDe volgende code gebruiken we als de predictor die ons interesseert continu is. Hier berekenen we de gemiddelde voorspelde kans om te stemmen als vertrouwen in politici (trstplt) verandert.\n\nESS9NL |&gt; \n  select(trstplt) |&gt; \n  view_df()\n\n\nData frame: select(ESS9NL, trstplt)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ntrstplt\nTrust in politicians\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n77\n88\n99\nNo trust at all\n1\n2\n3\n4\n5\n6\n7\n8\n9\nComplete trust\nRefusal\nDon't know\nNo answer\n\n\n\n\ntable(ESS9NL$trstplt)\n\n\n  0   1   2   3   4   5   6   7   8   9  10 \n 43  41  68  90 173 292 457 375  87  16   8 \n\n\nDe variabele loopt van 0 tot 10 dus deze waarden gebruiken we als minimum en maximum. We berekenen verder de kans per interval van 2 eenheden (missing waarden zijn reeds op NA gezet). We zouden ook voor elke eenheid de kans kunnen berekenen maar dit geeft vrij veel output, wellicht meer dan we nodig hebben. We zouden in plaats van deze intervallen ook minimum, 1ste kwartiel, mediaan, 3rde kwartiel en maximum van de variabele kunnen gebruiken (zie Section 5.3.1 voor het proces om deze waarden te verkrijgen).\n\n#Voorspellingen in nieuw object\nPred_conts &lt;- predictions(Vote_model_mp,\n                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2))) \n\n\nnewdata = datagrid(trstplt\n\nAlle predictoren in het model worden op hun gemiddelde/modus gehouden behalve de predictor die tussen haakjes staat.\n\n= seq(from=0,to=10,by=2)))\n\nWe vragen hier voorspellingen voor een sequentie (seq) van waarden: van (from) het minimum tot (to) het maximum met tussenstappen (by) van 2. We zouden als alternatief deze code kunnen gebruiken: trstplt = c(0,2,4,6,8,10)).\n\n\nLaten we de voorspellingen bekijken:\n\n1tibble(Pred_conts)\n\n\n1\n\ntibble() wordt gebruikt om de onderliggende data beter te kunnen zien.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr   agea lrscale trstplt\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male   50.7    5.15       0\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male   50.7    5.15       2\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male   50.7    5.15       4\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male   50.7    5.15       6\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male   50.7    5.15       8\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male   50.7    5.15      10\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output is gelijkaardig aan die voor voorspellingen voor lineaire regressiemodellen (zie Chapter 5):\n\nDe estimate kolom bevat de voorspelde kans.\nDe p.value t.e.m. conf.high kolommen geven de onzekerheid van de schatting weer.\nWe kunnen ook de kolommen zien voor de andere onafhankelijke variabelen in het model (gndr, agea, lrscale) . Deze kolommen tonen de waarde waarop deze variabelen constant worden gehouden. De predictions() functie houdt continue variabelen op hun gemiddelde en factor variabelen op hun modus als je newdata = datagrid() gebruikt zoals we hierboven gedaan hebben.\nDe laatste 2 kolommen tonen trstplt, met de waarden gebruikt om de voorspelling te berekenen en een kolom (niet zichtbaar hier) met de Y (vote) die toont welke categorie voorspeld wordt.\n\n\n\n\n\n11.2.2 Factor onafhankelijke variabele\nDe code voor categorische variabelen is licht anders. We gebruiken hier de by= optie. In dit voorbeeld bereken we de gemiddelde voorspelde kans voor mannen en vrouwen (met andere predictoren constant gehouden op hun gemiddelde).\n\n#voorspellingen in nieuw object\nPred_cat &lt;- predictions(Vote_model_mp,\n              by=\"gndr\", \n              newdata = \"mean\") \n\n#tibble voor overzicht\ntibble(Pred_cat)\n\n# A tibble: 2 × 11\n  rowid gndr  estimate  p.value s.value conf.low conf.high  agea trstplt lrscale\n  &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Fema…    0.863 1.35e-60    199.    0.835     0.887  50.7    5.34    5.15\n2     2 Male     0.868 1.44e-64    212.    0.841     0.891  50.7    5.34    5.15\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\n\nby=\"gndr\"\n\nMet deze optie duiden we aan dat we voor elk niveau van de factor variabele een voorspelde kans willen berekenen.\n\nnewdata = \"mean\"\n\nDeze optie moeten we toevoegen om duidelijk te maken dat andere predictoren op hun gemiddelde/modus gehouden moeten worden. Deze optie moet samen met by= gebruikt worden."
  },
  {
    "objectID": "logit_03.html#voorspelde-kansen-voor-specifieke-waarden-van-predictoren",
    "href": "logit_03.html#voorspelde-kansen-voor-specifieke-waarden-van-predictoren",
    "title": "11  Voorspelde kansen",
    "section": "11.3 Voorspelde kansen voor specifieke waarden van predictoren",
    "text": "11.3 Voorspelde kansen voor specifieke waarden van predictoren\nTen slotte kunnen we de voorspelde kans op Y berekenen als een observatie bepaalde, hypothetische waarden zou aannemen.\nBijvoorbeeld, hier berekenen we de voorspelde kans om te stemmen voor een man (gndr), die 33 jaar oud is (agea), een score van 2 heeft voor vertrouwen in politici (trstplt) en een score van 8 heeft op de links-rechts schaal (lrscale). We moeten hiervoor de waarden voor alle predictoren verduidelijken tussen haakjes bij newdata=datagrid.\n\n#Berekenen en opslaan in object\nPred_specific &lt;- predictions(Vote_model_mp,\n1                             newdata = datagrid(gndr=c(\"Male\"),\n                                                agea=c(33),   \n                                                trstplt=c(2), \n                                                lrscale=c(8)))\n#bekijken\nPred_specific\n\n\n1\n\nWe gebruiken haakjes omdat dit een factor variabele is met labels voor categorieën.\n\n\n\n\n\n gndr agea trstplt lrscale Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n Male   33       2       8    0.729   &lt;0.001 20.2 0.645  0.799\n\nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, gndr, agea, trstplt, lrscale, vote \nType:  invlink(link)"
  },
  {
    "objectID": "logit_04.html#fit-statistieken-met-summary",
    "href": "logit_04.html#fit-statistieken-met-summary",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "12.1 Fit statistieken met summary()",
    "text": "12.1 Fit statistieken met summary()\nLaten we teruggaan naar het logistisch model waar we ook in vorige hoofdstukken mee werkten: wat is de kans dat iemand gaat stemmen op basis van informatie over gender, leeftijd, vertouwen in politici en links-rechtsideologie?\n\n#Data management\nESS9NL &lt;- ESS9NL |&gt;\n  #Factor maken van categorische variabelen\n  mutate(gndr = factorize(gndr), \n         vote = factorize(vote))  |&gt; \n  #Not Eligible op missing zetten\n  mutate(vote = na_if(vote,\"Not eligible to vote\")) |&gt; \n  #Relevel van variabelen\n  mutate(vote = relevel(vote, \"No\"), \n         gndr = relevel(gndr, \"Female\"))\n\n#Het model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Resultaten printen\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nZoals bij een lineair model (lm), zal de summary() functie in het onderste gedeelte van de output informatie bevatten over model fit. We krijgen informatie over de “Null” en “Residual Deviance” statistieken. De Residual Deviance statistiek duidt het verschil (“deviance”) aan tussen het geschatte model en een “perect’ model dat precies bij de data past. De Null Deviance statistiek doet dezelfde vergelijking, maar ten opzichte van een nulmodel dat enkel het intercept bevat.\nKleinere Residual Deviance waarden duiden beter passende modellen aan. Echter is het niet gewenst om de deviance statistiek op zicht te interpreteren gezien de schaal onduidelijk is en er geen maximumwaarde is. Daarom maken we gebruik van andere statistieken en test gebaseerd op de deviance statistiek (zie onder)."
  },
  {
    "objectID": "logit_04.html#modellen-vergelijken-likelihood-ratio-test",
    "href": "logit_04.html#modellen-vergelijken-likelihood-ratio-test",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "12.2 Modellen vergelijken: Likelihood Ratio Test",
    "text": "12.2 Modellen vergelijken: Likelihood Ratio Test\nWe kunnen de likelihood ratio test gebruiken om verschillende logistische regressiemodellen te vergelijken met elkaar en na te gaan welke beter past. De LRT berekent de ratio tussen de deviance statistieken van de modellen en gaat na of er een significant verschil is.\nAls we modellen willen verglijken moeten we net zoals bij lineaire regressie (zie Section 6.2) zorgen dat de modellen een gelijke N hebben en dat complexere modellen alle predictors bevatten van simpelere modellen (nested). We zorgen dat we eerst een dataset maken met complete observaties voor het meest complexe model (alle predictors).\n\nESS9NL_glm &lt;- ESS9NL |&gt;\n  filter(complete.cases(vote,  gndr,  agea,  trstplt,  lrscale))\n\nDan schatten we een reeks modellen waaraan we telkens 1 van de onafhankelijke varaibelen toevoegen. We beginnen met een nulmodel dat enkel het intercept bevat. Het model met 1 onafhankelijke variabele kan daar dan mee vergeleken worden.\n\n#Nulmodel\nVote_model0 &lt;- glm(vote ~ 1,\n                      data = ESS9NL_glm, family = \"binomial\")\n# + gndr\nVote_model1 &lt;- glm(vote ~ gndr , \n                data = ESS9NL_glm, family = \"binomial\")\n# + agea\nVote_model2 &lt;- glm(vote ~ gndr + agea , \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + trst\nVote_model3 &lt;- glm(vote ~ gndr + agea + trstplt, \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + lrscale\nVote_model4 &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL_glm, family = \"binomial\")\n\nNu kunnen we de likelihood ratios van deze modellen met elkaar vergelijken en significantietoetsen uitvoeren. We gebruiken het performance package met de test_likelihoodratio functie. De test vergelijkt de deviance statistiek (-2LL) van elk model, de verandering in vrijheidsgraden (df= degrees of freedom) per model, en gebruikt een Chi2 (\\(\\chi^2\\)) toets.\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model1,\n                     Vote_model2,\n                     Vote_model3,\n                     Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model1 |   glm |  2 |       1 |  0.11 |  0.744\nVote_model2 |   glm |  3 |       1 | 13.59 | &lt; .001\nVote_model3 |   glm |  4 |       1 | 24.38 | &lt; .001\nVote_model4 |   glm |  5 |       1 |  0.55 |  0.457\n\n\n\ntest_likelihoodratio(\n\n: We voeren de likelihood ratio test uit op de modellen tussen haakjes. Er moeten minstens twee modellen aangeduid zijn en de volgorde bepaalt welke vergelijking gemaakt wordt.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output lees je als volgt:\n\nName: naam van het object waarin het model is opgeslagen\nModel: informatie over het type model. Te negeren.\ndf: Geeft weer hoeveel termen gebruikt werden in het model. Vote_model0 heeft een df van 1 gezien er maar 1 term is: het intercept. Vote_model4 heeft 5 df omdat er 5 termen zijn: het intercept en de coëfficiënten voor de 4 onafhankelijke variabelen.\ndf_diff: Geeft weer hoeveel het model verschilt van het vorige model in termen van df. Dit is telkens 1 hier omdat we telkens maar 1 nieuwe predictor hebben toegevoegd.\nChi2 & p: Dit is de Chi2 statistiek en bijhorende p-waarde. De test gaat na of de fit van een model beter is dan de fit van het model in de rij erboven. De nulhypothese is dat er geen verschil is in fit. Een significante toets betekent dat het model beter past.\n\n\n\nIn dit voorbeeld:\n\nModel 1 heeft geen significant betere fit dan een nulmodel (vote_model0)\nModel 2 heeft een betere fit dan Model 1\nModel 3 heeft een betere fit dan Model 1 Model 2\nModel 4 heeft geen significant betere fit dan Model 3.\n\nWe kunnen concluderen dat Model 3 (vote_model3) het best passende model is zonder inclusie van nietszeggende variabelen (i.e. het model is het meest ‘parsimonious’).\nZoals het geval was voor de anova() functie bij lineaire regressie kun je ook specifieke groepen van modellen vergelijken:\n\n#Past Model 4 beter dan Model 1?: Ja!\ntest_likelihoodratio(Vote_model1, Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model1 |   glm |  2 |         |       |       \nVote_model4 |   glm |  5 |       3 | 38.53 | &lt; .001\n\n#Past Model 3 beter dan een nulmodel?: Ja!\ntest_likelihoodratio(Vote_model0, Vote_model3)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model3 |   glm |  4 |       3 | 38.08 | &lt; .001\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nDe volgorde waarin we onze modellen aanduiden in de test_likelihoodratio() syntax bepaalt welke modellen precies vergeleken worden net zoals met anova() bij lineaire regressie ( Section 6.2). Bij een verkeerde volgorde krijg je een error in R. Een juiste volgorde houdt in dat je van minder naar meer complex gaat:\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model4,\n                     Vote_model2,\n                     Vote_model1,\n                     Vote_model3)\n\nError: The models are not nested, which is a prerequisite for\n  `test_likelihoodratio()`.\n  See the 'Details' section.\n  You may try `test_vuong()` instead.\n\n\nAls we 2 modellen testen en de eerste in de syntax is de meest complexe, dan krijgen we dezelfde Chi2 en p-waarde vergeleken met een juiste volgorde, maar de df_diff zal negatief zijn (-3 ipv +3 in dit voorbeeld). Op zich is dit geen probleem, zolang we maar weten wat we precies aan het vergelijken zijn zodat we geen interpretatiefouten maken.\n\ntest_likelihoodratio(Vote_model4, Vote_model1)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model4 |   glm |  5 |         |       |       \nVote_model1 |   glm |  2 |      -3 | 38.53 | &lt; .001"
  },
  {
    "objectID": "logit_04.html#pseudo-r2",
    "href": "logit_04.html#pseudo-r2",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "12.3 Pseudo R2",
    "text": "12.3 Pseudo R2\nBij een lineair regressiemodel beoordelen we fit met de R2 waarde. Een logistisch model is anders geschat en dus hebben we deze waarde niet. Verschillende zogenaamde pseudo R2 statistieken werden ontwikkeld om meer intuïtief inzicht te verkrijgen in de verklarende kracht van een model. De pseudo R2 maatstaven zijn gebaseerd op de lieklihood ratio test en kunnen niet als ‘proportie verklaarde variantie’ geïnterpreteerd worden.\nHier gebruiken we de Nagelkerke R². De waarde van deze maatstaf ligt tussen 0 en 1. Lage waarden wijzen op een lage verklarende kracht, hoge waarden op een hoge verklarende kracht.\nWe kunnen de Nagelkerke R² statistiek opvragen met de r2_nagelkerke() functie uit het performance package.\n\n# Nagelkerke R2: Model 3\nr2_nagelkerke(Vote_model3)\n\nNagelkerke's R2 \n     0.04698189 \n\n# Nagelkerke R2: Model 4\nr2_nagelkerke(Vote_model4)\n\nNagelkerke's R2 \n     0.04765513 \n\n\n\nr2_nagelkerke(\n\nDeze functie berekent de Nagelkerke R2 voor het model tussen haakjes. Er kan slecht 1 model opgegeven worden.\n\n\nDe Nagelkerke R2 is hoger voor Model 4 dan Model 3. Echter is een likelihood ratio test nodig om te weten of dit verschil significant is. Zoals we hierboven zagen is dit niet het geval.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nEr bestaan verschillende pseudo R2 statistieken om de fit van logistische regressiemodellen te helpen interpreteren. Geen enkele van hen kan geïnterpreteerd worden in termen van ‘proprotie verklaarde variantie’."
  },
  {
    "objectID": "logit_05.html#beperkte-multicollineariteit",
    "href": "logit_05.html#beperkte-multicollineariteit",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "13.1 Beperkte multicollineariteit",
    "text": "13.1 Beperkte multicollineariteit\nWe kunnen nagaan of ons model onderhevig is aan te sterke multicollineariteit met de vif() functie uit het car package. Dit is gelijkaardig aan wat we deden voor lineaire regressie ( Section 7.2). dezelfde vuistregels zijn van toepassing. Voor logistische regressiemodellen wordt een ‘generalized VIF’ berekend.\n\nvif(Vote_model4)\n\n    gndr     agea  trstplt  lrscale \n1.013505 1.018080 1.019284 1.013647 \n\n\nDe resultaten duiden op geen problemen met multicollineariteit."
  },
  {
    "objectID": "logit_05.html#lineariteit-van-de-logit",
    "href": "logit_05.html#lineariteit-van-de-logit",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "13.2 Lineariteit van de logit",
    "text": "13.2 Lineariteit van de logit\nLogistische regressie verondersteld dat veranderingen in de log odds (de logit) lineair geassocieerd zijn met Y=1. Om de assumptie te checken gebruiken we de augment() functie uit het broom package. Deze functie creëert een dataframe met de variabelen gebruikt in het model, alsook belangrijke statistieken om assumpties te testen:\n\naugment(Vote_model4)\n\n# A tibble: 1,425 × 11\n   vote  gndr    agea trstplt lrscale .fitted .resid    .hat .sigma   .cooksd\n   &lt;fct&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes   Female    32       6       5    1.62  0.601 0.00238  0.894 0.0000947\n 2 No    Male      57       7       5    2.32 -2.20  0.00175  0.893 0.00356  \n 3 Yes   Female    45       8       5    2.25  0.448 0.00220  0.894 0.0000467\n 4 Yes   Female    34       7       5    1.85  0.540 0.00237  0.894 0.0000749\n 5 Yes   Male      67       6       6    2.33  0.430 0.00188  0.894 0.0000365\n 6 No    Female    85       5       4    2.37 -2.22  0.00330  0.893 0.00710  \n 7 Yes   Female    40       7       5    1.96  0.513 0.00199  0.894 0.0000561\n 8 Yes   Male      71       8       7    2.83  0.339 0.00245  0.894 0.0000292\n 9 Yes   Female    84       5       5    2.38  0.421 0.00310  0.894 0.0000577\n10 Yes   Male      24       7       5    1.71  0.576 0.00360  0.894 0.000131 \n# ℹ 1,415 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nvote t.e.m. lrscale: Deze kolommen bevatten de geobserveerde waarden op de betreffende variabelen voor alle observaties gebruikt in het model.\n.fitted: De voorspelde (‘fitted’) waarden op basis van de schattingen in het model in ‘logit’ vorm en dus niet in probabiliteiten.\n.resid: De residuals (fouten/errors) voor elke observatie. Ook gekend als de “deviance residuals”.\n.hat: Diagonaal van de hat matrix (te negeren).\n.sigma: Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n.cooksd: Cook’s D waarden (zie onder).\n.std.resid: gestandaardiseerde residuals (zie onder).\n\n\n\nWe zullen verder werken met de augment statistieken hier en voor outliers en influential cases dus maken we een nieuw dataobject met de resultaten:\n\nmodel4_augmented &lt;- augment(Vote_model4, data = ESS9NL_glm)\n\n\naugment(Vote_model4, data=ESS9NL_glm)\n\nWe voegen deze syntax toe aan de functie: data = ESS9NL_glm. De reden is dat we zo een dataobject creëren met de augment-statistieken, de variabelen gebruikt in het model, en alle overige variabelen in de originele ESS9 dataset. Dit kan nuttig zijn voor bepaalde handelingen. We kunnen enkel de overige variabelen toevoegen als de datasets evenveel rijen hebben. Dit is niet het geval als er missing waarden zijn en het model minder observaties heeft dan de originele dataset. Vandaar dat we eerst een complete.casesdata subset hebben gemaakt hierboven.\n\n\nOm lineariteit te checken plotten we de logit die augment heeft berekend telkens tegenover de onafhankelijke variabelen in het model, specifiek de continue onafhankelijke variabelen. We maken een scatterplot met een loess-lijn en .fittedgeplot op de y-)as.\n\n# Leeftijd\nggplot(model4_augmented, aes(x = agea, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Vertrouwen in politici\nggplot(model4_augmented, aes(x = trstplt, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# LR-ideologie\nggplot(model4_augmented, aes(x = lrscale, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe gaan na of de loess lijn sterke afwijkingen van een lineaire relatie vertoont. Dit lijkt hier niet het geval."
  },
  {
    "objectID": "logit_05.html#beperkte-impact-outliers-en-influential-cases",
    "href": "logit_05.html#beperkte-impact-outliers-en-influential-cases",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "13.3 Beperkte impact outliers en influential cases",
    "text": "13.3 Beperkte impact outliers en influential cases\nMet de augment functie hebben we reeds de gestandaardiseerde residuals en Cook’s D waarden opgeslagen in een dataobject. We kijken eerst naar outliers, dan naar invloedrijke casussen\n\n13.3.1 Outliers\nWe bekijken eerst de descriptieve statistieken voor de gestandaardiseerde residuals:\n\nsummary(model4_augmented$.std.resid)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-2.3983  0.4104  0.5040  0.1870  0.5916  1.0319 \n\n\nDe output helpt ons na te gaan of er observaties zijn die de drempelwaarden (|1.96|, |2.58|, |3.29|) overschrijden. We zien dat de hoogste drempelwaarden (|2.58|, |3.29|) niet overschreden worden maar de laagste van 1.96 wel (het minimum is -2.398). Nu moeten we nog weten hoeveel observaties deze waarde overschrijden.\nDit kunnen we nagaan door net zoals bij lineaire regressie een dummy variabele te maken (0 = .std.resid &lt; |1.96|, 1 = .std.resid &gt; |1.96|) en de frequentietabel te inspecteren. 1 (zie Section 7.6.1 voor de syntax voor de andere drempelwaarden)\n\n#dummy variabele maken: \nmodel4_augmented &lt;- model4_augmented |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0\n  ))\n\n#proportie opzoeken \nfre(model4_augmented$SRE1.96)\n\n\n\n\nmodel4_augmented$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n1344\n94.3\n94.3\n94.3\n94.3\n\n\n 1 \n81\n5.7\n5.7\n5.7\n100.0\n\n\n #Total \n1425\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\n\n5.7% van de observaties liggen buiten het +/- 1.96 interval. Om te onderzoeken of deze outliers de parameters van het model beïnvloeden, kunnen we het model opnieuw schatten zonder deze observaties. We doen dit door in onze dataset enkel observaties met een waarde van ‘0’ op SRE1.96 op te nemen. We zouden dan de resultaten van het model met en het model zonder outliers vergelijken:\n\nVote_model41.96 &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = subset(model4_augmented, SRE1.96 == 0), \n                family = \"binomial\")\n\n\n\n13.3.2 Influential cases\nOm te onderzoeken of er invloedrijke casussen aanwezig zijn inspecteren we de Cook’s D waarden van de observaties in het model. We kunnen de descriptieve statistieken bekijken en het Cook’s D plot via de resid_panel() funtie uit het ggResidpanel package. We hanteren dezelfde vuistregels als voor lineaire regressie (zie Section 7.6.2).\n\n#Summary of the Cook's D values\nsummary(model4_augmented$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n2.331e-05 5.117e-05 8.959e-05 7.085e-04 2.442e-04 1.668e-02 \n\n#Plot\nresid_panel(Vote_model4, plots = c('cookd'))\n\nWarning in helper_plotly_label(model): NAs introduced by coercion\n\nWarning in helper_plotly_label(model): NAs introduced by coercion\n\n\n\n\n\nBeide methoden wijzen op lage Cook’s D waarden; de maximum waarde is slechts 0.017. Indien we hogere waarden zouden vinden, zouden we deze observaties uit de dataset kunnen filteren en het model opnieuw schatten om resultaten met en zonder invloedrijke casussen te vergelijken"
  },
  {
    "objectID": "logit_05.html#footnotes",
    "href": "logit_05.html#footnotes",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "",
    "text": "We zouden ook het gemiddelde van de 0/1 variabele kunnen berekenen gezien dit ons de proportie zou geven voor de ‘1’ cases.↩︎"
  },
  {
    "objectID": "logit_06.html#rapportage",
    "href": "logit_06.html#rapportage",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.1 Rapportage",
    "text": "14.1 Rapportage\nEen rapport van een logistisch regressiemodel bevat best de volgende zaken:\n\nEen bespreking van de richting van de relatie en wat dit concreet betekent (de codering van de variabelen inachtgenomen).\n\nBij een multiple regressie is het belangrijk te verduidelijken dat het effect dat je vindt voor een onafhankelijke variabele gecontroleerd is op de andere onafhankelijke variabelen in het model. Deze worden ‘constant gehouden’ (oftewel ‘ceteris paribus’).\n\nEen bespreking van de AMEs of voorspelde waarden om de sterkte van de associatie te duiden.\nEen bespreking van de statistische significantie (verwerpen of niet nulhypothese?) met vermelding van z-statistiek en p-waarde en/of het betrouwbaarheidsinterval.\n\nCoëfficiënten met p-waarden groter dan 0.05 worden meestal niet als statistisch significant of als statistisch significant bij conventionele niveaus beschouwd.1 Rapporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nHet betrouwbaarheidsinterval kan ook gebruikt worden om statistische significantie te bespreken en de onzekerheid rond de geschatte AMEs/voorspellingen aan te duiden. Als je het betrouwbaarheidsinterval bespreekt, kun je dit tussen haakjes toevoegen, bv. “het gemiddelde marginale effect van leeftijd is 0.004 (95% CI: -0.006, 0.013)”.\nHet is minder gebruikelijk de z-statistiek concreet te benoemen, maar het is ook geen probleem als je dit doet. Indien de z-waarde wordt opgenomen, zet je deze bij de p-waarde: “(z = 1.18, p &gt; 0.05)”.\n\n\nHieronder vind je een voorbeeld voor gndr (binaire factor) en trstplt (continue predictor) op basis van het hierboven geschatte model. Zie vorige hoofdstukken voor de berekening van de AME en odds ratio waarden.\n\n\n\n\n\n\nRapportagevoorbeeld\n\n\n\ntrstplt: De kans dat iemand gaat stemmen is hoger als vertrouwen in politici hoger is. De kans neemt gemiddeld genomen met 2.3 percentpunten toe als vertouwen met 1 eenheid stijgt. De relatie is statistisch significant (p &lt; 0.001).\ngndr (AME example): De kans om te stemmen is gemiddeld 4.3 percentpunten hoger voor mannen dan voor vrouwen. Deze relatie is echter niet statistisch significant (p = 0.78).\ngndr (Odds Ratio Example): De odds om te stemmen voor mannen zijn 1.04 keer hoger dan die voor vrouwen. Het verschil is echter niet statistisch significant (p = 0.78).\n\n\nBijkomende richtlijnen voor besprekingen in papers:\n\nIn je rapportage kun je ook een bespreking van de voorspelde waarden opnemen (bv. wat is de voorspelde kans dat iemand gaat stemmen bij lage en hoge niveaus van vetrouwen in politici?) Een plot van voorspelde waarden kan de bespreking verder verduidelijken. Zie Section 14.5 voor meer informatie.\nAls je onderzoek vooral gericht is op de relatie tussen een specifieke onafhankelijke variabele en de afhankelijke variabele dan is een discussie over de controlevariabelen doorgaans niet nodig.\nHet intercept wordt zelden besproken bij logistische regressies.\nWees voorzichting in je bespreking van de relatie tussen de variabelen. Causaliteit is moeilijk te bepalen en is onderhevig aan sterke voorwaarden. Je schrijft bijgevolg dus meestal niet het “effect van X op Y” , maar “de verandering in X is geassocieerd met de verandering in Y”."
  },
  {
    "objectID": "logit_06.html#sec-presentation-regression-tables-logit",
    "href": "logit_06.html#sec-presentation-regression-tables-logit",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.2 Presentatie: Regressietabellen",
    "text": "14.2 Presentatie: Regressietabellen\nWe gebruiken de modelsummary() funcie uit het modelsummary package om regressietabellen te produceren. De procedure en syntax is gelijkaardig aan die voor lineaire regressietabellen (zie Section 8.4). Het belangrijkste verschil zit in de model fit statistieken.\n\nmodelsummary(Vote_model_mp,\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constante\",\n                             \"agea\" = \"Leeftijd\",\n                             \"gndrMale\" = \"Man\",\n                             \"trstplt\"= \"Vertrouwen in politici\",\n                             \"lrscale\" = \"links-recht positie\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Opkomst in Nederland (ESS9)\",\n             notes = (\"Logistische regressiecoëfficiënten met standaardfouten tussen haakjes\"))\n\n\nOpkomst in Nederland (ESS9)\n\n\n\n (1)\n\n\n\n\nConstante\n-0.284\n\n\n\n(0.380)\n\n\nMan\n0.043\n\n\n\n(0.154)\n\n\nLeeftijd\n0.018***\n\n\n\n(0.005)\n\n\nVertrouwen in politici\n0.195***\n\n\n\n(0.039)\n\n\nlinks-recht positie\n0.029\n\n\n\n(0.039)\n\n\nNum.Obs.\n1425\n\n\nLog.Lik.\n-567.653\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n Logistische regressiecoëfficiënten met standaardfouten tussen haakjes\n\n\n\n\n\n\n\n\n\n\ngof_map = c(\"nobs\", \"logLik\")\n\nWe kunnen verschillende goodness-of-fit statistieken toevoegen aan de tabel. Hier beperken we ons tot het aantal observaties en de log likelihood. We kunnen alle statistieken weglaten met gof_map = NA. Het is meestal een goed idee een Pseudo R2 maatstaf als goodness-of-fit statistiek toe te voegen aan de tabel. modelsummary() voegt echter niet automatisch de Nagelkerke R2 toe. We kunnen deze wel manueel toevoegen aan de tabel in Word in een rij onder ‘Log.Lik.’.\n\n\n\n14.2.1 Tabellen met Odds Ratios\nOm odds ratios en hun betrouwbaarheidsintervallen in de regressietabel te presenteren moeten een aantal elementen toegevoegd worden. Vergeet in dit geval ook niet het onderschrift (notes) te veranderen.\n\nmodelsummary(Vote_model_mp,\n1             exponentiate = TRUE, conf_level=0.95,\n2             statistic = 'conf.int',\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constante\",\n                             \"agea\" = \"Leeftijd\",\n                             \"gndrMale\" = \"Man\",\n                             \"trstplt\"= \"Vertrouwen in politici\",\n                             \"lrscale\" = \"links-recht positie\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Opkomst in Nederland (ESS9)\",\n             notes = (\"Odds ratios met 95% betrouwbaarheidsintervallen\"))\n\n\n1\n\nVraagt modelsummary() de logistische coëfficiënten te exponentiëren, wat de odds ratios oplevert.\n\n2\n\nVraagt modelsummary() de 95% betrouwbaarheidsintervallen te produceren. Dit is gebruikelijk bij odds ratios.\n\n\n\n\n\nOpkomst in Nederland (ESS9)\n\n\n\n (1)\n\n\n\n\nConstante\n0.753\n\n\n\n[0.357, 1.588]\n\n\nMan\n1.044\n\n\n\n[0.772, 1.413]\n\n\nLeeftijd\n1.019***\n\n\n\n[1.010, 1.028]\n\n\nVertrouwen in politici\n1.215***\n\n\n\n[1.126, 1.311]\n\n\nlinks-recht positie\n1.030\n\n\n\n[0.953, 1.112]\n\n\nNum.Obs.\n1425\n\n\nLog.Lik.\n-567.653\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n Odds ratios met 95% betrouwbaarheidsintervallen\n\n\n\n\n\n\n\n\n\n\nexponentiate = TRUE,\n\nMet deze code vragen we om de exponentiële coëfficiënten, i.e., de odds ratios.\n\nconf_level=0.95,\n\nMet deze code kunnen we het betrouwbaarheidsniveau aanpassen. Standaard is dit niveau 0.95. Als dit het gewenste niveau is, kan deze code ook worden weggelaten.\n\nstatistic = 'conf.int'\n\nMet deze code vragen we om betrouwbaarheidsintervallen te presenteren en niet de standaardfouten (de default)."
  },
  {
    "objectID": "logit_06.html#presentatie-plots-van-coëfficiënten-en-odds-ratios",
    "href": "logit_06.html#presentatie-plots-van-coëfficiënten-en-odds-ratios",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.3 Presentatie: Plots van coëfficiënten (en odds ratios)",
    "text": "14.3 Presentatie: Plots van coëfficiënten (en odds ratios)\nWe kunnen de output ook presenteren in de vorm van een coefficiëntenplot (eventueel met de volledige regressietabel in Appendix), net zoals bij lineaire regressiemodellen. De procedure wordt beschreven in Section 8.5 . Hier is een voorbeeld op basis van bovenstaand model:\n\n1tidy(Vote_model_mp, conf.int = TRUE) |&gt;\n2  filter(term != \"(Intercept)\") |&gt;\n3  mutate(term = recode(term,\n                       \"gndrMale\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x= estimate, y= term)) +\n  geom_pointrange(aes(xmin=conf.low, \n                      xmax=conf.high)) +\n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Logistische regressiecoëfficiënt\") + \n  geom_vline(xintercept=0, linetype=\"dashed\", color=\"red\") +\n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.1)\n\n\n1\n\nWe produceren het plot in 1 stap, gebruikmakend van de |&gt; operator. Je zou de syntax echter kunnen opbreken in meerdere stappen: (1) tidyresultaten opslaan in nieuw object; (2) Hercoderen van de term variabelen in dat object; en (3) plot maken.\n\n2\n\nHet intercept wordt doorgaans niet getoond.\n\n3\n\nWe zouden i.p.v. recode() ook eerst een factor kunnen maken van de termvariabele met factor(). Daarmee zouden we labels kunnen toevoegen en de volgorde waarin de variabelen verschijnen kunnen aanpassen. Zie Section 8.5.\n\n\n\n\n\n\n\nAls we odds ratios willen plotten vragen we eerts dat tidy() odds ratios produceert en vervolgens zetten we de referentielijn voor statistische significantie op 1. We veranderen ook het label op de x-as.:\n\n1tidy(Vote_model_mp, conf.int = TRUE, exponentiate = TRUE) |&gt;\n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"gndrMale\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x= estimate, y= term)) +\n  geom_pointrange(aes(xmin=conf.low, \n                      xmax=conf.high)) +\n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Odds Ratio\") + \n2  geom_vline(xintercept = 1, linetype = 'dashed', color ='red') +\n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nexponentiate = TRUE voor de odds ratios\n\n2\n\nOdds ratios zijn multiplicatief. Daarom moet de referentielijn op 1 komen te staan\n\n\n\n\n\n\n\n\n14.3.1 Instructies\n\nMeestal plaats je de coëfficiënt op de x-as en de naam van de variabele op de y-as. Het is mogelijk dit te veranderen met de ggplot syntax, maar dan kunnen de variabelenamen makkelijker overlappen. Lange variabelennamen leiden wel vaker tot problemen met de visualisatie (in deze blog vind je enkele tips).\nStandaard plot ggplot de coëfficiënten in alfabetische volgorde. Dit kan ervoor zorgen dat variabelen die bij elkaar horen (bv. meerdere dummies van 1 onderliggende categorische variabele) niet bij elkaar staan in het plot (zoals in het voorbeeld hierboven). We kunnen de volgorde aanpassen als we de term variabele omzetten in een factor variabele en de volgorde van de levels zelf bepalen. Zie Section 8.5\nHet toevoegen van de (afgeronde) coëfficiënt-waarde kan lezers helpen de resultaten beter te vatten.\nMeestal plotten we de 95% betrouwbaarheidsintervallen, maar dit kan aangepast worden (we kunnen tidy om andere niveaus vragen).\nIn een rapport voeg je best een notitie onderaan de figuur toe, bv. “Notitie: OLS coëfficiënten met 95% betrouwbaarheidsinterval”.\nHet is handig en gebruikelijk een referentielijn toe te voegen die nul aanduidt want dan kan statistische significantie (hier: bij p &lt; 0.05) onmiddellijk afgelezen worden."
  },
  {
    "objectID": "logit_06.html#presentatie-ame-plots",
    "href": "logit_06.html#presentatie-ame-plots",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.4 Presentatie: AME Plots",
    "text": "14.4 Presentatie: AME Plots\nWe kunnen ook de gemiddelde marginale effect ( average marginal effects, AME) plotten. Dit kan het meest informatieve zijn voor lezers gezien deze waarden in termen van probabiliteiten geïnterpreteerd kunnen worden. De procedure is gelijkaardig aan die voor coëfficiëntenplots, maar in plaats van tidy() gebruiken we de avg_slopes() functie uit het marginaleffects package:\n\n1avg_slopes(Vote_model_mp) |&gt;\n2  mutate(term = recode(term,\n3                       \"gndr\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Gemiddelde Marginale Effect\") + \n  geom_vline(xintercept = 0, linetype = 'dashed', color ='red') + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nWe produceren het plot in 1 stap, gebruikmakend van de |&gt; operator. Je zou de syntax echter kunnen opbreken in meerdere stappen: (1) avg_slopesresultaten opslaan in nieuw object; (2) Hercoderen van de term variabelen in dat object; en (3) plot\n\n2\n\nWe zouden i.p.v. recode() ook eerst een factor kunnen maken van de termvariabele met factor(). Daarmee zouden we labels kunnen toevoegen en de volgorde waarin de variabelen verschijnen kunnen aanpassen. Zie Section 8.5.\n\n3\n\navg_slopes() combineert niet de variabelenaam en de categorielabel bij factor variabelen in term (bv. het toont gndr in plaats van gndrMale).\n\n\n\n\n\n\n\nBovenstaand voorbeeld plot probabiliteiten lopende van 0 tot 1. We kunnen deze ook in percentagepunten uitdrukken wanneer we de AME (estimate) en de betrouwbaarheidsintervallen (conf.low, conf.high) met 100 vermenigvuldigen:\n\navg_slopes(Vote_model_mp) |&gt; \n   mutate(term = recode(term,\n                       \"gndr\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\"), \n         estimate = estimate * 100, \n         conf.low = conf.low * 100,\n         conf.high = conf.high * 100) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Gemiddelde Marginale Effect (Percentpunten)\") + \n  geom_vline(xintercept = 0, linetype = 'dashed', color ='red') + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n\n\n\n14.4.1 Instructies\nDe richtlijnen voor coëfficiënteplots worden ook hier gehanteerd (zie boven en Section 8.5)."
  },
  {
    "objectID": "logit_06.html#sec-presentation-predicted-probability-plots",
    "href": "logit_06.html#sec-presentation-predicted-probability-plots",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.5 Presentatie: Plots van Voorspelde Waarden",
    "text": "14.5 Presentatie: Plots van Voorspelde Waarden\nTen slotte kunnen we de resultaten van een model ook grafisch presenteren met behulp van voorspelde waarden. We zagen eerder hoe we de voorspelde waarden plotten voor specifieke waarden van een continue of categorische onafhankelijke variabele in een lineair regressiemodel (see Section 8.6). Nu doen we hetzelfde voor logistische modellen.\n\n14.5.1 Continue onafhankelijke variabele\nDe output van het model toonde dat stemmen waarcshijnlijker wordt naarmate mensen meer vertouwen hebben in politici. De AME toonde dat de stijging gemiddeld 2.3 percentpunten was per eenheid vertrouwen. Maar hoeveel impact heeft dit dan echt op stemgedrag? Gaat men van heel onwaarschijnlijk tot zeer waarschijnlijk om te stemmen? Een plot kan helpen dit te veruidelijken.\nWe beginnen met de predictions() functie om de voorspelde kansen te berekenen bij verschillende waarden van vetrouwen in politici (trstplt)..\n\n#Voorspellingen opslaan\nPred_conts &lt;- predictions(Vote_model_mp, \n1                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2)))\n#en bekijken\ntibble(Pred_conts)\n\n\n1\n\nWe zouden predictions() ook intervallen van 1pt kunnen laten berekenen, maar dit is doorgaans niet nodig. ggplot() verbindt de punten in een lijn.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr   agea lrscale trstplt\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male   50.7    5.15       0\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male   50.7    5.15       2\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male   50.7    5.15       4\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male   50.7    5.15       6\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male   50.7    5.15       8\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male   50.7    5.15      10\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\nWe voeren deze data door naar ggplot() zoals we voorheen ook bij lineaire regressie deden:\n\n1ggplot(Pred_conts, aes(x = trstplt, y = estimate)) +\n2  geom_line() +\n3  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +\n4  labs(title = \"Vertrouwen en opkomst in Nederland\",\n             x = \"Vertrouwen in politici\", \n       y = \"Voorspelde kans om te stemmen\")\n\n\n1\n\nZegt ggplot() welke data te gebruiken (Pred_conts) en wat op de x- (trstplt) en y-as (estimate) te zetten.\n\n2\n\nZegt ggplot() dat we een verbindingslijn willen tussen de voorspellingen.\n\n3\n\nZegt ggplot() dat we een band met betrouwbaarheidsintervallen willen en hoe donker de kleur daarvan mag zijn (alpha = 0.2).\n\n4\n\nInformatieve labels.\n\n\n\n\n\n\n\nWe zouden ook de schaal van y kunnen aanpassen om het volledige theoretische bereik van probabiliteiten (0 tot 1) weer te geven, indien we denken dat resultaten misleidend kunnen zijn zonder deze aanpassing:\n\nggplot(Pred_conts, aes(x = trstplt, y = estimate)) +   \n  geom_line() +                                        \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +  \n  labs(title = \"Vertrouwen en opkomst in Nederland\",\n             x = \"Vertrouwen in politici\", \n       y = \"Voorspelde kans om te stemmen\") + \n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\n\n14.5.2 Factor onafhankelijke variabele\nWe kunnen deze syntax gebruiken voor predictors die factors zijn:\n\n#Voorspellingen opslaan\nPred_cat &lt;- predictions(Vote_model_mp, by = \"gndr\", newdata = \"mean\") \n\n#en bekijken\ntibble(Pred_cat)\n\n# A tibble: 2 × 11\n  rowid gndr  estimate  p.value s.value conf.low conf.high  agea trstplt lrscale\n  &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Fema…    0.863 1.35e-60    199.    0.835     0.887  50.7    5.34    5.15\n2     2 Male     0.868 1.44e-64    212.    0.841     0.891  50.7    5.34    5.15\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\nDe data wordt dan naar een plot overgezet:\n\nggplot(Pred_cat, aes(x= gndr, y= estimate)) +   \n  geom_pointrange(aes(ymin=conf.low, ymax=conf.high)) +  \n  labs(title = \"Gender en opkomst in Nederland\", \n       x = \"Gender\",\n       y = \"Voorspelde kans om te stemmen\") +\n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25) +\n  scale_y_continuous(limits=c(0.8,0.9))+\n  scale_x_discrete(labels = c(\"Male\" = \"Man\", \"Female\" = \"Vrouw\"))\n\n\n\n\n\n\n14.5.3 Instructies\n\nWelke variabelen en waarden plot je?\n\nAls de variabele binair/categorisch is, gebruik je alle categorieën die relevant zijn voor de discussie.\nAls de variabele continue is gebruik je het minimum en maximum met redelijke tussenintervallen. Om het minimum en maximum te bepalen kijk je naar de data voor de observaties gebruikt in het model (dit is niet noodzakelijk de volledige dataset gezien observaties kunnen wegvallen door missing waarden). Met de predictions() kun je gemakkelijk een dataset aanmaken met alle observaties gebruikt in het model en vervolgens gebruik je summary om minimum en maximum te bepalen (zie Section 5.3.1).\n\nWe gebruiken een lijn met betrouwbaarheidsintervallen voor contnue predictoren; voor categorische doen we beroep op geom_pointrange() of geom_errorbar().\nDe y-schaal verdient bijzonder aandacht bij dit soort plots. In het voorbeeld wordt scale_y_continuous() gebruikt om ervoor te zorgen dat het plot het volledige bereik van de afhankelijke variabele (democratiescore) omvat. Soms maakt ggplot() zelf de schaal kleiner (om ongebruikte ruimte weg te laten), maar dan kan een effect groter lijken dan het is. Deze aanpak heeft ook wel nadelen, bijvoorbeeld juist veel ongebruikte ruimte in een plot en minder duidelijke visualisatie. Socioloog Kieran Healy geeft een verdere bespreking over deze verschillende manieren om de schaal vorm te geven in zijn boek over datavisualisatie."
  },
  {
    "objectID": "logit_06.html#footnotes",
    "href": "logit_06.html#footnotes",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "Als de N van het model laag is, kan eventueel een 90% niveau gebruikt worden.↩︎"
  },
  {
    "objectID": "part_interactions.html",
    "href": "part_interactions.html",
    "title": "Interacties in Lineaire en Logistische Regressiemodellen",
    "section": "",
    "text": "In dit onderdeel ligt de focus op de inclusie van interactie-effecten in regressieanalyses en hun interpretatie. Je leert hoe je…\n\nInteractievariabelen toevoegt aan regressiemodellen\ngemiddelde marginale effecten en voorspelde waarden/kansen gebruikt om interactie te interpreteren."
  },
  {
    "objectID": "interaction_01.html#een-interactie-in-het-regressiemodel",
    "href": "interaction_01.html#een-interactie-in-het-regressiemodel",
    "title": "15  Interacties in het Regressiemodel",
    "section": "15.1 Een interactie in het regressiemodel",
    "text": "15.1 Een interactie in het regressiemodel\nZowel bij lineaire (lm) als logistische (glm) regressie kunnen we meerdere onafhankelijke variabelen toevoegen door gebruik te maken van het ‘+’ teken. We kunnen een interactie tussen twee onafhankelijke variabelen toevoegen door het ‘*’ teken in plaats van de ‘+’ te gebruiken.\nIn het volgende lineaire regressiemodel voorspellen we hoe respondenten kandidaat en uitdager Joe Biden evalueren op een schaal van 0 (‘heel koud of ongunstig’) tot 100 (‘heel warm of gunstig’) door gebruik te maken van 3 predictors:\n\npid: ‘partisan identity’ of partij-identificatie, een continue variabele die loopt van 1 ‘Overtuigd Democraat’ tot 7 ‘Overtuigd Republikein’;\nright_track: een binaire, factor variabele waarbij ‘0’ betekent dat een respondent vindt dat het de verkeerde richting uitgaat met het land en ‘1’ dat het de goede richting uitgaat met het land;\nrural_urban: een categorische variabele die aangeeft in welk soort locatie een respondent woont, met ‘suburb’ als referentiecategorie.\n\n\n#Model schatten en resultaten opslaan\nbiden_model &lt;- lm(biden ~ pid + right_track + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_model)\n\n\nCall:\nlm(formula = biden ~ pid + right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-83.656 -13.349   0.771  16.344  90.722 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 93.9170     0.6543 143.537  &lt; 2e-16 ***\npid                        -10.2606     0.1364 -75.245  &lt; 2e-16 ***\nright_trackRight Direction -12.8153     0.6993 -18.326  &lt; 2e-16 ***\nrural_urbanRural            -4.1666     0.8219  -5.070 4.09e-07 ***\nrural_urbanSmall Town       -2.9846     0.7011  -4.257 2.10e-05 ***\nrural_urbanCity             -0.3076     0.6713  -0.458    0.647    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.88 on 7141 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.602, Adjusted R-squared:  0.6018 \nF-statistic:  2161 on 5 and 7141 DF,  p-value: &lt; 2.2e-16\n\n\nBiden wordt minder positief ingeschat als partij-identificatie meer richting Republikeinen gaat en als respondenten vinden dat het de goede richting uitgaat met het land (onder Trump). Er zijn ook verschillen voor locatie. 1\nStel dat we op basis van theorie denken dat er een interactie is tussen partij-identificatie en de evaluatie dat het land in de goede/slechte richting gaat. We kunnen denken dat het effect van pid op de evaluatie van Biden anders is als men vindt dat het land in de slechte richting in plaats van de goede richting beweegt. Of we denken dat het effect van right_track anders is voor (overtuigde) Democraten en Republikeinen. Beide hypotheses onderzoeken we door dezelfde interactieterm toe te voegen aan het model. We verbinden hiervoor 2 onafhankelijke variabelen met een (‘*’) in plaats van een (‘+’) teken.\n\n#Model schatten en resultaten opslaan\nbiden_int &lt;- lm(biden ~ pid * right_track + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_int)\n\n\nCall:\nlm(formula = biden ~ pid * right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-84.834 -13.186   0.166  15.166  87.299 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     95.6585     0.6730 142.146  &lt; 2e-16 ***\npid                            -10.8243     0.1468 -73.744  &lt; 2e-16 ***\nright_trackRight Direction     -33.1885     2.1600 -15.365  &lt; 2e-16 ***\nrural_urbanRural                -4.0838     0.8163  -5.003 5.79e-07 ***\nrural_urbanSmall Town           -2.8082     0.6965  -4.032 5.60e-05 ***\nrural_urbanCity                 -0.3202     0.6667  -0.480    0.631    \npid:right_trackRight Direction   3.7144     0.3729   9.961  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.73 on 7140 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.6075,    Adjusted R-squared:  0.6072 \nF-statistic:  1842 on 6 and 7140 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe structuur van de output is dezelfde als bij lineaire regressimodellen zonder interactie, behalve dat een nieuwe term werd toegevoegd: pid:right_trackRight Direction.\nWanneer we 2 predictoren verbinden met het ‘*’ teken, voegt R de beide variabelen toe en daarnaast ook de interactieterm, oftewel de vermenigvuldiging van de variabelen. De naam die we terugvinden voor de interactieterm voegt de 2 predictoren samen met een dubbelpunt (pid:right_trackRight Direction).\n\n\nVoor een logistisch model wordt hetzelfde principe gevolgd. Hier voorspellen we of een persoon vindt dat de VS de goede (1) of verkeerde (0) richting uitgaat met de variabele right_track. We gebruiken de volgende predictoren: vote2016, voor wie gestemd werd in 2016 (Hillary Clinton = 0, Donald Trump = 1); age, leeftijd in jaren; en rural_urban, locatie. We voegen een interactie toe tussen vote2016 en age in dit voorbeeld.\n\n#Model schatten en resultaten opslaan\nrighttrack_int &lt;- glm(right_track ~ vote2016 * age + rural_urban, \n                      family = \"binomial\", data = anes)\n#Overzicht resultaten\nsummary(righttrack_int)\n\n\nCall:\nglm(formula = right_track ~ vote2016 * age + rural_urban, family = \"binomial\", \n    data = anes)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.952141   0.344679  -8.565  &lt; 2e-16 ***\nvote2016Trump Vote      2.820292   0.373350   7.554 4.22e-14 ***\nage                    -0.009465   0.006296  -1.503   0.1328    \nrural_urbanRural        0.208129   0.111289   1.870   0.0615 .  \nrural_urbanSmall Town   0.110962   0.101173   1.097   0.2727    \nrural_urbanCity         0.160473   0.110704   1.450   0.1472    \nvote2016Trump Vote:age  0.012914   0.006823   1.893   0.0584 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5929.4  on 5132  degrees of freedom\nResidual deviance: 4033.5  on 5126  degrees of freedom\n  (3147 observations deleted due to missingness)\nAIC: 4047.5\n\nNumber of Fisher Scoring iterations: 6\n\n\n::: callout-warning #### Interpretatie\nWanneer we een interactie testen, vragen we ons eigenlijk af of het effect van een bepaalde predictor (X) op de afhankelijke variable (Y) anders is wanneer een tweede predictor (Z) andere waarden aanneemt..\n\n\n\n\n\nDe coëfficiënt van de interactie vertelt ons of dit het geval is. In het lineaire “biden_int” model, bijvoorbeeld, vinden we dat de coëfficiënt statistisch significant is: de relatie tussen partij-identificatie en hoe een respondent Biden evalueert, hangt af van de opinie van de respondent over de richting dat het land uitgaat.2 De interactievariabele in het logistische “righttrack_int” model is echter niet statistisch significant (we gebruiken hier een standaard 95% betrouwbaarheidsniveau). Dit betekent dat bijvoorbeeld de relatie tussen leeftijd en opinie over het land hetzelfde is ongeacht of respondenten in 2016 op Clinton of Trump hebben gestemd.\nOm interactietermen beter te begrijpen, kunnen we R gebruiken om:\n\nHet marginale effect van 1 onafhankelijke variabele (X) op Y te berekenen bij verschillende waarden van de andere onafhankelijke (Z) (Chapter 16).\nDe voorspelde waarden voor Y te berekenen voor verschillende combinaties van waarden van de 2 onafhankelijke variabelen (Chapter 17)."
  },
  {
    "objectID": "interaction_01.html#regressietabellen",
    "href": "interaction_01.html#regressietabellen",
    "title": "15  Interacties in het Regressiemodel",
    "section": "15.2 Regressietabellen",
    "text": "15.2 Regressietabellen\nIn de volgende 2 hoofdstukken gaan we dieper in op hoe je interactie-effecten best kan begrijpen en communiceren met plot. Hier lichten we kort toe hoe ze te presenteren in regressietabellen. We maken hiervoor weer gebruik van de modelsummary() functie uit het modelsummary package. De basisprincipes zijn dezelfde als degene die we bespraken in eerdere hoofdstukken (lineaire regressietabellen: Section 8.4 ; logistische regressietabellen: Section 14.2 ).\nWe zullen de resultaten van het model zonder en het model met interactie naast elkaar presenteren. Zo ziet de lezer onmiddellijk het verschil tussen beide modellen.\n\n# Lijst van modellen\n1interaction_lm_models &lt;- list(\n  biden_model, biden_int\n)\n\n#Tabel maken\nmodelsummary(interaction_lm_models, \n2             stars = T,\n3             coef_rename = c(\n               \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n               \"right_trackRight Direction\" = \"Land gaat in de goede richting\", \n               \"rural_urbanCity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\", \n               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\"), \n4             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n5             title = \"Evaluatie van kandidaat Biden\",\n6             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\")\n\n\n1\n\nLijst van modellen om te gebruiken in de tabel\n\n2\n\nToevoegen van stersymbolen voor statistische significantie\n\n3\n\nDuidelijke namen geven aan variabelen coef_rename()\n\n4\n\nModel fit statistieken selecteren gof_map()\n\n5\n\nInformatieve titel met title =\n\n6\n\nDuidelijke notitie over wat we precies weergeven in de tabel notes =\n\n\n\n\n\nEvaluatie van kandidaat Biden\n\n\n\n (1)\n  (2)\n\n\n\n\nConstante\n93.917***\n95.659***\n\n\n\n(0.654)\n(0.673)\n\n\nPartij-Identificatie (PID)\n-10.261***\n-10.824***\n\n\n\n(0.136)\n(0.147)\n\n\nLand gaat in de goede richting\n-12.815***\n-33.188***\n\n\n\n(0.699)\n(2.160)\n\n\nLandelijk gebied (Ref. Stedelijke buitenwijk)\n-4.167***\n-4.084***\n\n\n\n(0.822)\n(0.816)\n\n\nKleine stad (Ref. Stedelijke buitenwijk)\n-2.985***\n-2.808***\n\n\n\n(0.701)\n(0.697)\n\n\nStad (Ref. Stedelijke buitenwijk)\n-0.308\n-0.320\n\n\n\n(0.671)\n(0.667)\n\n\nPID x Juiste Richting\n\n3.714***\n\n\n\n\n(0.373)\n\n\nNum.Obs.\n7147\n7147\n\n\nR2\n0.602\n0.607\n\n\nR2 Adj.\n0.602\n0.607\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n OLS coëfficiënten met standaardfouten tussen haakjes\n\n\n\n\n\n\n\n\n\n\nWat we hier nog zouden willen veranderen is de interactieterm dichter bij de hoofdvariabelen van de interactie zetten in plaats van standaard onderaan de tabel. Dit kunnen we door i.p.v. coef_rename gebruik te maken van coef_map. Zo kunnen we ook de volgorde van de variabelen bepalen.\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n1             coef_map = c(\n              \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n               \"right_trackRight Direction\" = \"Land gaat in de goede richting\", \n2               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\",\n               \"rural_urbanCity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Evaluatie van kandidaat Biden\", # \n             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\") \n\n\n1\n\nVerander coef_rename naar coef_map\n\n2\n\nInteractieterm dichter bij hoofdvariabelen.\n\n\n\n\n\nEvaluatie van kandidaat Biden\n\n\n\n (1)\n  (2)\n\n\n\n\nConstante\n93.917***\n95.659***\n\n\n\n(0.654)\n(0.673)\n\n\nPartij-Identificatie (PID)\n-10.261***\n-10.824***\n\n\n\n(0.136)\n(0.147)\n\n\nLand gaat in de goede richting\n-12.815***\n-33.188***\n\n\n\n(0.699)\n(2.160)\n\n\nPID x Juiste Richting\n\n3.714***\n\n\n\n\n(0.373)\n\n\nStad (Ref. Stedelijke buitenwijk)\n-0.308\n-0.320\n\n\n\n(0.671)\n(0.667)\n\n\nLandelijk gebied (Ref. Stedelijke buitenwijk)\n-4.167***\n-4.084***\n\n\n\n(0.822)\n(0.816)\n\n\nKleine stad (Ref. Stedelijke buitenwijk)\n-2.985***\n-2.808***\n\n\n\n(0.701)\n(0.697)\n\n\nNum.Obs.\n7147\n7147\n\n\nR2\n0.602\n0.607\n\n\nR2 Adj.\n0.602\n0.607\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n OLS coëfficiënten met standaardfouten tussen haakjes\n\n\n\n\n\n\n\n\n\n\nMet deze syntax zetten we de interactieterm net onder de twee variabelen waaruit de interactie bestaat (pid en right_track).\n\n\n\n\n\n\nWaarschuwing!\n\n\n\ncoef_map is handig maar is gevoelig aan het juist typen van de variabelenamen. Waar coef_rename bij een typfout gewoon de oude naam geeft, doet coef_map de variabele in z’n geheel verdwijnen. Laten we bij wijze van voorbeeld 2 typfouten maken. We schrijven “right_trackRight direction” i.p.v. “right_trackRight Direction” en “rural_urbancity” i.p.v. “rural_urbanCity”:\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n             coef_map = c(\n              \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n1               \"right_trackRight direction\" = \"Land gaat in de goede richting\",\n               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\",  \n2               \"rural_urbancity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Evaluatie van kandidaat Biden\", # \n             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\")  \n\n\n1\n\nDirection naar direction\n\n2\n\nCity naar city\n\n\n\n\n\nEvaluatie van kandidaat Biden\n\n\n\n (1)\n  (2)\n\n\n\n\nConstante\n93.917***\n95.659***\n\n\n\n(0.654)\n(0.673)\n\n\nPartij-Identificatie (PID)\n-10.261***\n-10.824***\n\n\n\n(0.136)\n(0.147)\n\n\nPID x Juiste Richting\n\n3.714***\n\n\n\n\n(0.373)\n\n\nLandelijk gebied (Ref. Stedelijke buitenwijk)\n-4.167***\n-4.084***\n\n\n\n(0.822)\n(0.816)\n\n\nKleine stad (Ref. Stedelijke buitenwijk)\n-2.985***\n-2.808***\n\n\n\n(0.701)\n(0.697)\n\n\nNum.Obs.\n7147\n7147\n\n\nR2\n0.602\n0.607\n\n\nR2 Adj.\n0.602\n0.607\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n OLS coëfficiënten met standaardfouten tussen haakjes\n\n\n\n\n\n\n\n\n\n\nDe coëfficiënten voor deze variabelen zijn nu verdwenen uit de tabel. Je krijgt geen waarschuwing dus moet je extra opletten. Meer info over coef_map vind je op de modelsummary website (link)"
  },
  {
    "objectID": "interaction_01.html#footnotes",
    "href": "interaction_01.html#footnotes",
    "title": "15  Interacties in het Regressiemodel",
    "section": "",
    "text": "De dataset bevat ook een variabele voor hoe respondenten Donald Trump evalueren (also has a measure of evaluations of Donald Trump (the variable named (trump). Mensen die vinden dat het land de slechte richting op gaat zijn negatiever voor Trump dan mensen die vinden dat het land de goede richting uitgaat.↩︎\nInteracties zijn symmetrisch, dus we kunnen ook stellen dat het effect van ‘right_track’ op Biden score verschilt naarmate respondenten een andere patij-identificatie hebben. Welke variabele als hoofdvariabele (X) en welke als moderator (Z) wordt beschouwd is aan de onderzoeker.↩︎"
  },
  {
    "objectID": "interaction_02.html#binaire-x-continue-interactie",
    "href": "interaction_02.html#binaire-x-continue-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.1 Binaire X Continue Interactie",
    "text": "16.1 Binaire X Continue Interactie\n\n16.1.1 Berekening en interpretatie\nWe bekijken eerst hoe we de marginale effecten berekenen voor een interactie tussen een binaire en continue variabele. Dit was het geval voor ons ‘biden_int’ model waarin een interactie werd toegevoegd tussen partij-identificatie (pid, loopt van 1 ‘Overtuigd Democraat’ tot 7 ‘Overtuigd Republikein’) en right_track (waarbij ‘0’ betekent dat een respondent vindt dat het de verkeerde richting uitgaat met het land en ‘1’ dat het de goede richting uitgaat met het land).\nHier gebruiken we de slopes() functie om het effect van pid op Biden scores te berekenen voor elke waarde van right_track. Wanneer de moderator (Z) een factor variabele is, zoals hier het geval is, gebruiken we de volgende code:\n\nslopes(biden_int, \n       variables = \"pid\", \n       by = \"right_track\")\n\n\n Term    Contrast     right_track Estimate Std. Error     z Pr(&gt;|z|)     S\n  pid mean(dY/dX) Wrong Track       -10.82      0.147 -73.7   &lt;0.001   Inf\n  pid mean(dY/dX) Right Direction    -7.11      0.344 -20.7   &lt;0.001 312.7\n  2.5 % 97.5 %\n -11.11 -10.54\n  -7.78  -6.44\n\nColumns: term, contrast, right_track, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\nslopes(biden_int,\n\nWe passen de functie slopes toe op het model tussen haakjes.\n\nvariables = \"pid\"\n\nWe duiden hier de onafhankelijke variabele aan waarvoor we de verschillende marginale effecten willen berekenen. Voor eigen toepassingen voeg je hier je eigen continue variabele toe.\n\nby = \"right_track\"\n\nHier wordt de moderator variabele aangeduid. De code kan enkel gebruikt worden als de moderator een factor is.\n\n\nDe helling van de regressielijn voor pid als right_track = ‘Right Direction’” is -7.11. De helling van pid wanneer right_track = ‘Wrong Track’ is -10.82. Het effect van partij-identificatie op de score voor Biden is sterker (negatiever) als respondenten vinden dat het de verkeerde richting uitgaat met het land. Dit effect is ook statistisch significant (p &lt; 0.001). Dit zien we aan de p-waarde voor de interactie-term (zie onder). We kunnen de nulhypothese verwerpen dat het effect van pid niet verschilt naargelang right_track andere waarden aanneemt.\nJe ziet ook dat het effect van pidals right_track = ‘Wrong Track’ gelijk is aan de coëfficiënt van pid in het model (dit effect geldt als moderator 0 is). Het verschil tussen de 2 marginale effecten is gelijk aan de waarde van de interactiecoëfficiënt.\n\n#resultaten om coëfficiënten en significantie te tonen\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginaal effect (Right Direction) - Marginaal effect (Wrong Track) = coëfficiënt van de interactieterm\n-7.11 - (-10.82)\n\n[1] 3.71\n\n\nWe kunnen ook onderzoeken hoe het effect van de factor variabele right_track op de afhankelijke variabele anders is voor verschillende waarden van partij-identificatie. We kiezen er hier voor de effecten te berekenen voor elke waarde van pid gezien er maar 7 waarden zijn.\n\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\n\n        Term                      Contrast pid Estimate Std. Error      z\n right_track Right Direction - Wrong Track   1   -29.47      1.811 -16.28\n right_track Right Direction - Wrong Track   2   -25.76      1.473 -17.48\n right_track Right Direction - Wrong Track   3   -22.05      1.158 -19.04\n right_track Right Direction - Wrong Track   4   -18.33      0.888 -20.64\n right_track Right Direction - Wrong Track   5   -14.62      0.718 -20.37\n right_track Right Direction - Wrong Track   6   -10.90      0.721 -15.13\n right_track Right Direction - Wrong Track   7    -7.19      0.895  -8.03\n Pr(&gt;|z|)     S  2.5 % 97.5 %\n   &lt;0.001 195.4 -33.02 -25.92\n   &lt;0.001 224.9 -28.65 -22.87\n   &lt;0.001 266.0 -24.32 -19.78\n   &lt;0.001 311.9 -20.07 -16.59\n   &lt;0.001 303.9 -16.02 -13.21\n   &lt;0.001 169.4 -12.31  -9.49\n   &lt;0.001  49.9  -8.94  -5.43\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, pid, predicted_lo, predicted_hi, predicted, right_track, rural_urban, biden \nType:  response \n\n\n\nnewdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\nWe geven hier de waarden op van de moderator waarvoor marginale effecten van de andere predictor berekend moeten worden. De waarden dien je te veranderen voor eigen toepassingen. We gebruiken “newdata = datagrid()” omdat pid hier als continue variabele wordt gebruikt.\n\n\nDe output hierboven toont dat het effect van right_ direction'_trackongeveer -29.47 punten is voor overtuigde Democraten (pid=1), -25.76 punten voor minder overtuigde Democraten (pid = 2), en -7.19 punten voor overtuigde Republikeinen (pid=7). Het effect van de right_track variabele daalt met 3.71 eenheden telkens als pidmet 1 eenheid stijgt: dit is de waarde van de interactiecoëfficiënt.\n\n##resultaten om coëfficiënten en significantie te tonen\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginaal effect (PID = 2) - Marginaal effect (PID = 1) = coëfficiënt van de interactieterm\n-25.76 - (-29.47)\n\n[1] 3.71\n\n#Marginaal effect (PID = 7) - Marginaal effect (PID = 6) = coëfficiënt van de interactieterm\n-7.19 - (-10.90)\n\n[1] 3.71\n\n\nDe statistisch significante interactieterm leidt ertoe dat we de nulhypothese verwerpen dat het effect van right_track gelijk blijft als pidverandert.\n\n\n16.1.2 Plotten\nMarginale effecten worden vaak gevisualiseerd in een grafiek. De y-as in deze grafieken is het geschatte marginale effect en de x-as is de waarde die de moderator aanneemt. We bekijken eerst het voorbeeld waarbij de factor variabele de moderator is. De ggplot code hebben we gebruikt in eerdere weken. Belangrijk: we gebruiken geom_pointrange wanneer de moderator een factor is (hier: right_track).\n\n1slopes(biden_int,\n       variables = \"pid\",  \n       by = \"right_track\") |&gt; \n  ggplot(aes(x = right_track, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Marginaal effect van partij-identificatie op Biden score\", \n       y = \"Effect van partij-identificatie (pid)\", \n       x = \"Land gaat goede of verkeerde richting uit?\")  + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.2) +\n   geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +\n  scale_x_discrete(labels = c(\"Wrong Track\" = \"Verkeerde richting\", \"Right Direction\" = \"Goede richting\"))\n\n\n1\n\nIn dit voorbeeld nemen we de output van slopes() onmiddellijk op met ggplot() via de pipe operator. We zouden ook de resultaten van slopes() in een data object kunnen opslaan en die resultaten gebruiken voor een nieuwe ggplot() functie.\n\n\n\n\n\n\n\nEn hier is het voorbeeld waarbij de continue variabele de moderator is. We gebruiken nu geom_line() in combinatie met geom_ribbon:\n\n#Effect van right_track bij verschillende waarden pid\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7))) |&gt; \n  ggplot(aes(x=pid, y=estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Marginaal effect van perceptie over de richting van het land\" ,\n       y = \"Verkeerde richting (0) - Goede richting (1)\", \n       x = \"Partij-identificatie (hogere waarden: meer Republikeins)\") + \n  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') + \n1  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))\n\n\n1\n\nZonder deze regel zou ggplot() enkel ticks tonen bij 2, 4, and 6. Dit is vaak voldoende maar hier is het handig het volledige bereik van de continue variabele te kunnen plotten (1 tot 7)."
  },
  {
    "objectID": "interaction_02.html#continue-x-continue-interactie",
    "href": "interaction_02.html#continue-x-continue-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.2 Continue X Continue Interactie",
    "text": "16.2 Continue X Continue Interactie\nDe code voor de berekening van marginale effecten bij een interactie tussen 2 continue variabelen volgt dezelfde principes. In het voorbeeld hier voorspellen we de score voor Biden op basis van de volgende onafhankelijke variabelen: age (leeftijd), socialists (evaluatie van socialisten op een schaal van 0 (‘heel koud of ongunstig’) tot 100 (‘heel warm of gunstig’), en rural_urban als controlevariabele.\n\n#Model schatten en resultaten opslaan in object\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#Resultaten printen\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nHet interactie-effect is statistisch significant. We kunnen dit effect op twee manieren onderzoeken. We kunnen de marginale effecten berekenen van leeftijd op Biden score bij verschillende waarden voor socialisten. Of we berekenen de marginale effecten van socialisten op Biden score bij verschillende leeftijden. In beide gevallen moeten we waarden voor de continue moderator aanduiden in de syntax. We kiezen hier logische waarden in lijn met de schaal van de variabelen.\n\n#Marginaal effect van leeftijd bij socialists = 0, 10, 20...100\nslopes(biden_int2, \n       variables = \"age\", \n       newdata = datagrid(socialists = seq(from = 0, to = 100, by = 10))) \n\n#Marginaal effect van socialists bij leeftijd = 20,30,40...80\nslopes(biden_int2, \n       variables = \"socialists\", \n1       newdata = datagrid(age = seq(from = 20, to = 80, by = 10)))\n\n\n1\n\nLeeftijd reikt van 18 tot 80 in de dataset (respondeten ouder dan 80 krijgen gewoon de score 80).\n\n\n\n\n\n Term socialists Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 %   97.5 %\n  age          0  -0.0752     0.0345 -2.177   0.0295   5.1 -0.1429 -0.00751\n  age         10   0.0228     0.0292  0.781   0.4350   1.2 -0.0344  0.07990\n  age         20   0.1207     0.0247  4.895   &lt;0.001  20.0  0.0724  0.16907\n  age         30   0.2187     0.0215 10.156   &lt;0.001  78.1  0.1765  0.26090\n  age         40   0.3167     0.0204 15.528   &lt;0.001 178.2  0.2767  0.35664\n  age         50   0.4146     0.0216 19.239   &lt;0.001 271.6  0.3724  0.45688\n  age         60   0.5126     0.0247 20.724   &lt;0.001 314.5  0.4641  0.56108\n  age         70   0.6106     0.0293 20.841   &lt;0.001 318.0  0.5532  0.66799\n  age         80   0.7085     0.0346 20.457   &lt;0.001 306.6  0.6407  0.77643\n  age         90   0.8065     0.0405 19.919   &lt;0.001 290.9  0.7272  0.88587\n  age        100   0.9045     0.0467 19.373   &lt;0.001 275.3  0.8130  0.99599\n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, socialists, predicted_lo, predicted_hi, predicted, age, rural_urban, biden \nType:  response \n\n       Term age Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n socialists  20    0.393     0.0253 15.6   &lt;0.001 178.7 0.343  0.442\n socialists  30    0.491     0.0195 25.2   &lt;0.001 463.6 0.453  0.529\n socialists  40    0.589     0.0147 40.1   &lt;0.001   Inf 0.560  0.618\n socialists  50    0.687     0.0123 55.9   &lt;0.001   Inf 0.663  0.711\n socialists  60    0.785     0.0136 57.8   &lt;0.001   Inf 0.758  0.811\n socialists  70    0.883     0.0178 49.7   &lt;0.001   Inf 0.848  0.917\n socialists  80    0.981     0.0233 42.0   &lt;0.001   Inf 0.935  1.026\n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, age, predicted_lo, predicted_hi, predicted, socialists, rural_urban, biden \nType:  response \n\n\nWe kunnen in de output zien dat het effect van leeftijd negatief en statistisch signficant is als de socialistsvariabele de waarde 0 aanneemt (-0.0752 [95% CI: -0.143, -0.008]). Dit is gelijk aan de coëfficiënt voor age. Het effect van leeftijd wordt steeds positiever als socialists hogere waarden aanneemt. We wien ook dat het effect van socialistspositief is voor jonge mensen (bv., het effect voor respondenten van 20 jaar is 0.39 [0.34, 0.44]). Dit effect wordt positiver naarmate mensen ouder zijn.3\nOm te plotten gebruiken we de code voor wanneer de moderator een continue variabele is (zie boven, Section 16.1.2)."
  },
  {
    "objectID": "interaction_02.html#binaire-x-binaire-interactie",
    "href": "interaction_02.html#binaire-x-binaire-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.3 Binaire x Binaire Interactie",
    "text": "16.3 Binaire x Binaire Interactie\nWanneer de interactievariabele een vermenigvuldiging is van 2 binaire factor variabelen zijn wederom dezelfde principes van toepassing. Hier voorspellen we de score voor Biden met een interactie tussen right_track en vote2016 (met rural_urban als controlevariabele).\n\n#Model schatten en resultaten opslaan\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_int3)\n\n\nCall:\nlm(formula = biden ~ right_track * vote2016 + rural_urban, data = anes)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-78.83 -13.61  -0.28  14.27  84.72 \n\nCoefficients:\n                                              Estimate Std. Error t value\n(Intercept)                                    78.3730     0.5811 134.877\nright_trackRight Direction                    -25.2460     2.1072 -11.981\nvote2016Trump Vote                            -51.6157     0.7699 -67.039\nrural_urbanRural                               -2.7666     0.9071  -3.050\nrural_urbanSmall Town                          -1.6706     0.7850  -2.128\nrural_urbanCity                                 0.4524     0.7534   0.601\nright_trackRight Direction:vote2016Trump Vote  13.7690     2.2780   6.044\n                                              Pr(&gt;|t|)    \n(Intercept)                                    &lt; 2e-16 ***\nright_trackRight Direction                     &lt; 2e-16 ***\nvote2016Trump Vote                             &lt; 2e-16 ***\nrural_urbanRural                                0.0023 ** \nrural_urbanSmall Town                           0.0334 *  \nrural_urbanCity                                 0.5482    \nright_trackRight Direction:vote2016Trump Vote 1.61e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.89 on 5195 degrees of freedom\n  (3078 observations deleted due to missingness)\nMultiple R-squared:  0.6608,    Adjusted R-squared:  0.6604 \nF-statistic:  1687 on 6 and 5195 DF,  p-value: &lt; 2.2e-16\n\n\nDe marginale effecten worden als volgt berekend:\n\n#right_track als moderator\nslopes(biden_int3, \n       variables = \"vote2016\", \n       by = \"right_track\")\n\n\n     Term                              Contrast     right_track Estimate\n vote2016 mean(Trump Vote) - mean(Clinton Vote) Wrong Track        -51.6\n vote2016 mean(Trump Vote) - mean(Clinton Vote) Right Direction    -37.8\n Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n       0.77 -67.0   &lt;0.001   Inf -53.1  -50.1\n       2.15 -17.6   &lt;0.001 227.0 -42.1  -33.6\n\nColumns: term, contrast, right_track, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n#vote2016 als moderator\nslopes(biden_int3, \n       variables = \"right_track\", \n       by = \"vote2016\")\n\n\n        Term                                  Contrast     vote2016 Estimate\n right_track mean(Right Direction) - mean(Wrong Track) Clinton Vote    -25.2\n right_track mean(Right Direction) - mean(Wrong Track) Trump Vote      -11.5\n Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n      2.107 -12.0   &lt;0.001 107.5 -29.4 -21.12\n      0.866 -13.2   &lt;0.001 130.7 -13.2  -9.78\n\nColumns: term, contrast, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nDe eerste resultaten tonen dat 2016 Trump kiezers een slechtere indruk van Biden hebben dan 2016 Clinton kiezers, ongeacht wat ze vinden van het land. Maar het verschil is groter voor respondenten die vinden dat het land de verkeerde richting opgaat (verschil = -51.6) dan zij die vinden dat het de goede kant uitgaat (-37.80). Dit verschil is gelijk aan de interactiecoëfficiënt. Deze coëfficiënt was ook statistisch significant.\nOm dit te plotten gebruiken we de code voor wanneer de moderator een factor variabele is (zie boven Section 16.1.2)."
  },
  {
    "objectID": "interaction_02.html#logistische-regressie-voorbeeld",
    "href": "interaction_02.html#logistische-regressie-voorbeeld",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.4 Logistische regressie: voorbeeld",
    "text": "16.4 Logistische regressie: voorbeeld\nBij logistische regressie worden de marginale effecten met dezelfde code berekend. Hier geven deze effecten de gemiddelde verandering in voorspelde kans weer in percentpunten (zie Chapter 10).\nWe hebben reeds een righttrack_int model berekend, waarin we een interactie tussen age en vote2016 hebben toegevoegd. We bekijken de resultaten nogmaals:\nHere are the interaction model again:\n\n#Our model\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nDe interactie is tussen age (continue variabele) en vote2016 (binaire factor variabelen). We berekenen de marginale effecten als volgt:\n\n# age als moderator op = 20, 30...80\nslopes(righttrack_int, \n       variables = \"vote2016\", \n       newdata = datagrid(age = seq(from = 20, to = 80, by = 10))) \n\n\n     Term                  Contrast age Estimate Std. Error    z Pr(&gt;|z|)     S\n vote2016 Trump Vote - Clinton Vote  20    0.443     0.0300 14.8   &lt;0.001 161.9\n vote2016 Trump Vote - Clinton Vote  30    0.455     0.0244 18.7   &lt;0.001 255.6\n vote2016 Trump Vote - Clinton Vote  40    0.467     0.0199 23.4   &lt;0.001 400.7\n vote2016 Trump Vote - Clinton Vote  50    0.479     0.0173 27.7   &lt;0.001 558.2\n vote2016 Trump Vote - Clinton Vote  60    0.490     0.0172 28.6   &lt;0.001 593.7\n vote2016 Trump Vote - Clinton Vote  70    0.501     0.0195 25.7   &lt;0.001 481.7\n vote2016 Trump Vote - Clinton Vote  80    0.512     0.0235 21.8   &lt;0.001 347.1\n 2.5 % 97.5 %\n 0.384  0.502\n 0.407  0.503\n 0.428  0.506\n 0.445  0.513\n 0.456  0.524\n 0.463  0.539\n 0.466  0.558\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, age, predicted_lo, predicted_hi, predicted, vote2016, rural_urban, right_track \nType:  response \n\n# vote2016 als moderator\nslopes(righttrack_int, \n       variables = \"age\", \n       by = \"vote2016\")\n\n\n Term    Contrast     vote2016  Estimate Std. Error     z Pr(&gt;|z|)   S\n  age mean(dY/dX) Clinton Vote -0.000312   0.000209 -1.49    0.136 2.9\n  age mean(dY/dX) Trump Vote    0.000854   0.000650  1.31    0.189 2.4\n     2.5 %   97.5 %\n -0.000723 9.84e-05\n -0.000421 2.13e-03\n\nColumns: term, contrast, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nWe verwachten dat mensen die op Trump gestemd hebben in 2016 een grotere kans hebben om te zeggen dat het land de goede richting uitgaat dan mensen die Clinton stemden. Dit effect geldt al voor jonge mensen maar wordt sterker met leeftijd. Voor respondenten die 30 jaar oud zijn is de kans om te zeggen dat het land de goede richting uitgaat 45.5 percentpunten hoger voor Trump kiezers. Voor respondenten van 80 jaar is dit 51.2 percentpunten.4\nZie eerder secties voor instructies over plotten.."
  },
  {
    "objectID": "interaction_02.html#footnotes",
    "href": "interaction_02.html#footnotes",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "",
    "text": "Onze pid variabele heeft een bereik van 1 tot 7 en kent dus geen nulwaarde. Het effect wordt geëxtrapoleerd alsof er een nulwaarde zou zijn. Dit vormt niet echt een probleem.↩︎\nWe tonen geen voorbeeld voor een interactie met een categorische variabele met 3 of meer categorieën maar dezelfde principes als binaire variabelen worden gevolgd hiervoor.↩︎\nHier hebben we intervallen van 10 gebruikt voor de moderator (age = 20, 30, 40…). Als we telkens intervallen van 1 eenheid hadden gekozen, dan hadden we gezien dat het verschil in marginale effecten gelijk is aan de interactiecoëfficiënt. Het effect van socialists is 0.393 wanneer age = 20 en 0.403 wanneer age =21. 0.403 - 0.393 = 0.01 is gelijk aan de interactieterm (met afrondingen bij berekening).↩︎\nHier berekenen we effecten voor respondenten die 20 jaar oud zijn. Deze respondenten konden echter nog niet stemmen in 2016. Het effect dat we hier vinden voor deze respondenten is niet betekenisvol. We moeten hiervoor blijven oppassen als we interpretaties maken.↩︎"
  },
  {
    "objectID": "interaction_03.html#binaire-x-continue-interactie",
    "href": "interaction_03.html#binaire-x-continue-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.1 Binaire X Continue Interactie",
    "text": "17.1 Binaire X Continue Interactie\nWe hebben reeds een model geschat waarbij scores voor kandidaat Biden voorspeld worden met een interactie van partij-identificatie (pid) en perceptie over de richting dat het land uitgaat (right_track).\nOp basis van dit model (biden_int), berekenen we nu met predictions() de voorspelde waarden voor elke combinatie van waarden voor de 2 onafhankelijke variabelen in de interactie (bv. pid = 1 & right_track = “Right Direction”, pid = 1 & right_track = “Wrong Track”, pid = 2 & right_track = “Right Direction”…). Als er te veel waarden zouden zijn om realistisch op deze manier te werk te gaan dan kiezen we voorspellingen op basis van een subset van waarden (bv. minimum, gemiddelde, maximum).\nAndere onafhankelijke variabelen in het model worden op hun gemiddelde (continue variabelen) of modus (factor variabelen) gehouden.\n\n#Voorspelde waarden berekenen en opslaan in data object\nbiden_int_preds &lt;- predictions(biden_int, \n            newdata = datagrid(pid = c(1,2,3,4,5,6,7), \n                               right_track = c(\"Right Direction\", \"Wrong Track\")))\n\n\nbiden_int_preds &lt;- predictions(biden_int,\n\nWe passen de functie ‘predictions’ toe op het model tussen haakjes en slaan de resultaten op in een data object (“biden_int_preds”) dat we later weer kunnen gebruiken.\n\nnewdata = datagrid(pid = c(1,2,...7), right_track = c(\"Right Direction\", \"Wrong Track\")))\n\nWe duiden de gewenste waarden van de predictoren aan waarvoor voorspellingen berekend zullen worden met de “newdata = datagrid()” optie. We duiden alle waarden voor pid aan (1 tot 7) en de 2 mogelijke waarden voor right_track (Right Direction or Wrong Track).1 In eigen toepassingen wordt dit aangepast volgens de eigen variabelen.\n\n\nDe dataset die we verkrijgen heeft 14 rijen met voorspelde waarden: 7 (waarden voor pid) * 2 (waarden voor right_track).\n\n# print resultaten\nbiden_int_preds\n\n\n pid     right_track Estimate Std. Error     z Pr(&gt;|z|)      S 2.5 % 97.5 %\n   1 Right Direction     55.4      1.808  30.6   &lt;0.001  681.6  51.8   58.9\n   1 Wrong Track         84.8      0.581 146.0   &lt;0.001    Inf  83.7   86.0\n   2 Right Direction     48.3      1.493  32.3   &lt;0.001  759.2  45.3   51.2\n   2 Wrong Track         74.0      0.515 143.7   &lt;0.001    Inf  73.0   75.0\n   3 Right Direction     41.1      1.193  34.5   &lt;0.001  863.3  38.8   43.5\n   3 Wrong Track         63.2      0.486 130.1   &lt;0.001    Inf  62.2   64.1\n   4 Right Direction     34.0      0.925  36.8   &lt;0.001  982.0  32.2   35.8\n   4 Wrong Track         52.4      0.500 104.8   &lt;0.001    Inf  51.4   53.3\n   5 Right Direction     26.9      0.724  37.2   &lt;0.001 1002.1  25.5   28.3\n   5 Wrong Track         41.5      0.554  75.0   &lt;0.001    Inf  40.5   42.6\n   6 Right Direction     19.8      0.656  30.2   &lt;0.001  662.9  18.5   21.1\n   6 Wrong Track         30.7      0.638  48.2   &lt;0.001    Inf  29.5   32.0\n   7 Right Direction     12.7      0.757  16.8   &lt;0.001  207.4  11.2   14.2\n   7 Wrong Track         19.9      0.741  26.8   &lt;0.001  524.2  18.4   21.3\n rural_urban\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, pid, right_track, biden \nType:  response \n\n\nDe voorspellingen kunnen we visueel presenteren in een plot. Het proces dat we volgen is vrijwel hetzelfde als wat we doen voor een model zonder interactie (zie Section 8.6). Er is echter een belangrijke toevoeging: het linetype gedeelte van de syntax, dat enkel gebruikt kan worden indien er een factor variabele is.\nVoor we het plot produceren veranderen we de waarden voor right_track naar het Nederlands zodat ze correct worden weergegeven op het plot. Net zoals bij marginale effecten zouden we de code voor predictions ook kunnen combineren met de ggplot code via de pipe operator.\n\nbiden_int_preds |&gt;\n  mutate(right_track = recode(right_track, \n                       \"Wrong Track\" = \"Verkeerde richting\",\n                       \"Right Direction\" = \"Goede richting\")) |&gt;\nggplot(aes(x=pid, y=estimate, linetype = right_track)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Voorspelde score voor Biden\", \n       x = \"Partij-identificatie\", \n       y = \"Voorspelde waarden\", \n       linetype = \"Richting land\" ) + \n  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))\n\n\n\n\n\nggplot(..., linetype = right_track)) + geom_line() + geom_ribbon(...) +\n\nDit gedeelte van de syntax is grotendeels ook al gebruikt in eerdere weken. Een belangrijke toevoeging is linetype = right_track. Zo vragen we ggplot() om de voorspelde waarden voor elke categorie van “right_track” weer te geven als verschillende lijnen. We zouden de voorspellingen ook kunnen onderscheiden op een andere manier, bv. met kleur (color = right_track). De linetype (en color) functies werken enkel met factor variabelen. De variabele right_trackis hier reeds een factor dus we hebben geen verdere data managment stappen moeten ondernemen. Zie Section A.5 voor meer informatie."
  },
  {
    "objectID": "interaction_03.html#continue-x-continue-interactie",
    "href": "interaction_03.html#continue-x-continue-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.2 Continue X Continue Interactie",
    "text": "17.2 Continue X Continue Interactie\nOm voorspelde waarden voor interacties tussen continue variabelen te berekenen en te plotten, is het proces iets ingewikkelder, omdat er veel mogelijke combinaties van waarden zijn om voorspellingen voor te maken.\nIn het vorige hoofdstuk hebben we het biden_int2 model gebruikt om Biden scores te voorspellen met een interactie tussen age en socialists. We schatten dat model opnieuw hieronder.\n\n#Model schatten en resultaten opslaan\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#resultaten bekijekn\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nBeide variabelen kunnen veel mogelijke waarden aannemen. We zouden voorspellingen kunnen maken voor waarden van 0 tot 100 voor socialists met intervallen van 10, en van 20 tot 80 voor agemet intervallen van 10. Dit zou ons echter veel waarden opleveren die we moeilijk zouden kunnen plotten (en begrijpen).\nWat vaak gebeurt in de praktijk is dat we 1 van de 2 predictoren kiezen en voorspellingen maken voor 3 waarden: het gemiddelde, 1 standaarddeviatie (SD) onder het gemiddelde en 1 standaarddeviatie (SD) boven het gemiddelde. De continue variabele zal eigenlijk getransformeerd worden in een factor met 3 waarden. Zo kunnen we een plot maken met 3 lijnen. We transformeren doorgaans de moderator (Z).\nVoor het ‘biden_int2’ model, nemen we nu (bij wijze van voorbeeld) socialists als de moderator. Eerst berekenen we de drie relevante waarden (gemiddelde, 1 SD daaronder, 1 SD daarboven. Deze statistieken moeten we berekenen op basis van de observaties gebruikt in het model. Dit zijn niet altijd het aantal observaties in de dataset door missende waarden op andere variabelen. Als tussenstap gebruiken we hier de predictions() functie van het marginaleffects package gezien deze functie een nieuwe dataset creëert met alle complete observaties. 2\n\npredictions(biden_int2) |&gt;   #nieuw dataobject met complete observaties\n  summarise(\n    mean_below = mean(socialists) - sd(socialists), #1 SD onder gemiddelde\n    mean = mean(socialists),                        #gemiddelde\n    mean_above = mean(socialists) + sd(socialists)) #1 SD boven gemiddelde\n\n  mean_below     mean mean_above\n1   9.716161 38.33639   66.95661\n\n\nNu kunnen we de voorspelde waarden berekenen op basis van de waarden voor socialists die we net berekend hebben. Voor leeftijd vragen we ook geen voorspellingen over de hele schaal, maar voor de leeftijden van 20 tot 80 met tussenstappen van 10 jaar.\n\n#voorspelde waarden\nbiden_int2_preds &lt;- predictions(biden_int2, \n            newdata = datagrid(\n              socialists = c(9.72, 38.34, 66.96), \n              age = c(20,30,40,50,60,70,80))) \n\n#print resultaten\nbiden_int2_preds\n\n\n socialists age Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n       9.72  20     32.3      1.208  26.8   &lt;0.001 522.3  30.0   34.7\n       9.72  30     32.5      0.983  33.1   &lt;0.001 796.8  30.6   34.5\n       9.72  40     32.7      0.802  40.8   &lt;0.001   Inf  31.2   34.3\n       9.72  50     32.9      0.703  46.9   &lt;0.001   Inf  31.6   34.3\n       9.72  60     33.1      0.718  46.1   &lt;0.001   Inf  31.7   34.6\n       9.72  70     33.3      0.843  39.6   &lt;0.001   Inf  31.7   35.0\n       9.72  80     33.5      1.037  32.3   &lt;0.001 759.7  31.5   35.6\n      38.34  20     43.6      0.891  48.9   &lt;0.001   Inf  41.8   45.3\n      38.34  30     46.6      0.755  61.7   &lt;0.001   Inf  45.1   48.1\n      38.34  40     49.6      0.657  75.5   &lt;0.001   Inf  48.3   50.9\n      38.34  50     52.6      0.612  86.0   &lt;0.001   Inf  51.4   53.8\n      38.34  60     55.6      0.633  87.8   &lt;0.001   Inf  54.4   56.8\n      38.34  70     58.6      0.715  82.0   &lt;0.001   Inf  57.2   60.0\n      38.34  80     61.6      0.839  73.5   &lt;0.001   Inf  60.0   63.3\n      66.96  20     54.8      1.083  50.6   &lt;0.001   Inf  52.7   57.0\n      66.96  30     60.6      0.892  68.0   &lt;0.001   Inf  58.9   62.4\n      66.96  40     66.4      0.756  87.9   &lt;0.001   Inf  65.0   67.9\n      66.96  50     72.3      0.709 102.0   &lt;0.001   Inf  70.9   73.6\n      66.96  60     78.1      0.766 101.9   &lt;0.001   Inf  76.6   79.6\n      66.96  70     83.9      0.909  92.2   &lt;0.001   Inf  82.1   85.7\n      66.96  80     89.7      1.105  81.2   &lt;0.001   Inf  87.5   91.8\n rural_urban\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, socialists, age, biden \nType:  response \n\n\nDeze dataset heeft 21 observaties: 7 waarden voor age * 3 waarden voor socialists.\nWe plotten de voorspelde waarden zoals hiervoor met het linetype statement. We moeten de socialist variabele in de predictions dataset wel veranderen in een factor om het statement te kunnen gebruiken. We gebruiken hier de ‘factor’ functie gezien de data numeriek is en niet gelabeld (bij labels gebruiken we doorgaans factorize).\n\n#Class variabele\nclass(biden_int2_preds$socialists)\n\n[1] \"numeric\"\n\n#factor maken\nbiden_int2_preds &lt;- biden_int2_preds |&gt; \n  mutate(socialists = factor(socialists, \n                             levels = c(9.72, 38.34, 66.96), \n                             labels = c(\"1SD &lt; Gemiddelde\", \"Gemiddelde\", \"1SD &gt; Gemiddelde\")))\n\nWe kunnen dan de plot maken op een vergelijkbare manier als eerder:\n\nggplot(biden_int2_preds, aes(x=age, y=estimate, linetype=socialists)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = .2) + \n  labs(title = \"Voorspelde score voor Biden\", \n       y = \"Voorspelde score\", \n       x = \"Leeftijd\", \n       linetype= \"Voorkeur socialisten (hoger = meer voorkeur)\")"
  },
  {
    "objectID": "interaction_03.html#binaire-x-binaire-interactie",
    "href": "interaction_03.html#binaire-x-binaire-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.3 Binaire x Binaire Interactie",
    "text": "17.3 Binaire x Binaire Interactie\nVoor een interactie met twee binaire variabelen gelden gelijkaardige principes.\nEen dergelijke interactie gebruiken we in het biden_int3-model, namelijk een interactie tussen (right_track) en vote2016 (Clinton kiezer = 0, Trump kiezer = 1). Als controlevariabele voegen we rural_urban toe.\n\n#Model schatten en resultaten oplsaan\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#resultaten printen\ntidy(biden_int3)\n\n# A tibble: 7 × 5\n  term                                     estimate std.error statistic  p.value\n  &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                                78.4       0.581   135.    0       \n2 right_trackRight Direction                -25.2       2.11    -12.0   1.20e-32\n3 vote2016Trump Vote                        -51.6       0.770   -67.0   0       \n4 rural_urbanRural                           -2.77      0.907    -3.05  2.30e- 3\n5 rural_urbanSmall Town                      -1.67      0.785    -2.13  3.34e- 2\n6 rural_urbanCity                             0.452     0.753     0.601 5.48e- 1\n7 right_trackRight Direction:vote2016Trum…   13.8       2.28      6.04  1.61e- 9\n\n\nWe gebruiken predictions() om voor alle combinaties van deze twee variabelen voorspelde waarden te berekenen. Dit resulteert in 4 voorspelde waarden: Clinton voter & “right direction”, Clinton voter & “wrong track”, Trump voter & “right direction”, en Trump voter & “wrong track”.\n\npredictions(\n  biden_int3, \n  by = c(\"right_track\", \"vote2016\"), \n  newdata = \"mean\")\n\n\n     right_track     vote2016 Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 %\n Right Direction Trump Vote       15.3      0.737  20.7   &lt;0.001 314.8  13.8\n Right Direction Clinton Vote     53.1      2.119  25.1   &lt;0.001 458.6  49.0\n Wrong Track     Trump Vote       26.8      0.775  34.5   &lt;0.001 864.8  25.2\n Wrong Track     Clinton Vote     78.4      0.581 134.9   &lt;0.001   Inf  77.2\n 97.5 %\n   16.7\n   57.3\n   28.3\n   79.5\n\nColumns: rowid, right_track, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, rowid_dedup \nType:  response \n\n\n\nby = c(\"right_track\", \"vote2016\")\n\nOm voorspelde waarden te verkrijgen voor alle categorieën van een binaire/categorische variabele kunnen we gebruik maken van de by = “variable name” optie. Gezien beide predictoren factor variabelen zijn duiden we ze beiden aan.\n\nnewdata = \"mean\")\n\nDeze optie hebben we hier nodig (gezien we het ‘by’ statement gebruiken) om de overige onafhankelijke variabelen op hun gemiddelde of modus te houden.\n\n\nDe resultaten kunnen we in een plot visualiseren. De syntax is vrijwel hetzelfde als die voor plots van voorspelde waarden voor 1 factor variable (Section 8.6). We moeten gebruikmaken van geom_pointrange(). Nieuw is dat we voorspellingen onderscheiden van elkaar op basis van de waarden van de moderator via de shape = optie. Deze vertelt aan ggplot verschillende vormen te gebruiken voor de voorspelde waarden.[^interaction_03-3]\nVoor we plotten vertalen we de labels voor vote2016 naar het Nederlands.\n[^interaction_03-3] Dit zou eventueel ook kunnen via kleuren (bv. color = vote2016). Let er wel op dat niet iedereen kleuren kan zien (R heeft wel color-bind palettes beschikbaar). Bovendien kan een plot met kleuren onduidelijk worden afgedrukt in zwart/wit.\n\n1predictions(\n  biden_int3, \n  by = c(\"right_track\", \"vote2016\"), \n  newdata = \"mean\") |&gt; \n  ggplot(aes(x = right_track, y=estimate, shape = vote2016)) + \n2  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +\n  geom_text(aes(label = round(estimate, 2), hjust=-0.2)) + \n  labs(title = \"Voorspelde score voor Biden\", \n       x = \"Richting van het land\", \n       y = \"Voorspelde score Biden\", \n       shape = \"Stemkeuze 2016\") + \n3  scale_y_continuous(limits = c(0 , 100)) +\n    scale_x_discrete(labels = c(\"Wrong Track\" = \"Verkeerde richting\", \"Right Direction\" = \"Goede richting\"))\n\n\n1\n\nWe doen hier alles in 1 syntax-stap. We zouden dit in meerdere stappen kunnen opspitsen: eerst voorspellingen maken en oplsaan in data-object, dan data doorvoeren naar ggplot().\n\n2\n\nIndien voorspelde waarden gelijkaardig zijn dan kunnen de markers overlappen. Om dit te verhelpen kun je de markers wat verplaatsen door , position = position_dodge(width = 0.2) toe te voegen aan het geom_pointrange() gedeelte, na het aes() gedeelte. De waarde waarmmee markers verschoven worden (hier: 0.2) kun je veranderen.\n\n3\n\nWe zetten de y-as op een schaal van 0 tot 100. Dit is niet strikt nodig, maar kan de figuur duidelijker maken."
  },
  {
    "objectID": "interaction_03.html#logistische-regressie-voorbeeld",
    "href": "interaction_03.html#logistische-regressie-voorbeeld",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.4 Logistische regressie: voorbeeld",
    "text": "17.4 Logistische regressie: voorbeeld\nBovenstaande syntax is ook van toepassing voor logistische regressie. Hier voorspellen we probabiliteiten in plaats van scores. In dit voorbeeld gebruiken we een rightrack_int model waarin we rightrack voorspellen en een interactie hebben tussen vote2016 en age.\n\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nWe berekenen de voorspelde kans dat een respondent vindt dat het land de goede richting uitgaat met combinaties van waarden voor age en vote2016. We maken voorspellingen, vertalen de labels en maken het plot:\n\nright_track_int_preds &lt;-predictions(righttrack_int, \n            newdata = datagrid(age = seq(from=20,to=80, by=10), \n                               vote2016 = c(\"Trump Vote\", \"Clinton Vote\"))) |&gt;\n  mutate(vote2016 = recode(vote2016, \n                       \"Clinton Vote\" = \"Clinton Stem\",\n                       \"Trump Vote\" = \"Trump Stem\"))\n  ggplot(right_track_int_preds, aes(x=age, y=estimate, linetype=vote2016)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Voorspelde kans dat respondent vindt dat het land de goede richting uitgaat\", \n       y = \"Voorspelde kans\", \n       x = \"Leeftijd\", \n       linetype = \"2016 Stemkeuze\") + \n  scale_y_continuous(limits=c(0,1))"
  },
  {
    "objectID": "interaction_03.html#footnotes",
    "href": "interaction_03.html#footnotes",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "",
    "text": "De waarden voor pid zouden we ook als volgt kunnen aanduiden: pid = c(1:7).↩︎\nWe zouden ook de originele dataset (anes) kunnen nemen, missing waarden voor de variabelen gebruikt in het model wegfilteren en de juiste statistieken berekenen: anes \\|\\&gt; filter(complete.cases(biden, socialists, age, rural_urban)) \\|\\&gt; summarize(...).predictions() combineert deze stappen voor ons.↩︎"
  },
  {
    "objectID": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "href": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "A.1 Your R assignment file (.rmd) won’t knit to an html file",
    "text": "A.1 Your R assignment file (.rmd) won’t knit to an html file\n\n\n\n\n\n\nThe Problem\n\n\n\nYou are trying to knit your assignment and you receive an error such as “No such file or directory”; more generally, you cannot knit to an html\n\n\nThe scenario: you have been successfully working through an R assignment in the .rmd file that was provided to you. However, you receive an error message such as “No such file or directory” when you try and “knit” the file to an html (i.e., ask R to convert the .rmd file into an html file). More generally, everything works while working in R Studio until you try to knit the final file.\nThere are a variety of potential causes for this problem. They perhaps share a common root though: when you ask R to “knit” a file, R will essentially from a blank slate and begin working downwards through your .rmd file. By blank slate, we mean that R will act as if you have not loaded any libraries or imported data or stored regression results (etc.) in the Environment and start running all the syntax that you have created to do these things. Here we’ll discuss three ways this could short circuit the ‘knitting’ process. First, though, we’ll note a general piece of advice:\n\n\n\n\n\n\nAdvice\n\n\n\nKnit as you go!\n\n\nIf you have had difficulties knitting a document before, we suggest “knitting as you go”. Specifically, knit your .rmd file (convert it into an html) after every major section (e.g., after loading packages and your data, after question 1, after question 2…). Doing so may enable you to more quickly find, and troubleshoot, the specific problem affecting your file. For instance, if you can successfully knit your document after the first three questions of an assignment but have a problem after the fourth, then this implies that it is something specifically about the fourth question that is derailing the process. This can help you avoid spending unnecessary time and effort working through the earlier portions of the file.\n\nA.1.1 Incorrectly Specifying the “yaml”\n\n\n\n\n\n\nThe Cause\n\n\n\nThe “yaml” has been incorrectly specified\n\n\nAll .rmd documents begin with something called the “yaml”. This is the portion of the document that lays out the basic attributes of the file you are trying to create: its title, author information, and other basic formatting details. Here is an example:\n\nThe “yaml” is the first thing that R deals with when knitting your file, so if there is a mistake here then the file won’t be produced. We have seen three types of error in student submissions on this front:\n\nRemoving quotation marks: the title, author, and date information should all be enclosed within quotation marks. Removing them will lead to an error.\nAdding information in the “sys.date()” area: “r sys.date()” is a specific snippet of syntax that tells R to use the date on your computer as the date in the html that is being produced. This general syntax is nice because it means we do not need to constantly update this line if we are working with a file over time. However, if you add information here (e.g., “r sys.date(27-09-2023”), then R will grind to a halt because this is not how the syntax works. In fact, we had to take special care formatting this bullet point because a mistake with writing out the “sys.date” information initially prevented this file from knitting to an html!\nAdding additional options: For instance, we have seen students add something like “pdf: default” to the format area. R can knit to pdf files, but this requires some additional packages be installed to handle the conversion from an .rmd file to a .pdf file. Creating .pdf files can also be a little finicky as well. Adding this information can thus produce errors.\n\n\n\n\n\n\n\nThe Solution\n\n\n\nUh…don’t do those things!\n\n\nMore specifically, you should only make one change to the “yaml” area - you should update the author information to include your name and your student number while making sure that this information is provided in quotation marks. Everything else should be left as is.\nAs an example:\n\n\n\nA.1.2 Not Properly Importing Your Data\n\n\n\n\n\n\nThe Cause\n\n\n\nYou are manually loading data via the Files window rather than using syntax\n\n\nWe load data into the R Environment, thereby enabling us to work with it, via syntax. Specifically, we use the import() function from the rio package:\n\nlibrary(rio)\ness &lt;- import(\"ess_nl.sav\")\n\nWe have seen some students take a different, and worse, route to this same end. Specifically, there is a “Files” window in R Studio that is typically presented in the bottom/right of the R Studio window, as so:\n\nHere we can see that there are some data files within the working directory containing this .rmd file (e.g., “ess_nl.sav” or “demdata.rds”). We may be able to load this data by double clicking on the file and using the “Import Dataset” option that pops up. However, this is a bad idea. Remember that R begins working downwards within your .rmd file as it tries to knit it to an html. If you take this route to loading the data, then R will move through the yaml and fail to find the necessary syntax to load the rio package or to load your data via import(). It won’t know that you have loaded the file manually because it is, per above, working in a type of blank slate environment. This is will almost certainly lead to lots of errors as R works through your file because you will be asking it to do things with data that it doesn’t know exists since you are not including the necessary information within the .rmd file itself.\n\n\n\n\n\n\nThe Solution\n\n\n\nProperly load your data.\n\n\nThe solution is simple: use the appropriate syntax to load your data.\n\n\nA.1.3 Not loading libraries within the .rmd file\n\n\n\n\n\n\nThe Problem\n\n\n\nPerforming operations outside of the .rmd file that are required for your analyses\n\n\nThis is a more general version of the previous issue. For instance, perhaps you have loaded the rio library and correctly imported your data via syntax … just not in the .rmd file (e.g., you may have entered these commands directly in the Console portion of R Studio or perhaps have run them from within an R Script that is separate from your .rmd file). The same problem would emerge: you would have access to the libraries and functions in question to work with while completing your assignment, but R wouldn’t when it started to knit your document because it’s not in the set of commands you’re directly sending it.\nOne tip off here may be in the error message that R provides you. Consider the following error message taken from a student’s error-prone .rmd file last year:\n\nIn this instance, the student is running into an issue with knitting. R provides us with information about the specific input that is causing a problem (“Error in import(….)”) and the specific problem (“could not find function ‘import’”). One way this error could emerge is if rio were loaded outside of the .rmd file (that is: the .rmd file does not contain library(rio) to load the library for use) such that R will have no idea where to find this command. (Another potential explanation for this error is below.)\n\n\n\n\n\n\nThe Solution\n\n\n\nKeep all your steps in the same .rmd file\n\n\nThis is a type of problem that can readily emerge, but also one that can be readily fixed: make sure you have included all of the relevant syntax in the .rmd file.\n\n\nA.1.4 Library/Package Conflicts\n\n\n\n\n\n\nThe Cause\n\n\n\nTwo or more R libraries conflict with one another and have been loaded in such a way that this grinds R to a halt; packages loaded in an order that creates issues\n\n\nR libraries may sometimes feature identically named commands (e.g., both the tidyverse/dplyr and car libraries contain a function named recode()). In such instances, R will use the function from the library loaded most recently/last. This can create problems down the line; see SECTION for more on this particular conflict.\nAnother way this could emerge is if the syntax for loading the library and syntax for using it are mis-ordered. This, for instance, would lead to an error:\n\ndemdata &lt;- import(\"demdata.rds\")\n\nError in import(\"demdata.rds\"): could not find function \"import\"\n\nlibrary(rio)\n\nWarning: package 'rio' was built under R version 4.3.1\n\n\nR would try and use the import function here, but an error would emerge because the library from which this command originates has not been loaded at that point and, hence, R will not know how to act.\n\n\n\n\n\n\nThe Solution\n\n\n\nLoad relevant libraries at the start of the R document and pay attention to potential conflicts\n\n\nWe recommend you begin your assignment by reading it in full to understand all of the steps that you will need to accomplish and then loading all of the relevant libraries at the start of the document so that R will know what it has accessible to use in later portions. This should be done in a way that does not introduce conflicts. Here we note two particular sources of conflict, both with the tidyverse library:\n\nexpss\ncar\n\nWe recommend loading these libraries before loading the tidyverse library to avoid conflicts (or, if necessary, taking one of the other strategies for avoiding conflict discussed in SECTION)."
  },
  {
    "objectID": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "href": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "A.2 Not seeing the right number of categories for factor variables in regression models",
    "text": "A.2 Not seeing the right number of categories for factor variables in regression models\n\n\n\n\n\n\nThe Problem\n\n\n\nYou tried to convert a categorical variable into a factor variable but only one coefficient is present in the regression output\n\n\nWe include categorical variables in a regression model by first converting the variable into a factor variable. R will then include the appropriate number of indicators in the model for us. For instance, if we have a categorical variable with four levels, then R will include three indicators in the model if we successfully convert the variable into a factor variable.\nSuppose we have a numeric variable in our dataset corresponding to the gross domestic product in a country where countries are sorted into one of three groups: “low” GDP (value of 1), medium GDP (value of 2), and “high” GDP (value of 3). We would include this variable in our model by converting it into a factor variable. We should then see two indicators for this variable in the model (with the left out group acting as the reference category). For instance:\n\n#Distribution of Variable\ntable(dta$gdp_3cat)\n\n\n 1  2  3 \n40 78 40 \n\n#Convert to factor variable\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_factor = factorize(gdp_3cat))\n\n#Run and summarize the regression\nmodel1 &lt;- lm(v2x_polyarchy ~ gdp_3cat_factor, data=dta)\nsummary(model1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_factor, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67320 -0.15257  0.04909  0.17964  0.36359 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.24184    0.05264   4.594 8.91e-06 ***\ngdp_3cat_factor  0.14879    0.02480   6.000 1.33e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2218 on 156 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.1875,    Adjusted R-squared:  0.1823 \nF-statistic:    36 on 1 and 156 DF,  p-value: 1.329e-08\n\n\nWe only have one indicator in our model for the factor variable. Why?1\n\n\n\n\n\n\nThe Cause\n\n\n\nYou used factorize() with non-labelled data.\n\n\nWe can convert a variable into a factor variable in either of two ways in R:\n\nfactor(): This is a built in function that will work with any type of data.\nfactorize(): This function comes from the rio package.\n\nfactorize() is a handy tool but it only works with variables that have value labels stored within the dataset. In these instances, factorize() will automatically attach each numeric value with its corresponding value. While labelled data is common (but not universal) when the dataset in question is either a .dta or .sav file format, it is not common with .csv for .xlsx file formats. Note that by labelled data we mean situations where the labels are included within the datset itself rather than only being found in a separate codebook.\nWe can use the following function to obtain information as to whether a variable has value labels associated with it in the dataset that we are using: attr(dataset$varname, \"labels\"). Here is an example with two variables: one labelled and one unlabelled:\n\n#Unlabelled\nattr(dta$gdp_3cat, \"labels\")\n\nNULL\n\n#Labelled\nattr(dta$Fragile2006, \"labels\")\n\n     Fragile Intermediate       Stable \n           1            2            3 \n\n\nIn the former case, we observe the value of “NULL” meaning that no value labels are stored in the metadata for this variable. factorize() works by applying stored labels to numeric values, but there is nothing here to apply.\nOn the other hand, we see values reported in the latter case. The variable in question is a numeric variable with three values: 1 (associated with the label “Fragile”), 2 (associated with the label “Intermediate”), and 3 (associated with the label “Stable”). We can use factorize() in this instance with the resulting model reporting the correct number of terms in the model.2\n\ndta &lt;- dta |&gt; \n  mutate(fragile = factorize(Fragile2006))\n\nmodel2 &lt;- lm(v2x_polyarchy ~ fragile, data=dta)\nsummary(model2)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ fragile, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.64836 -0.14467  0.03116  0.15945  0.43393 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          0.36907    0.02915  12.662  &lt; 2e-16 ***\nfragileIntermediate  0.14954    0.03975   3.762 0.000236 ***\nfragileStable        0.36028    0.04345   8.291  4.2e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2162 on 161 degrees of freedom\n  (15 observations deleted due to missingness)\nMultiple R-squared:  0.2996,    Adjusted R-squared:  0.2909 \nF-statistic: 34.44 on 2 and 161 DF,  p-value: 3.539e-13\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUsing factor() instead of factorize()\n\n\nThe built in factor() command will be more useful in this type of situation. Here we specify the levels of the factor variable (with the reference group being the first category provided in levels=c()) and its associated labels.\n\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_correct = factor(gdp_3cat, \n                                   levels=c(1,2,3), \n                                   labels=c(\"Low\", \"Medium\", \"High\")))\n\nmodel3 &lt;- lm(v2x_polyarchy ~ gdp_3cat_correct, data=dta)\nsummary(model3)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_correct, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70363 -0.13534  0.06887  0.15537  0.39479 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.42105    0.03484  12.086  &lt; 2e-16 ***\ngdp_3cat_correctMedium  0.08716    0.04285   2.034   0.0437 *  \ngdp_3cat_correctHigh    0.29757    0.04927   6.040  1.1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2203 on 155 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.2034,    Adjusted R-squared:  0.1931 \nF-statistic: 19.79 on 2 and 155 DF,  p-value: 2.224e-08"
  },
  {
    "objectID": "common_errors.html#sec-glm-factor",
    "href": "common_errors.html#sec-glm-factor",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”",
    "text": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to perform a logistic model where our DV is a factor variable but are running into a message saying “Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in ‘y’” and “In Ops.factor(y, mu) : ‘-’ not meaningful for factors”\n\n\nSuppose that we wish to predict a binary outcome for whether a person reports being close to a political party or not based on their age. We would use create a factor variable of the binary outcome variable and then use the glm() function, rather than lm() to do so. However, if we ran the following syntax, we would run into an error:\n\n#Factorize the variable\ness &lt;- ess |&gt; \n  mutate(close_party = factor(clsprty, \n                              levels = c(2, 1), \n                              labels = c(\"Not Close\", \"Close to Party\")))\n\n#Run the model\nglm(close_party ~ agea, data = ess)\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nWarning in Ops.factor(eta, offset): '-' not meaningful for factors\n\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nError in glm.fit(x = structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in 'y'\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nWe haven’t specified a “family” for the model.\n\n\nThe glm() function can be used to fit a variety of different models depending on the nature of the dependent variable. We specify the type of model (and hence the nature of the DV) via a family= option. If we do not specify a family option, then glm() will default to attempting to perform a linear model, which creates an error when the DV is a factor variable.3\n\n\n\n\n\n\nSolution\n\n\n\nSpecify the correct family, here: “family =”binomial”\n\n\n\nglm(close_party ~ agea, data = ess, family = 'binomial')\n\n\nCall:  glm(formula = close_party ~ agea, family = \"binomial\", data = ess)\n\nCoefficients:\n(Intercept)         agea  \n   -0.64393      0.01825  \n\nDegrees of Freedom: 1646 Total (i.e. Null);  1645 Residual\n  (26 observations deleted due to missingness)\nNull Deviance:      2260 \nResidual Deviance: 2214     AIC: 2218"
  },
  {
    "objectID": "common_errors.html#sec-slopes-error",
    "href": "common_errors.html#sec-slopes-error",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "A.4 “Unable to compute predicted values with this model”",
    "text": "A.4 “Unable to compute predicted values with this model”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re using avg_slopes() to try and find the slope for a variable but are running into an error: “Unable to compute predicted values with this model”\n\n\nSuppose we have a binary dependent variable that we wish to predict with a binary or category independent variable. For instance, we might want to know if the chances of voting are higher/lower among men versus women. We would convert both variables to factor variables and perform a logistic model. The syntax below walks through this process by first investigating the variables (e.g., what labels are associated with each category); converting both variables to factors; and then running the model and reporting the results.\n\n#Value Values\n1attr(ess$vote,\"labels\")\nattr(ess$gndr, \"labels\")\n\n#Distribution\ntable(ess$vote)\ntable(ess$gndr)\n\n#Convert into factor\n  #Vote: 0 = did not vote, 1 = voted\n  #Gender: 0 = male, 1 = female\n\ness &lt;- ess |&gt; \n  mutate(voted = factor(vote, levels=c(2,1), \n                        labels=c(\"Did Not Vote\", \"Voted\")), \n         gender = factorize(gndr))\n\n#Model and Summary\name_example &lt;- glm(voted ~ gender, data=ess, family=\"binomial\")\nsummary(ame_example)\n\n\n1\n\nattr(data$variable, \"labels\") is a shortened version of attributes(data$variable) that only shows whether there are value labels associated with the variable.\n\n\n\n\n                 Yes                   No Not eligible to vote \n                   1                    2                    3 \n             Refusal           Don't know            No answer \n                   7                    8                    9 \n     Male    Female No answer \n        1         2         9 \n\n   1    2    3 \n1291  247  130 \n\n  1   2 \n833 840 \n\nCall:\nglm(formula = voted ~ gender, family = \"binomial\", data = ess)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.7484     0.1015  17.229   &lt;2e-16 ***\ngenderFemale  -0.1836     0.1392  -1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe coefficient for our IV is negative, which indicates that female respondents have a lower chance of reporting that they turned out to vote than men (although this difference is not statistically significant). This coefficient is on the log of the odds (logit) scale, which is hard to interpret. We may want to look at the average difference in the probability of turning out between women and men to more clearly communicate the difference between the two groups. We can do this by using the avg_slopes() function from the marginaleffects package. However, in this instance we receive an error message:\n\navg_slopes(ame_example)\n\nError: Unable to compute predicted values with this model. This error can arise\n  when `insight::get_data()` is unable to extract the dataset from the\n  model object, or when the data frame was modified since fitting the\n  model. You can try to supply a different dataset to the `newdata`\n  argument.\n  \n  In addition, this error message was raised:\n  \n  Error in model.frame.default(Terms, newdata, na.action = na.action, xlev\n  = object$xlevels): factor gender has new levels No answer\n\n  \n  Bug Tracker:\n  https://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThere is a category with no observations.\n\n\nLet’s take a look at the gender variable we created earlier compared with its original form:\n\n#Original Variable\nattr(ess$gndr, \"labels\")\n\n     Male    Female No answer \n        1         2         9 \n\ntable(ess$gndr)\n\n\n  1   2 \n833 840 \n\n#Recoded\nlevels(ess$gender)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\ntable(ess$gender)\n\n\n     Male    Female No answer \n      833       840         0 \n\n\nThe gndr variable has three labels associated with it: Male (=1), Female (=2), and No Answer (=9). However, no observations have a value of 9 on this original variable. Regardless, factorize() will still port over the label for “No Answer”. The issue is that avg_slopes() is expecting there to be observations with a label of “No Answer” - when it finds none, it crashes.\n\n\n\n\n\n\nSolution\n\n\n\nUse droplevels() to removing categories with no observations or use factor() to create the variable to begin with\n\n\nWe can avoid this issue in either of two ways. First, we could use droplevels() to drop levels (and their associated labels) that have no observations. Second, we can preempt the problem by simply using factor() and only including the categories we care about.\n\n#Recoding Using the Two Options\ness &lt;- ess |&gt; \n  mutate(\n    #Option 1: droplevels()\n    gender_opt1 = factorize(gndr), \n    gender_opt1 = droplevels(gender_opt1), \n    #Option 2: factor() from the beginning\n    gender_opt2 = factor(gndr,\n                         levels=c(1,2), \n                         labels=c(\"Male\", \"Female\")))\n\n#Levels\nlevels(ess$gender_opt1)\n\n[1] \"Male\"   \"Female\"\n\nlevels(ess$gender_opt2)\n\n[1] \"Male\"   \"Female\"\n\n#Option 1: \name_example_opt1 &lt;- glm(voted ~ gender_opt1, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt1)\n\n\n        Term                  Contrast Estimate Std. Error     z Pr(&gt;|z|)   S\n gender_opt1 mean(Female) - mean(Male)  -0.0247     0.0187 -1.32    0.187 2.4\n   2.5 % 97.5 %\n -0.0614  0.012\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n#Option 2\name_example_opt2 &lt;- glm(voted ~ gender_opt2, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt2)\n\n\n        Term                  Contrast Estimate Std. Error     z Pr(&gt;|z|)   S\n gender_opt2 mean(Female) - mean(Male)  -0.0247     0.0187 -1.32    0.187 2.4\n   2.5 % 97.5 %\n -0.0614  0.012\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response"
  },
  {
    "objectID": "common_errors.html#sec-linetype-error",
    "href": "common_errors.html#sec-linetype-error",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”",
    "text": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to create a predicted values plot from a model with an interaction involving a continuous variable and see the error “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\nSuppose we predict a country’s democracy score with a continuous measure of gross domestic product (gdp_ppp), a continuous measure of corruption (cpi), and their interaction:\n\ninter_model &lt;- lm(v2x_polyarchy ~ gdp_ppp*cpi, data=dta)\nsummary(inter_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_ppp * cpi, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.58552 -0.09686  0.02947  0.13111  0.30958 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.250e-02  5.643e-02   1.462    0.146    \ngdp_ppp     -1.902e-06  3.092e-06  -0.615    0.539    \ncpi          1.203e-02  1.463e-03   8.220 8.34e-14 ***\ngdp_ppp:cpi -2.524e-08  4.370e-08  -0.578    0.564    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1833 on 152 degrees of freedom\n  (23 observations deleted due to missingness)\nMultiple R-squared:  0.4538,    Adjusted R-squared:  0.443 \nF-statistic: 42.09 on 3 and 152 DF,  p-value: &lt; 2.2e-16\n\n\nInterpreting coefficients in a model with an interaction can be tricky and especially so when both variables are continuous variables. One solution is to use predictions() function to obtain predicted values across the range of our main variable for different values of our moderator (e.g., “low”, “medium”, and “high”). For instance:\n\ninter_preds &lt;- predictions(inter_model, \n                           newdata = datagrid(\n                             cpi = c(12,30,40,43.94,56,88), \n                             gdp_ppp = c(711.4, 20309.8, 111751.3)))\n\ninter_preds\n\n\n  cpi gdp_ppp Estimate Std. Error       z Pr(&gt;|z|)     S   2.5 % 97.5 %\n 12.0     711   0.2253     0.0405  5.5659   &lt;0.001  25.2  0.1459  0.305\n 12.0   20310   0.1821     0.0479  3.8040   &lt;0.001  12.8  0.0883  0.276\n 12.0  111751  -0.0196     0.2732 -0.0717   0.9429   0.1 -0.5550  0.516\n 30.0     711   0.4415     0.0248 17.8188   &lt;0.001 233.5  0.3929  0.490\n 30.0   20310   0.3893     0.0282 13.7902   &lt;0.001 141.3  0.3340  0.445\n 30.0  111751   0.1462     0.1995  0.7325   0.4639   1.1 -0.2449  0.537\n 40.0     711   0.5616     0.0251 22.3295   &lt;0.001 364.5  0.5123  0.611\n 40.0   20310   0.5045     0.0210 23.9895   &lt;0.001 420.0  0.4633  0.546\n 40.0  111751   0.2382     0.1608  1.4820   0.1383   2.9 -0.0768  0.553\n 43.9     711   0.6089     0.0275 22.1578   &lt;0.001 359.0  0.5550  0.663\n 43.9   20310   0.5499     0.0199 27.6463   &lt;0.001 556.5  0.5109  0.589\n 43.9  111751   0.2745     0.1463  1.8768   0.0605   4.0 -0.0122  0.561\n 56.0     711   0.7537     0.0392 19.2345   &lt;0.001 271.5  0.6769  0.831\n 56.0   20310   0.6887     0.0241 28.5995   &lt;0.001 595.2  0.6415  0.736\n 56.0  111751   0.3856     0.1071  3.5986   &lt;0.001  11.6  0.1756  0.596\n 88.0     711   1.1380     0.0810 14.0449   &lt;0.001 146.4  0.9792  1.297\n 88.0   20310   1.0572     0.0588 17.9733   &lt;0.001 237.5  0.9419  1.173\n 88.0  111751   0.6802     0.1107  6.1456   &lt;0.001  30.2  0.4633  0.897\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cpi, gdp_ppp, v2x_polyarchy \nType:  response \n\n\nThere is a lot of data here to try and read/interpret. However, we can create a nice plot to summarize the predictions. Unfortunately, we run into the following error when running this syntax:\n\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)\n\nError in `geom_line()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error in `scale_f()`:\n! A continuous variable cannot be mapped to the linetype aesthetic\nℹ choose a different aesthetic or use `scale_linetype_binned()`\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThe variable being used to specify linetype (or color, etc.) is numeric in value.\n\n\nWe created three sets of predictions above: one where gdp_ppp = 711.4 and cpi took on one of five values from across its range; one where gdp_ppp = 20309.8 and cpi took on one of those five values; and one where cpi = 111751.3 and cpitook on one of those values. We can visually differentiate between these different predictions by telling ggplot() to use a different type of line for each set (or, perhaps, a different color). But, the linetype function requires the variable in question to be a factor.\n\n\n\n\n\n\nSolution\n\n\n\nConvert the problematic numeric variable to a factor and then run the ggplot() command.\n\n\nWe can avoid this issue by converting the offending variable to a factor variable using the factor() function.\n\n#Convert to factor\ninter_preds &lt;- inter_preds |&gt; \n  mutate(\n    gdp_ppp = factor(gdp_ppp, \n                     levels=c( 711.4, 20309.8, 111751.3), \n                     labels=c(\"Low\", \"Medium\", \"High\")))\n\n#Create the plot\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)"
  },
  {
    "objectID": "common_errors.html#footnotes",
    "href": "common_errors.html#footnotes",
    "title": "Appendix A — Veelgemaakte fouten in R",
    "section": "",
    "text": "There could an additional culprit: missing data. Suppose that you have 1 DV and two IVs, one of which is a categorical variable with three levels (low, middle, and high) and the other a continuous variable. R will automatically drop observations from the model that have missing data on at least one of the variables in the model (DV and IV). Suppose that all of the observations with a classification of “high” on the categorical variable have missing (NA) values on the continuous variable - in that instance, R would not have the necessary data to estimate a coefficient for the “high” category and, as a result, you would likely only get indicators for one category of the categorical variable (comparing it to the reference group) and one for the continuous variable.↩︎\nOf course, in practice we might want to follow the factorize() step with a subsequent step where we relevel the variable, i.e., change the reference group. Alternatively we could simply use factor() in this instance as well and handle the levelling and labelling all at once.↩︎\nWhat if the DV was simply coded 0/1 and not converted to a factor? The syntax in this example would run but a different problem would emerge: the glm() command would fit a linear model (i.e., a linear regression model) to the data rather than a logistic model. This is another reason to explicitly specify the family to be used when using the glm() function.↩︎"
  },
  {
    "objectID": "package_overview.html#alle-packages-installeren",
    "href": "package_overview.html#alle-packages-installeren",
    "title": "Appendix B — Overzicht R Packages",
    "section": "B.1 Alle packages installeren",
    "text": "B.1 Alle packages installeren\nOm alle gebruikte packages in één keer te installeren, kun je onderstaande code gebruiken:\n\npackage_list &lt;- c(\"tidyverse\", \"rio\", \"summarytools\", \"DescTools\", \"skimr\",\n                  \"correlation\", \"parameters\", \"performance\", \"effectsize\",\n                  \"see\", \"marginaleffects\", \" bromo\", \"ggResidpanel\", \"rms\",\n                  \"car\", \"modelsummary\", \"gt\", \"gtsummary\", \"kableExtra\",\n                  \"knitr\", \"rmarkdown\",\"huxtable\", \"flextable\", \"lmtest\" ,\n                  \"openintro\", \"statsr\", \"tidymodels\", \"tinytex\",\n                  \"visdat\", \"patchwork\", \"ggpubr\", \"cowplot\", \"expss\",\n                  \"effsize\", \"foreign\", \"haven\",\n                  \"ggstance\", \"ggrepel\", \"ggsignif\", \"naniar\", \"openxlsx\",\n                  \"sjmisc\", \"crosstable\", \"sjlabelled\", \"psych\", \"dice\",\n                  \"pwr\", \"visualize\", \"infer\" , \"sandwich\", \"sjPlot\",\n                  \"scales\")\n\ninstall.packages(package_list)\n\nMoest er een probleem optreden bij de installatie van het marginaleffects package, probeer dan volgende syntax:\nfeb #| eval: false  install.packages(\"marginaleffects\", type=\"binary\")}"
  },
  {
    "objectID": "Formulas.html#covariance-and-correlation",
    "href": "Formulas.html#covariance-and-correlation",
    "title": "Appendix C — Formules",
    "section": "C.1 Covariance and Correlation",
    "text": "C.1 Covariance and Correlation\n(Sample) Covariance\n\\[cov(x,y) = \\frac{\\sum (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{n-1}\\]\nPearson Correlation\n\\[r = \\frac{cov(x,y)}{SD(x) * SD(y)}\\]"
  },
  {
    "objectID": "Formulas.html#linear-regression",
    "href": "Formulas.html#linear-regression",
    "title": "Appendix C — Formules",
    "section": "C.2 Linear Regression",
    "text": "C.2 Linear Regression\nLinear Regression Equation\n\\[y_{i} = b_{0} + b_{1}x_{1i} + b_{2}x_{2i} + ... + b_{k}x_{ki} + \\epsilon_{i}\\]\nSimple Linear Regression: Slope\n\\[b_{1} = \\frac{\\sum(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum(x_{i} - \\bar{x})^2}\\]\nSimple Linear Regression: Intercept/Constant\n\\[b_{0} = \\bar{y} - b_{1}\\bar{x}\\]\nRegression Model with Interaction\n\\[y = b_{0} + b_{1}x_{1} + b_{2}x_{2} + b_{3}(x_{1}x_{2}) + \\epsilon\\]\nMarginal Effects in Interaction Model\n\\[b_{1} + (x2 * b_{3})\\] \\[b_{2} + (x1 * b_{3})\\]\nt-test for regression coefficients\n\\[t = \\frac{b}{SE_{b}}\\]\nConfidence Interval: Coefficient\n\\[CI = b \\pm (t_{df} * SE)\\]\nRegression Sum of Squares (Also called: Model Sum of Squares)\n\\[SS_{Regression} = \\sum(\\hat{y} - \\bar{y})^2\\]\nResidual Sum of Squares\n\\[SS_{Residual} = \\sum(y_{i} - \\hat{y})^2\\]\nTotal Sum of Squares\n\\[SS_{Total} = \\sum(y_{i} - \\bar{y})^2\\]\nR2\n\\[R^2 = \\frac{SS_{Regression}}{SS_{Total}}\\]\n\\[R^2 = 1 - \\frac{SS_{Residual}}{SS_{Total}} \\]\nMean Squares: Residual\n\\[MS_{Residual} = \\frac{SS_{Residual}}{\\textrm{df}_{Residual}}\\] \\[\\textrm{df}_{Residual} = n-k\\] Mean Squares: Regression Model\n\\[MS_{Model} = \\frac{SS_{Regression}}{df_{Model}}\\]\n\\[df_{Model} = k\\] F\n\\[F = \\frac{MS_{Model}}{MS_{Residual}}\\]"
  },
  {
    "objectID": "Formulas.html#logistic-regression",
    "href": "Formulas.html#logistic-regression",
    "title": "Appendix C — Formules",
    "section": "C.3 Logistic Regression",
    "text": "C.3 Logistic Regression\nLogistic Regression Model with Single Explanatory Variable\n\\[\\textrm{log(Odds)} = b_0 + b_1x_{1i} + b_2x_{2i}...\\]\n\\[P(Y_{i} = 1) = \\frac{1}{1 + e^{-(b_{0} + b_{1}x_{1i})}}\\]\nOdds and Probabiilty\n\\[odds = \\frac{p}{1 - p}\\]\n\\[p = \\frac{odds}{1 + odds}\\]\nOdds Ratio\n\\[e^{b}\\]\nz statistic\n\\[z = \\frac{b}{se}\\]\nLikelihood Ratio\n\\[\\chi^2 = (-2LL_{baseline}) - (-2LL_{new})\\]\n\\[\\textrm{df} = k_{new} - k_{baseline}\\]"
  },
  {
    "objectID": "Formulas.html#appendix-critical-values-of-t-distribution",
    "href": "Formulas.html#appendix-critical-values-of-t-distribution",
    "title": "Appendix C — Formules",
    "section": "C.4 Appendix: Critical Values of t-distribution",
    "text": "C.4 Appendix: Critical Values of t-distribution\n\n\n\nCritical Values of the t-distribution (Two-Tailed Test)\n\n\ndf\n0.05\n0.01\n\n\n\n\n1\n12.71\n63.66\n\n\n2\n4.30\n9.92\n\n\n3\n3.18\n5.84\n\n\n4\n2.78\n4.60\n\n\n5\n2.57\n4.03\n\n\n6\n2.45\n3.71\n\n\n7\n2.36\n3.50\n\n\n8\n2.31\n3.36\n\n\n9\n2.26\n3.25\n\n\n10\n2.23\n3.17\n\n\n11\n2.20\n3.11\n\n\n12\n2.18\n3.05\n\n\n13\n2.16\n3.01\n\n\n14\n2.14\n2.98\n\n\n15\n2.13\n2.95\n\n\n16\n2.12\n2.92\n\n\n17\n2.11\n2.90\n\n\n18\n2.10\n2.88\n\n\n19\n2.09\n2.86\n\n\n20\n2.09\n2.85\n\n\n21\n2.08\n2.83\n\n\n22\n2.07\n2.82\n\n\n23\n2.07\n2.81\n\n\n24\n2.06\n2.80\n\n\n25\n2.06\n2.79\n\n\n26\n2.06\n2.78\n\n\n27\n2.05\n2.77\n\n\n28\n2.05\n2.76\n\n\n29\n2.05\n2.76\n\n\n30\n2.04\n2.75\n\n\n35\n2.03\n2.72\n\n\n40\n2.02\n2.70\n\n\n45\n2.01\n2.69\n\n\n50\n2.01\n2.68\n\n\n60\n2.00\n2.66\n\n\n70\n1.99\n2.65\n\n\n80\n1.99\n2.64\n\n\n90\n1.99\n2.63\n\n\n100\n1.98\n2.63\n\n\n∞\n1.96\n2.58"
  }
]